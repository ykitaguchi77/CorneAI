{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjVtdDNO6mLXsPdoe22DqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CorneAI/blob/main/GradCAM_Revision_250718.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwHpAVy2T_ov"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **【目次】論文リビジョン用 CorneAI 分析ノートブック**\n",
        "\n",
        "### **はじめに**\n",
        "このノートブックは、角膜画像データセットに対するYOLOv5モデルの性能評価および、その判断根拠を複数の説明可能性AI（XAI）手法を用いて分析・評価することを目的とします。各セクションは独立して実行、または順次実行できるように構成されています。\n",
        "\n",
        "---\n",
        "\n",
        "### **第0部：環境構築と初期設定**\n",
        "全ての分析の基礎となる環境をここで一括して設定します。\n",
        "\n",
        "* **0.1. Google Driveのマウント**\n",
        "* **0.2. 必須ライブラリのインストール**\n",
        "* **0.3. リポジトリのクローンとパス設定**\n",
        "* **0.4. 主要パラメータとパスの一元管理**\n",
        "* **0.5. 共通関数の定義**\n",
        "* **0.6. YOLOv5モデルのロード**\n",
        "\n",
        "---\n",
        "\n",
        "### **第1部：基礎データの準備とAIによる初期予測**\n",
        "分析の土台となるCSVファイルを作成し、ベースラインとなるAIの予測結果を記録します。\n",
        "\n",
        "* **1.1. 初期CSVファイルの作成**\n",
        "* **1.2. ファイル名からのGround Truth抽出**\n",
        "* **1.3. 全画像に対するYOLOv5推論の実行**\n",
        "* **1.4. 予測結果と信頼度をCSVに追記**\n",
        "* **1.5. 結果CSVの保存と確認**\n",
        "\n",
        "---\n",
        "\n",
        "### **第2部：説明可能性AI（XAI）分析とマスク画像の生成**\n",
        "各XAI手法を実行し、モデルの判断根拠を可視化した「マスク画像」を生成・保存します。\n",
        "\n",
        "* **2.1. GradCAM++による分析**\n",
        "* **2.2. GradCAMによる分析**\n",
        "* **2.3. LIMEによる分析**\n",
        "* **2.4. Occlusion Sensitivityによる分析**\n",
        "* **2.5. (オプション) RISE, SHAPによる分析**\n",
        "\n",
        "---\n",
        "\n",
        "### **第3部：評価指標の計算と記録**\n",
        "生成したマスク画像と専門家の手動アノテーション（Expert Mask）を比較し、定量的評価を行います。\n",
        "\n",
        "* **3.1. Pointing Game Accuracyの計算**\n",
        "* **3.2. Intersection over Union (IoU) の計算**\n",
        "* **3.3. 最終評価CSVの保存**\n",
        "\n",
        "---\n",
        "\n",
        "### **第4部：Cut & Paste実験**\n",
        "角膜領域を別の画像に移植し、モデルの頑健性を評価する追加実験です。\n",
        "\n",
        "* **4.1. 実験用CSVの作成 (`Ueno_Mix1039_cutmix.csv`)**\n",
        "* **4.2. Cut & Paste画像の生成と推論**\n",
        "* **4.3. Cut & Paste予測結果の記録**\n",
        "\n",
        "---\n",
        "\n",
        "### **第5部：追加分析とデータ整理**\n",
        "論文に必要なその他の補足データを算出します。\n",
        "\n",
        "* **5.1. AI検出BBoxと専門家マスクの一致率計算 (`expert_ratio`)**\n",
        "* **5.2. 最終統計分析と可視化**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bNIowuUXUAHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##第0部：環境構築と初期設定\n",
        "\n",
        "全ての分析の基礎となる環境をここで一括して設定します。このセクションのセルを上から順に実行すれば、以降の分析の準備がすべて整います。"
      ],
      "metadata": {
        "id": "Ew2lAx3eVvYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.1. Google Driveのマウント\n",
        "\n",
        "Google Driveに接続します。"
      ],
      "metadata": {
        "id": "ObCJKoMrU4fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "AtDT3RwBUCY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.2. & 0.3. ライブラリのインストールと作業ディレクトリへの移動\n",
        "\n",
        "分析に必要なライブラリをインストールし、yolov5-gradcamリポジトリをクローンして、そのディレクトリを基準に作業を進めます。"
      ],
      "metadata": {
        "id": "wAfNJOHFVArY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインストール\n",
        "%cd /content\n",
        "!pip install -U git+https://github.com/pooya-mohammadi/deep_utils.git --q\n",
        "!pip install japanize-matplotlib --q\n",
        "!pip install scikit-image --q\n",
        "\n",
        "# リポジトリをクローンして作業ディレクトリに設定\n",
        "!git clone https://github.com/pooya-mohammadi/yolov5-gradcam\n",
        "%cd /content/yolov5-gradcam\n",
        "\n",
        "print(\"✅ 環境構築完了\")"
      ],
      "metadata": {
        "id": "gj9G6vWFVFGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.4. ライブラリの一括インポート\n",
        "\n",
        "ノートブック全体で使用するライブラリをここでまとめてインポートします。"
      ],
      "metadata": {
        "id": "XqDk88reVHk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 基本ライブラリ\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# データ操作・計算\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# PyTorch関連\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 可視化\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# ユーティリティ\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.segmentation import quickshift\n",
        "\n",
        "# YOLOv5 / Grad-CAM 関連\n",
        "from models.experimental import attempt_load\n",
        "from models.yolo import Model, Detect\n",
        "from models.common import Conv, C3, SPPF\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import non_max_suppression as yolo_nms\n",
        "\n",
        "# 警告を抑制\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"✅ ライブラリのインポート完了\")"
      ],
      "metadata": {
        "id": "Bae7QB9hVLh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.5. 主要パラメータとパスの一元管理\n",
        "\n",
        "全てのファイルパスや設定値をこのセルで管理します。変更が必要な場合はこのセルのみを修正してください。"
      ],
      "metadata": {
        "id": "U2petihJVQYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 主要パス設定 ---\n",
        "BASE_DIR = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/Ueno_Mix1039\"\n",
        "IMAGE_DIR = os.path.join(BASE_DIR, \"Images\")\n",
        "MODEL_PATH = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "\n",
        "# --- CSV関連パス ---\n",
        "# このCSVが全ての分析結果を集約するマスターファイルとなります\n",
        "MAIN_CSV_PATH = os.path.join(BASE_DIR, \"Ueno_Mix1039_compare_methods.csv\")\n",
        "CUTMIX_CSV_PATH = os.path.join(BASE_DIR, \"Ueno_Mix1039_cutmix.csv\")\n",
        "\n",
        "# --- マスク(アノテーション)関連パス ---\n",
        "EXPERT_MASK_DIR = os.path.join(BASE_DIR, \"Expert_annotation_masks\")\n",
        "XML_ANNOTATION_PATH = os.path.join(BASE_DIR, \"Cornea_segmentation/annotations.xml\")\n",
        "\n",
        "# --- 分析結果の保存先ディレクトリ ---\n",
        "BBOX_MASK_DIR = os.path.join(BASE_DIR, \"YOLO_bbox_mask\")\n",
        "GRADCAM_PP_MASK_DIR = os.path.join(BASE_DIR, \"AOI_50_mask_GradCAM++\")\n",
        "GRADCAM_MASK_DIR = os.path.join(BASE_DIR, \"AOI_50_mask_GradCAM\")\n",
        "LIME_MASK_DIR = os.path.join(BASE_DIR, \"AOI_50_mask_LIME\")\n",
        "OCCLUSION_MASK_DIR = os.path.join(BASE_DIR, \"AOI_50_mask_Occlusion_sensitivity\")\n",
        "\n",
        "# --- モデル設定 ---\n",
        "DEVICE = \"cpu\"  # GPUの個体差をなくし結果を統一するためCPUを使用\n",
        "CLASS_NAMES = [\"infection\", \"normal\", \"non-infection\", \"scar\", \"tumor\", \"deposit\", \"APAC\", \"lens opacity\", \"bullous\"]\n",
        "CONF_THRES = 0.25\n",
        "IOU_THRES = 0.45\n",
        "\n",
        "print(\"✅ パラメータ設定完了\")"
      ],
      "metadata": {
        "id": "J02f8aCrVS4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.6. 共通関数の定義\n",
        "\n",
        "複数のタスクで繰り返し使用する関数をここで定義します。"
      ],
      "metadata": {
        "id": "yuyywZuBVXCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img_bgr, device, img_size=(640, 640)):\n",
        "    \"\"\"画像をYOLOv5の入力形式に前処理する\"\"\"\n",
        "    # BGR to RGB, to 640x640 with letterbox\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    img_resized = letterbox(img_rgb, new_shape=img_size, auto=True)[0]\n",
        "\n",
        "    # HWC to CHW, to float tensor\n",
        "    img_transposed = np.ascontiguousarray(img_resized.transpose((2, 0, 1)))\n",
        "    img_tensor = torch.from_numpy(img_transposed).to(device).float() / 255.0\n",
        "\n",
        "    # Add batch dimension\n",
        "    if img_tensor.ndim == 3:\n",
        "        img_tensor = img_tensor[None]\n",
        "\n",
        "    return img_tensor, img_resized\n",
        "\n",
        "print(\"✅ 共通関数の定義完了\")"
      ],
      "metadata": {
        "id": "pPyrSv9uVah2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.7. YOLOv5モデルのロード\n",
        "\n",
        "分析の根幹となるYOLOv5モデルをロードします。ノートブック全体でこのmodel変数を使い回すことで、何度もロードする無駄をなくします。"
      ],
      "metadata": {
        "id": "Vaj8fqWrVckh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"'{MODEL_PATH}' からモデルをロードしています...\")\n",
        "print(f\"使用デバイス: {DEVICE}\")\n",
        "\n",
        "# PyTorchのカスタムクラスを安全にロードするための設定\n",
        "# エラー回避のために必要\n",
        "torch.serialization.add_safe_globals([\n",
        "    Model, Detect, Conv, C3, SPPF, nn.Sequential, nn.ModuleList,\n",
        "    nn.Conv2d, nn.BatchNorm2d, nn.SiLU, nn.MaxPool2d, nn.Upsample\n",
        "])\n",
        "\n",
        "model = attempt_load(MODEL_PATH, device=DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n✅ モデルのロード完了\")\n",
        "print(f\"モデルクラス: {model.names}\")"
      ],
      "metadata": {
        "id": "KyHDmntvVgHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qqBNMZjsViUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第1部：基礎データの準備とAIによる初期予測\n",
        "\n",
        "分析の土台となるCSVファイルを作成し、ベースラインとなるAIの予測結果を記録します。"
      ],
      "metadata": {
        "id": "t9je8hqmVyls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. & 1.2. 初期CSVファイルの作成とGround Truthの抽出\n",
        "\n",
        "画像フォルダをスキャンし、ファイル名を基にimage_basenameとGroundTruth列を持つDataFrameを作成します。"
      ],
      "metadata": {
        "id": "VBJtqe8UV6S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ground_truth(basename):\n",
        "    \"\"\"ファイル名から[]内の文字列を抽出し、対応するクラス名を返す\"\"\"\n",
        "    match = re.search(r\"\\[([^\\]]+)\\]\", basename)\n",
        "    if not match:\n",
        "        return None\n",
        "\n",
        "    label_text = match.group(1).lower()\n",
        "\n",
        "    # ラベルとクラス名のマッピング辞書\n",
        "    label_mapping = {\n",
        "        'infection': 'infection',\n",
        "        'normal': 'normal',\n",
        "        'immun': 'non-infection',\n",
        "        'scar': 'scar',\n",
        "        'tumor': 'tumor',\n",
        "        'deposit': 'deposit',\n",
        "        'apac': 'APAC',\n",
        "        'cat': 'lens opacity',\n",
        "        'bullous': 'bullous'\n",
        "    }\n",
        "\n",
        "    for key, value in label_mapping.items():\n",
        "        if key in label_text:\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "# 画像ディレクトリからファイル名リストを取得\n",
        "image_extensions = {'.jpg', '.jpeg', '.png'}\n",
        "image_files = [f for f in os.listdir(IMAGE_DIR) if Path(f).suffix.lower() in image_extensions]\n",
        "basenames = [Path(f).stem for f in image_files]\n",
        "\n",
        "# DataFrameを作成\n",
        "df = pd.DataFrame({'image_basename': basenames})\n",
        "\n",
        "# GroundTruth列を追加\n",
        "df['GroundTruth'] = df['image_basename'].apply(extract_ground_truth)\n",
        "\n",
        "print(f\"✅ {len(df)}件の画像からベースとなるDataFrameを作成しました。\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "gnW3ZfZaV7ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3. & 1.4. 全画像に対するYOLOv5推論と結果の追記\n",
        "\n",
        "作成したリストの各画像に対して推論を実行し、予測結果（Predict）と信頼度（Likelihood）をDataFrameに追加します。"
      ],
      "metadata": {
        "id": "QeJ45h1qV_mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "# 第0部でロード済みのモデルを使用して推論\n",
        "for basename in tqdm(df['image_basename'], desc=\"AIによる予測を実行中\"):\n",
        "    # 対応する画像ファイルのパスを検索\n",
        "    image_file_found = None\n",
        "    for ext in image_extensions:\n",
        "        p = Path(IMAGE_DIR) / f\"{basename}{ext}\"\n",
        "        if p.exists():\n",
        "            image_file_found = p\n",
        "            break\n",
        "\n",
        "    if not image_file_found:\n",
        "        predictions.append(None)\n",
        "        confidences.append(None)\n",
        "        continue\n",
        "\n",
        "    img = cv2.imread(str(image_file_found))\n",
        "    img_tensor, _ = preprocess_image(img, device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(img_tensor)[0]\n",
        "        pred_nms = yolo_nms(pred, conf_thres=CONF_THRES, iou_thres=IOU_THRES)[0]\n",
        "\n",
        "        if pred_nms is not None and len(pred_nms) > 0:\n",
        "            # 最も信頼度の高い予測を採用\n",
        "            best_pred = pred_nms[0]\n",
        "            pred_class_idx = int(best_pred[5])\n",
        "            predictions.append(CLASS_NAMES[pred_class_idx])\n",
        "            confidences.append(best_pred[4].item())\n",
        "        else:\n",
        "            # 何も検出されなかった場合\n",
        "            predictions.append(\"none\")\n",
        "            confidences.append(0.0)\n",
        "\n",
        "df['Predict'] = predictions\n",
        "df['Likelihood'] = confidences\n",
        "\n",
        "print(\"✅ 全画像の予測が完了しました。\")"
      ],
      "metadata": {
        "id": "X7zwap72WCV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5. 結果CSVの保存と確認\n",
        "\n",
        "全ての情報をまとめたDataFrameを、マスターCSVファイルとして保存します。"
      ],
      "metadata": {
        "id": "aQ-K6GxrWD_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分析手法ごとの列をあらかじめ作成（この後のタスクで使用）\n",
        "xai_methods = ['GradCAM', 'GradCAM++', 'RISE', 'LIME', 'Occlusion']\n",
        "for method in xai_methods:\n",
        "    df[f'{method}_X'] = pd.NA\n",
        "    df[f'{method}_Y'] = pd.NA\n",
        "    df[f'{method}_pointing_game'] = pd.NA\n",
        "    df[f'{method}_IoU'] = pd.NA\n",
        "\n",
        "# CSVファイルとして保存\n",
        "df.to_csv(MAIN_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"✅ 全ての初期データをCSVファイルに保存しました: {MAIN_CSV_PATH}\")\n",
        "\n",
        "# 保存した内容の確認\n",
        "print(\"\\n--- 保存されたデータの先頭5行 ---\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\n--- データ概要 ---\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n--- AIの予測結果の内訳 ---\")\n",
        "print(df['Predict'].value_counts())"
      ],
      "metadata": {
        "id": "vNrLeGfrWHlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第2部：説明可能性AI（XAI）分析とマスク画像の生成\n"
      ],
      "metadata": {
        "id": "ecozQOGKWeq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1. GradCAM++による分析\n",
        "\n",
        "YOLOv5モデルの指定された6つの畳み込み層に対してGradCAM++を適用します。「元画像と重ね合わせたヒートマップ」と「定量的評価用のAOIマスク」の両方を、それぞれ専用のフォルダに保存します。\n",
        "\n"
      ],
      "metadata": {
        "id": "PmBKliCWWd4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ヒートマップを画像に重ね合わせるヘルパー関数 ---\n",
        "def apply_heatmap_to_image(original_img, heatmap_normalized, colormap=cv2.COLORMAP_JET):\n",
        "    \"\"\"正規化されたヒートマップを元の画像に重ね合わせる\"\"\"\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap_normalized)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap_uint8, colormap)\n",
        "    overlaid_image = cv2.addWeighted(original_img, 0.6, heatmap_colored, 0.4, 0)\n",
        "    return overlaid_image\n",
        "\n",
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "\n",
        "target_layers = [\n",
        "    \"model_17_cv3_conv\", \"model_20_cv3_conv\", \"model_23_cv3_conv\",\n",
        "    \"model_24_m_0\", \"model_24_m_1\", \"model_24_m_2\"\n",
        "]\n",
        "\n",
        "# === 拡張子対応の修正 ===\n",
        "# 事前に画像ファイルの「ベース名 -> フルパス」の辞書を作成\n",
        "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "path_map = {\n",
        "    Path(f).stem: Path(IMAGE_DIR) / f\n",
        "    for f in os.listdir(IMAGE_DIR)\n",
        "    if Path(f).suffix.lower() in VALID_EXTENSIONS\n",
        "}\n",
        "print(f\"✅ {len(path_map)}件の画像ファイル（.JPG, .Jpgなども含む）をインデックスしました。\")\n",
        "\n",
        "# --- 出力ディレクトリの準備 ---\n",
        "base_output_dir = Path(GRADCAM_PP_MASK_DIR)\n",
        "heatmap_base_dir = base_output_dir / \"heatmaps\"\n",
        "mask_base_dir = base_output_dir / \"masks\"\n",
        "for layer_name in target_layers:\n",
        "    (heatmap_base_dir / layer_name).mkdir(parents=True, exist_ok=True)\n",
        "    (mask_base_dir / layer_name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"GradCAM++分析を開始します。保存先: {base_output_dir}\")\n",
        "\n",
        "# 画像ごとにループ\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"GradCAM++ 生成中\"):\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    # 辞書から画像パスを高速に取得\n",
        "    img_path_found = path_map.get(basename)\n",
        "    if not img_path_found:\n",
        "        continue\n",
        "\n",
        "    # 1つのレイヤーでも処理済みか簡易チェック（高速化のため）\n",
        "    # 厳密なチェックはレイヤーごとのループ内で行う\n",
        "    first_layer_mask_path = mask_base_dir / target_layers[0] / f\"{basename}.png\"\n",
        "    if first_layer_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    img = cv2.imread(str(img_path_found))\n",
        "    img_tensor, _ = preprocess_image(img, device=DEVICE)\n",
        "\n",
        "    # 各レイヤーに対してループ\n",
        "    for layer_name in target_layers:\n",
        "        heatmap_path = heatmap_base_dir / layer_name / f\"{basename}.jpg\"\n",
        "        mask_path = mask_base_dir / layer_name / f\"{basename}.png\"\n",
        "\n",
        "        if heatmap_path.exists() and mask_path.exists():\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # methodを\"gradcampp\"に指定\n",
        "            with YOLOV5GradCAM(model, layer_name, method=\"gradcampp\") as cam:\n",
        "                heatmap = cam(img_tensor)\n",
        "\n",
        "            if heatmap is not None:\n",
        "                original_h, original_w = img.shape[:2]\n",
        "                heatmap_resized = cv2.resize(heatmap, (original_w, original_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                # 1. ヒートマップ画像を保存\n",
        "                overlaid_image = apply_heatmap_to_image(img, heatmap_resized)\n",
        "                cv2.imwrite(str(heatmap_path), overlaid_image)\n",
        "\n",
        "                # 2. AOIマスク画像を保存\n",
        "                threshold_value = np.percentile(heatmap_resized, 50)\n",
        "                mask = (heatmap_resized >= threshold_value).astype(np.uint8) * 255\n",
        "                cv2.imwrite(str(mask_path), mask)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"エラー発生: {basename}, Layer: {layer_name}, Error: {e}\")\n",
        "\n",
        "print(\"✅ GradCAM++のヒートマップとAOIマスクの生成が完了しました。\")"
      ],
      "metadata": {
        "id": "goHGCMHdWiyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2. GradCAMによる分析\n",
        "\n",
        "基本的なGradCAMを6つの対象レイヤーに適用し、「元画像と重ね合わせたヒートマップ」と「AOIマスク」の両方を、それぞれ専用のフォルダに保存します。"
      ],
      "metadata": {
        "id": "odDA0ifTXIr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "\n",
        "target_layers = [\n",
        "    \"model_17_cv3_conv\", \"model_20_cv3_conv\", \"model_23_cv3_conv\",\n",
        "    \"model_24_m_0\", \"model_24_m_1\", \"model_24_m_2\"\n",
        "]\n",
        "\n",
        "# === 拡張子対応: 事前に画像ファイルのパス辞書を作成 ===\n",
        "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "path_map = {\n",
        "    Path(f).stem: Path(IMAGE_DIR) / f\n",
        "    for f in os.listdir(IMAGE_DIR)\n",
        "    if Path(f).suffix.lower() in VALID_EXTENSIONS\n",
        "}\n",
        "print(f\"✅ {len(path_map)}件の画像ファイルをインデックスしました。\")\n",
        "\n",
        "# --- 出力ディレクトリの準備 ---\n",
        "base_output_dir = Path(GRADCAM_MASK_DIR)\n",
        "heatmap_base_dir = base_output_dir / \"heatmaps\"\n",
        "mask_base_dir = base_output_dir / \"masks\"\n",
        "for layer_name in target_layers:\n",
        "    (heatmap_base_dir / layer_name).mkdir(parents=True, exist_ok=True)\n",
        "    (mask_base_dir / layer_name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"GradCAM分析を開始します。保存先: {base_output_dir}\")\n",
        "\n",
        "# 画像ごとにループ\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"GradCAM 生成中\"):\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    img_path_found = path_map.get(basename)\n",
        "    if not img_path_found:\n",
        "        continue\n",
        "\n",
        "    # 1つのレイヤーでも処理済みか簡易チェック\n",
        "    first_layer_mask_path = mask_base_dir / target_layers[0] / f\"{basename}.png\"\n",
        "    if first_layer_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    img = cv2.imread(str(img_path_found))\n",
        "    img_tensor, _ = preprocess_image(img, device=DEVICE)\n",
        "\n",
        "    # 各レイヤーに対してループ\n",
        "    for layer_name in target_layers:\n",
        "        heatmap_path = heatmap_base_dir / layer_name / f\"{basename}.jpg\"\n",
        "        mask_path = mask_base_dir / layer_name / f\"{basename}.png\"\n",
        "\n",
        "        if heatmap_path.exists() and mask_path.exists():\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # methodを\"gradcam\"に指定して実行\n",
        "            with YOLOV5GradCAM(model, layer_name, method=\"gradcam\") as cam:\n",
        "                heatmap = cam(img_tensor)\n",
        "\n",
        "            if heatmap is not None:\n",
        "                original_h, original_w = img.shape[:2]\n",
        "                heatmap_resized = cv2.resize(heatmap, (original_w, original_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                overlaid_image = apply_heatmap_to_image(img, heatmap_resized)\n",
        "                cv2.imwrite(str(heatmap_path), overlaid_image)\n",
        "\n",
        "                threshold_value = np.percentile(heatmap_resized, 50)\n",
        "                mask = (heatmap_resized >= threshold_value).astype(np.uint8) * 255\n",
        "                cv2.imwrite(str(mask_path), mask)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"エラー発生: {basename}, Layer: {layer_name}, Error: {e}\")\n",
        "\n",
        "print(\"✅ GradCAMのヒートマップとAOIマスクの生成が完了しました。\")"
      ],
      "metadata": {
        "id": "knP4_9krXQcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3. LIMEによる分析\n",
        "\n",
        "各画像に対してLIMEを実行し、判断に寄与したスーパーピクセルを特定します。その結果を「元画像と重ね合わせたヒートマップ」と「評価用のAOIマスク」として保存します。"
      ],
      "metadata": {
        "id": "h7OIRXAlWmaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LIME分析に必要なクラスと関数\n",
        "class SimpleLIME:\n",
        "    \"\"\"LIMEの簡易実装（バッチ処理対応）\"\"\"\n",
        "    def __init__(self, model, device='cpu'):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.eval()\n",
        "\n",
        "    def explain(self, img_bgr, target_class, num_samples=50):\n",
        "        \"\"\"LIME分析を実行\"\"\"\n",
        "        h, w = img_bgr.shape[:2]\n",
        "\n",
        "        # 1. スーパーピクセルに分割\n",
        "        segments = quickshift(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB), kernel_size=15, max_dist=200, ratio=0.2)\n",
        "        num_segments = np.max(segments) + 1\n",
        "\n",
        "        # 2. 摂動サンプルの生成と推論\n",
        "        data = []\n",
        "        labels = []\n",
        "\n",
        "        # tqdmをループの外側に配置\n",
        "        pbar = tqdm(range(num_samples), desc=\" LIME Samples\", leave=False)\n",
        "        for _ in pbar:\n",
        "            mask_vector = np.random.randint(0, 2, num_segments)\n",
        "            masked_img = img_bgr.copy()\n",
        "            for seg_id in range(num_segments):\n",
        "                if mask_vector[seg_id] == 0:\n",
        "                    masked_img[segments == seg_id] = 128 # グレーでマスク\n",
        "\n",
        "            with torch.no_grad():\n",
        "                img_tensor, _ = preprocess_image(masked_img, self.device)\n",
        "                pred = self.model(img_tensor)[0]\n",
        "                score = self._get_class_score(pred, target_class)\n",
        "\n",
        "            data.append(mask_vector)\n",
        "            labels.append(score)\n",
        "\n",
        "        # 3. 線形モデルで学習\n",
        "        from sklearn.linear_model import Ridge\n",
        "        model_ridge = Ridge(alpha=1.0)\n",
        "        model_ridge.fit(np.array(data), np.array(labels))\n",
        "        importance = model_ridge.coef_\n",
        "\n",
        "        # 4. 説明マップ（ヒートマップ）の作成\n",
        "        explanation_map = np.zeros_like(segments, dtype=float)\n",
        "        for seg_id in range(num_segments):\n",
        "            explanation_map[segments == seg_id] = importance[seg_id]\n",
        "\n",
        "        if np.max(explanation_map) > np.min(explanation_map):\n",
        "            explanation_map = (explanation_map - np.min(explanation_map)) / (np.max(explanation_map) - np.min(explanation_map))\n",
        "\n",
        "        return explanation_map\n",
        "\n",
        "    def _get_class_score(self, prediction, target_class):\n",
        "        \"\"\"特定クラスの最高信頼度スコアを取得\"\"\"\n",
        "        pred_nms = yolo_nms(prediction, conf_thres=0.01, iou_thres=IOU_THRES)[0]\n",
        "        if pred_nms is None or len(pred_nms) == 0: return 0.0\n",
        "        class_detections = pred_nms[pred_nms[:, 5] == target_class]\n",
        "        return class_detections[:, 4].max().item() if len(class_detections) > 0 else 0.0\n",
        "\n",
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "\n",
        "# 事前に画像ファイルのパス辞書を作成\n",
        "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "path_map = { Path(f).stem: Path(IMAGE_DIR) / f for f in os.listdir(IMAGE_DIR) if Path(f).suffix.lower() in VALID_EXTENSIONS }\n",
        "print(f\"✅ {len(path_map)}件の画像ファイルをインデックスしました。\")\n",
        "\n",
        "# 出力ディレクトリの準備\n",
        "base_output_dir = Path(LIME_MASK_DIR)\n",
        "heatmap_dir = base_output_dir / \"heatmaps\"\n",
        "mask_dir = base_output_dir / \"masks\"\n",
        "heatmap_dir.mkdir(parents=True, exist_ok=True)\n",
        "mask_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"LIME分析を開始します。計算に時間がかかります...\")\n",
        "print(f\"ヒートマップ保存先: {heatmap_dir}\")\n",
        "print(f\"AOIマスク保存先: {mask_dir}\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"LIME 生成中\"):\n",
        "    basename = row['image_basename']\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    mask_path = mask_dir / f\"{basename}.png\"\n",
        "\n",
        "    if heatmap_path.exists() and mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    img_path_found = path_map.get(basename)\n",
        "    if not img_path_found:\n",
        "        continue\n",
        "\n",
        "    predicted_class_name = row['Predict']\n",
        "    if pd.isna(predicted_class_name) or predicted_class_name == \"none\":\n",
        "        continue\n",
        "    target_class_idx = CLASS_NAMES.index(predicted_class_name)\n",
        "\n",
        "    try:\n",
        "        img_original = cv2.imread(str(img_path_found))\n",
        "        img_resized = resize_image_with_aspect_ratio(img_original, target_width=640)\n",
        "\n",
        "        lime_analyzer = SimpleLIME(model, device=DEVICE)\n",
        "        lime_map = lime_analyzer.explain(img_resized, target_class_idx, num_samples=50)\n",
        "\n",
        "        original_h, original_w = img_original.shape[:2]\n",
        "        heatmap_resized = cv2.resize(lime_map, (original_w, original_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        overlaid_image = apply_heatmap_to_image(img_original, heatmap_resized)\n",
        "        cv2.imwrite(str(heatmap_path), overlaid_image)\n",
        "\n",
        "        threshold_value = np.percentile(heatmap_resized, 50)\n",
        "        mask = (heatmap_resized >= threshold_value).astype(np.uint8) * 255\n",
        "        cv2.imwrite(str(mask_path), mask)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラー発生: {basename}, Error: {e}\")\n",
        "\n",
        "print(f\"✅ LIMEのヒートマップとAOIマスクの生成が完了しました。\")"
      ],
      "metadata": {
        "id": "B-IRNPaRaReE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4. Occlusion Sensitivityによる分析\n",
        "\n",
        "各画像に対してOcclusion Sensitivity分析を実行し、その結果を「元画像と重ね合わせたヒートマップ」と「評価用のAOIマスク」として、それぞれ専用のフォルダに保存します。"
      ],
      "metadata": {
        "id": "WPVWgHaaaeCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Occlusion Sensitivity分析に必要なクラスと関数\n",
        "class OcclusionSensitivity:\n",
        "    def __init__(self, model, device='cpu'):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.eval()\n",
        "\n",
        "    def analyze(self, img_bgr, target_class, bbox, patch_ratio=0.15, stride_ratio=0.2, batch_size=32):\n",
        "        h, w = img_bgr.shape[:2]\n",
        "\n",
        "        # パッチサイズとストライドを計算\n",
        "        bbox_width = bbox[2] - bbox[0]\n",
        "        bbox_height = bbox[3] - bbox[1]\n",
        "        patch_size = int(min(bbox_width, bbox_height) * patch_ratio)\n",
        "        patch_size = max(20, min(patch_size, 100))\n",
        "        stride = max(1, int(patch_size * stride_ratio))\n",
        "\n",
        "        # 元画像での予測スコアを取得\n",
        "        with torch.no_grad():\n",
        "            img_tensor, _ = preprocess_image(img_bgr, self.device)\n",
        "            base_pred = self.model(img_tensor)[0]\n",
        "            base_score = self._get_class_score(base_pred, target_class)\n",
        "\n",
        "        # 遮蔽する位置のリストを作成\n",
        "        positions = []\n",
        "        for y in range(0, h - patch_size + 1, stride):\n",
        "            for x in range(0, w - patch_size + 1, stride):\n",
        "                positions.append((y, x))\n",
        "\n",
        "        sensitivity_map = np.zeros((h, w), dtype=np.float32)\n",
        "        counts_map = np.zeros((h, w), dtype=np.float32)\n",
        "\n",
        "        for i in tqdm(range(0, len(positions), batch_size), desc=\" Occlusion Batches\", leave=False):\n",
        "            batch_positions = positions[i:i + batch_size]\n",
        "            batch_imgs = [img_bgr.copy() for _ in batch_positions]\n",
        "\n",
        "            for idx, (y, x) in enumerate(batch_positions):\n",
        "                batch_imgs[idx][y:y+patch_size, x:x+patch_size] = 128 # グレーで遮蔽\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_tensor = torch.cat([preprocess_image(img, self.device)[0] for img in batch_imgs])\n",
        "                batch_pred = self.model(batch_tensor)[0]\n",
        "\n",
        "            for idx, (y, x) in enumerate(batch_positions):\n",
        "                score = self._get_class_score(batch_pred[idx:idx+1], target_class)\n",
        "                score_drop = base_score - score\n",
        "                sensitivity_map[y:y+patch_size, x:x+patch_size] += score_drop\n",
        "                counts_map[y:y+patch_size, x:x+patch_size] += 1\n",
        "\n",
        "        # 重複領域を平均化し正規化\n",
        "        sensitivity_map = np.divide(sensitivity_map, counts_map, out=np.zeros_like(sensitivity_map), where=counts_map!=0)\n",
        "        if np.max(sensitivity_map) > np.min(sensitivity_map):\n",
        "            sensitivity_map = (sensitivity_map - np.min(sensitivity_map)) / (np.max(sensitivity_map) - np.min(sensitivity_map))\n",
        "\n",
        "        return sensitivity_map\n",
        "\n",
        "    def _get_class_score(self, prediction, target_class):\n",
        "        pred_nms = yolo_nms(prediction, conf_thres=0.01, iou_thres=IOU_THRES)[0]\n",
        "        if pred_nms is None or len(pred_nms) == 0: return 0.0\n",
        "        class_detections = pred_nms[pred_nms[:, 5] == target_class]\n",
        "        return class_detections[:, 4].max().item() if len(class_detections) > 0 else 0.0\n",
        "\n",
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "path_map = { Path(f).stem: Path(IMAGE_DIR) / f for f in os.listdir(IMAGE_DIR) if Path(f).suffix.lower() in {'.jpg', '.jpeg', '.png'} }\n",
        "print(f\"✅ {len(path_map)}件の画像ファイルをインデックスしました。\")\n",
        "\n",
        "# 出力ディレクトリの準備\n",
        "base_output_dir = Path(OCCLUSION_MASK_DIR)\n",
        "heatmap_dir = base_output_dir / \"heatmaps\"\n",
        "mask_dir = base_output_dir / \"masks\"\n",
        "heatmap_dir.mkdir(parents=True, exist_ok=True)\n",
        "mask_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Occlusion Sensitivity分析を開始します...\")\n",
        "print(f\"ヒートマップ保存先: {heatmap_dir}\")\n",
        "print(f\"AOIマスク保存先: {mask_dir}\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Occlusion Sensitivity 生成中\"):\n",
        "    basename = row['image_basename']\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    mask_path = mask_dir / f\"{basename}.png\"\n",
        "\n",
        "    if heatmap_path.exists() and mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    img_path_found = path_map.get(basename)\n",
        "    if not img_path_found:\n",
        "        continue\n",
        "\n",
        "    predicted_class_name = row['Predict']\n",
        "    if pd.isna(predicted_class_name) or predicted_class_name == \"none\":\n",
        "        continue\n",
        "    target_class_idx = CLASS_NAMES.index(predicted_class_name)\n",
        "\n",
        "    try:\n",
        "        img_original = cv2.imread(str(img_path_found))\n",
        "        img_resized = resize_image_with_aspect_ratio(img_original, target_width=640)\n",
        "\n",
        "        # BBoxを再計算\n",
        "        with torch.no_grad():\n",
        "            pred_tensor, _ = preprocess_image(img_resized, device=DEVICE)\n",
        "            pred = model(pred_tensor)[0]\n",
        "            pred_nms = yolo_nms(pred, conf_thres=CONF_THRES, iou_thres=IOU_THRES)[0]\n",
        "            if pred_nms is None or len(pred_nms) == 0: continue\n",
        "            bbox = pred_nms[0, :4].cpu().numpy()\n",
        "\n",
        "        occlusion_analyzer = OcclusionSensitivity(model, device=DEVICE)\n",
        "        heatmap = occlusion_analyzer.analyze(img_resized, target_class_idx, bbox)\n",
        "\n",
        "        # 元の画像サイズにリサイズ\n",
        "        original_h, original_w = img_original.shape[:2]\n",
        "        heatmap_resized = cv2.resize(heatmap, (original_w, original_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        # 1. ヒートマップ画像を保存\n",
        "        overlaid_image = apply_heatmap_to_image(img_original, heatmap_resized)\n",
        "        cv2.imwrite(str(heatmap_path), overlaid_image)\n",
        "\n",
        "        # 2. AOIマスク画像を保存\n",
        "        threshold_value = np.percentile(heatmap_resized, 50)\n",
        "        mask = (heatmap_resized >= threshold_value).astype(np.uint8) * 255\n",
        "        cv2.imwrite(str(mask_path), mask)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラー発生: {basename}, Error: {e}\")\n",
        "\n",
        "print(f\"✅ Occlusion SensitivityのヒートマップとAOIマスクの生成が完了しました。\")"
      ],
      "metadata": {
        "id": "OhZaw5Viai4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5. RISEによる分析 (比較実験用)"
      ],
      "metadata": {
        "id": "LYUvzsvua2qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RISE分析に必要なクラスと関数 ---\n",
        "\n",
        "def non_max_suppression_multilabel(prediction, conf_thres=0.25, iou_thres=0.45, max_det=300):\n",
        "    \"\"\"マルチラベル対応のNMS。各検出に対して複数クラスの確率を保持します。\"\"\"\n",
        "    nc = prediction.shape[2] - 5\n",
        "    xc = prediction[..., 4] > conf_thres\n",
        "\n",
        "    output = [torch.zeros((0, 6 + nc), device=prediction.device)] * prediction.shape[0]\n",
        "    for xi, x in enumerate(prediction):\n",
        "        x = x[xc[xi]]\n",
        "        if not x.shape[0]:\n",
        "            continue\n",
        "\n",
        "        box = xywh2xyxy(x[:, :4])\n",
        "        x[:, 5:] *= x[:, 4:5]\n",
        "\n",
        "        conf, j = x[:, 5:].max(1, keepdim=True)\n",
        "        x_nms = torch.cat((box, conf, j.float()), 1)\n",
        "\n",
        "        # 信頼度でフィルタリング\n",
        "        x_nms = x_nms[conf.view(-1) > conf_thres]\n",
        "        x = x[conf.view(-1) > conf_thres]\n",
        "        if not x_nms.shape[0]:\n",
        "            continue\n",
        "\n",
        "        c = x_nms[:, 5:6] * 4096\n",
        "        boxes, scores = x_nms[:, :4] + c, x_nms[:, 4]\n",
        "        i = torchvision.ops.nms(boxes, scores, iou_thres)\n",
        "        if i.shape[0] > max_det: i = i[:max_det]\n",
        "\n",
        "        # NMSで選択されたインデックスに対応する元の全クラス情報を保持\n",
        "        output[xi] = torch.cat((x_nms[i, :6], x[i, 5:]), 1)\n",
        "\n",
        "    return output\n",
        "\n",
        "class YOLOV5TorchObjectDetectorML(nn.Module):\n",
        "    \"\"\"RISEのために全クラスの確率を出力するYOLOv5ラッパー\"\"\"\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, img):\n",
        "        prediction, _, _ = self.model(img, augment=False)\n",
        "        return non_max_suppression_multilabel(prediction, conf_thres=0.01, iou_thres=IOU_THRES)\n",
        "\n",
        "class RISE:\n",
        "    def __init__(self, model, input_size=(640, 640), n_masks=1000, p1=0.5, s=16):\n",
        "        self.wrapped_model = YOLOV5TorchObjectDetectorML(model)\n",
        "        self.input_size = input_size\n",
        "        self.n_masks = n_masks\n",
        "        self.p1 = p1\n",
        "        self.s = s\n",
        "        self.masks = self._generate_masks().to(model.device)\n",
        "\n",
        "    def _generate_masks(self):\n",
        "        h = (self.input_size[0] + self.s - 1) // self.s\n",
        "        w = (self.input_size[1] + self.s - 1) // self.s\n",
        "        masks_np = (np.random.rand(self.n_masks, h, w) < self.p1).astype(np.float32)\n",
        "        return torch.from_numpy(masks_np)\n",
        "\n",
        "    def explain(self, img_tensor, target_class_idx, batch_size=50):\n",
        "        saliency = torch.zeros((1, 1, *self.input_size)).to(img_tensor.device)\n",
        "\n",
        "        for i in range(0, self.n_masks, batch_size):\n",
        "            masks_batch = self.masks[i:i + batch_size]\n",
        "            masks_resized = F.interpolate(masks_batch.unsqueeze(1), size=self.input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "            masked_imgs = img_tensor * masks_resized\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = self.wrapped_model(masked_imgs)\n",
        "\n",
        "            for j, p in enumerate(preds):\n",
        "                score = 0.0\n",
        "                if p is not None and len(p) > 0:\n",
        "                    target_probs = p[:, 6 + target_class_idx]\n",
        "                    if len(target_probs) > 0:\n",
        "                        score = target_probs.max().item()\n",
        "                saliency += masks_resized[j] * score\n",
        "\n",
        "        saliency /= self.n_masks\n",
        "        saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-8)\n",
        "        return saliency.squeeze().cpu().numpy()\n",
        "\n",
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "path_map = { Path(f).stem: Path(IMAGE_DIR) / f for f in os.listdir(IMAGE_DIR) if Path(f).suffix.lower() in {'.jpg', '.jpeg', '.png'} }\n",
        "\n",
        "# RISE用の出力ディレクトリを定義\n",
        "RISE_MASK_DIR = os.path.join(BASE_DIR, \"AOI_50_mask_RISE\")\n",
        "base_output_dir = Path(RISE_MASK_DIR)\n",
        "heatmap_dir = base_output_dir / \"heatmaps\"\n",
        "mask_dir = base_output_dir / \"masks\"\n",
        "heatmap_dir.mkdir(parents=True, exist_ok=True)\n",
        "mask_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"RISE分析を開始します。\")\n",
        "print(f\"ヒートマップ保存先: {heatmap_dir}\")\n",
        "print(f\"AOIマスク保存先: {mask_dir}\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"RISE 生成中\"):\n",
        "    basename = row['image_basename']\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    mask_path = mask_dir / f\"{basename}.png\"\n",
        "\n",
        "    if heatmap_path.exists() and mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    img_path_found = path_map.get(basename)\n",
        "    if not img_path_found:\n",
        "        continue\n",
        "\n",
        "    gt_class_name = row['GroundTruth']\n",
        "    if pd.isna(gt_class_name):\n",
        "        continue\n",
        "    target_class_idx = CLASS_NAMES.index(gt_class_name)\n",
        "\n",
        "    try:\n",
        "        img_original = cv2.imread(str(img_path_found))\n",
        "        img_tensor, _ = preprocess_image(img_original, device=DEVICE)\n",
        "\n",
        "        rise_analyzer = RISE(model, n_masks=1000)\n",
        "        heatmap = rise_analyzer.explain(img_tensor, target_class_idx)\n",
        "\n",
        "        original_h, original_w = img_original.shape[:2]\n",
        "        heatmap_resized = cv2.resize(heatmap, (original_w, original_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        overlaid_image = apply_heatmap_to_image(img_original, heatmap_resized)\n",
        "        cv2.imwrite(str(heatmap_path), overlaid_image)\n",
        "\n",
        "        threshold_value = np.percentile(heatmap_resized, 50)\n",
        "        mask = (heatmap_resized >= threshold_value).astype(np.uint8) * 255\n",
        "        cv2.imwrite(str(mask_path), mask)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラー発生: {basename}, Error: {e}\")\n",
        "\n",
        "print(\"✅ RISEのヒートマップとAOIマスクの生成が完了しました。\")"
      ],
      "metadata": {
        "id": "hIyf9cLEa5dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##第3部：評価指標の計算と記録\n"
      ],
      "metadata": {
        "id": "J1HstIqIfNsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.0. 評価用共通関数の定義\n",
        "\n",
        "まず、Pointing GameとIoUの計算で共通して使用するヘルパー関数を定義します。"
      ],
      "metadata": {
        "id": "G_S7pICufPN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_point_from_heatmap(heatmap_path):\n",
        "    \"\"\"保存されたヒートマップ画像から最大値の座標(x, y)を取得する\"\"\"\n",
        "    heatmap_img = cv2.imread(str(heatmap_path), cv2.IMREAD_GRAYSCALE)\n",
        "    if heatmap_img is None:\n",
        "        return None, None\n",
        "\n",
        "    max_idx = np.argmax(heatmap_img)\n",
        "    max_y, max_x = np.unravel_index(max_idx, heatmap_img.shape)\n",
        "\n",
        "    return int(max_x), int(max_y)\n",
        "\n",
        "def calculate_iou(mask1_path, mask2_path):\n",
        "    \"\"\"2つのマスク画像のパスからIoUを計算する\"\"\"\n",
        "    mask1 = cv2.imread(str(mask1_path), cv2.IMREAD_GRAYSCALE)\n",
        "    mask2 = cv2.imread(str(mask2_path), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if mask1 is None or mask2 is None:\n",
        "        return np.nan\n",
        "\n",
        "    # 異なるサイズのマスクはリサイズして合わせる\n",
        "    if mask1.shape != mask2.shape:\n",
        "        mask2 = cv2.resize(mask2, (mask1.shape[1], mask1.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    mask1_bool = mask1 > 128 # 閾値処理\n",
        "    mask2_bool = mask2 > 128 # 閾値処理\n",
        "\n",
        "    intersection = np.logical_and(mask1_bool, mask2_bool).sum()\n",
        "    union = np.logical_or(mask1_bool, mask2_bool).sum()\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "print(\"✅ 評価用共通関数の定義完了\")"
      ],
      "metadata": {
        "id": "heB5H52IfR1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1. GradCAM++の評価指標計算\n",
        "\n",
        "model_23_cv3_convレイヤーの結果を代表として、Pointing GameとIoUを計算し、結果をCSVに保存します。"
      ],
      "metadata": {
        "id": "oCICNOATfbmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "target_layer = \"model_23_cv3_conv\"\n",
        "\n",
        "heatmap_dir = Path(GRADCAM_PP_MASK_DIR) / \"heatmaps\" / target_layer\n",
        "mask_dir = Path(GRADCAM_PP_MASK_DIR) / \"masks\" / target_layer\n",
        "expert_dir = Path(EXPERT_MASK_DIR)\n",
        "\n",
        "print(f\"GradCAM++ ({target_layer}) の評価を開始します...\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"GradCAM++ 評価中\"):\n",
        "    # resume機能: 既に評価済みの場合はスキップ\n",
        "    if pd.notna(row.get('GradCAM++_IoU')):\n",
        "        continue\n",
        "\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    # 必要なファイルのパスを定義\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    aoi_mask_path = mask_dir / f\"{basename}.png\"\n",
        "    expert_mask_path = expert_dir / f\"{basename}.png\"\n",
        "\n",
        "    # 専門家マスクと、評価対象のファイルが存在するかチェック\n",
        "    if not expert_mask_path.exists() or not heatmap_path.exists() or not aoi_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    # 1. Pointing Game\n",
        "    max_x, max_y = get_max_point_from_heatmap(heatmap_path)\n",
        "    if max_x is not None:\n",
        "        expert_mask_img = cv2.imread(str(expert_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        is_hit = 1 if expert_mask_img[max_y, max_x] > 0 else 0\n",
        "\n",
        "        df.loc[index, 'GradCAM++_X'] = max_x\n",
        "        df.loc[index, 'GradCAM++_Y'] = max_y\n",
        "        df.loc[index, 'GradCAM++_pointing_game'] = is_hit\n",
        "\n",
        "    # 2. IoU\n",
        "    iou = calculate_iou(aoi_mask_path, expert_mask_path)\n",
        "    df.loc[index, 'GradCAM++_IoU'] = iou\n",
        "\n",
        "# --- 結果を保存 ---\n",
        "df.to_csv(MAIN_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "print(f\"✅ GradCAM++の評価結果をCSVに保存しました。\")\n",
        "display(df[['image_basename', 'GradCAM++_pointing_game', 'GradCAM++_IoU']].dropna().head())"
      ],
      "metadata": {
        "id": "Oq0E7QSlfdKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. GradCAMの評価指標計算\n",
        "\n",
        "model_23_cv3_convレイヤーの結果を代表として、Pointing GameとIoUを計算し、結果をCSVに保存します。"
      ],
      "metadata": {
        "id": "LjgO3ntCfyrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "target_layer = \"model_23_cv3_conv\"\n",
        "\n",
        "heatmap_dir = Path(GRADCAM_MASK_DIR) / \"heatmaps\" / target_layer\n",
        "mask_dir = Path(GRADCAM_MASK_DIR) / \"masks\" / target_layer\n",
        "expert_dir = Path(EXPERT_MASK_DIR)\n",
        "\n",
        "print(f\"GradCAM ({target_layer}) の評価を開始します...\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"GradCAM 評価中\"):\n",
        "    # resume機能: 既に評価済みの場合はスキップ\n",
        "    if pd.notna(row.get('GradCAM_IoU')):\n",
        "        continue\n",
        "\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    # 必要なファイルのパスを定義\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    aoi_mask_path = mask_dir / f\"{basename}.png\"\n",
        "    expert_mask_path = expert_dir / f\"{basename}.png\"\n",
        "\n",
        "    # 専門家マスクと、評価対象のファイルが存在するかチェック\n",
        "    if not expert_mask_path.exists() or not heatmap_path.exists() or not aoi_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    # 1. Pointing Game\n",
        "    max_x, max_y = get_max_point_from_heatmap(heatmap_path)\n",
        "    if max_x is not None:\n",
        "        expert_mask_img = cv2.imread(str(expert_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        is_hit = 1 if expert_mask_img[max_y, max_x] > 0 else 0\n",
        "\n",
        "        df.loc[index, 'GradCAM_X'] = max_x\n",
        "        df.loc[index, 'GradCAM_Y'] = max_y\n",
        "        df.loc[index, 'GradCAM_pointing_game'] = is_hit\n",
        "\n",
        "    # 2. IoU\n",
        "    iou = calculate_iou(aoi_mask_path, expert_mask_path)\n",
        "    df.loc[index, 'GradCAM_IoU'] = iou\n",
        "\n",
        "# --- 結果を保存 ---\n",
        "df.to_csv(MAIN_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "print(f\"✅ GradCAMの評価結果をCSVに保存しました。\")\n",
        "display(df[['image_basename', 'GradCAM_pointing_game', 'GradCAM_IoU']].dropna().head())"
      ],
      "metadata": {
        "id": "fhFVAqRlf1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3. LIMEの評価指標計算\n",
        "\n",
        "AOI_50_mask_LIMEフォルダに保存されたヒートマップとマスクを使用し、「Pointing Game」と「IoU」を計算してCSVに保存します。"
      ],
      "metadata": {
        "id": "F0uRKS3YgCBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "\n",
        "heatmap_dir = Path(LIME_MASK_DIR) / \"heatmaps\"\n",
        "mask_dir = Path(LIME_MASK_DIR) / \"masks\"\n",
        "expert_dir = Path(EXPERT_MASK_DIR)\n",
        "\n",
        "print(f\"LIME の評価を開始します...\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"LIME 評価中\"):\n",
        "    # resume機能: 既に評価済みの場合はスキップ\n",
        "    if pd.notna(row.get('LIME_IoU')):\n",
        "        continue\n",
        "\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    # 必要なファイルのパスを定義\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    aoi_mask_path = mask_dir / f\"{basename}.png\"\n",
        "    expert_mask_path = expert_dir / f\"{basename}.png\"\n",
        "\n",
        "    # 専門家マスクと、評価対象のファイルが存在するかチェック\n",
        "    if not expert_mask_path.exists() or not heatmap_path.exists() or not aoi_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    # 1. Pointing Game\n",
        "    max_x, max_y = get_max_point_from_heatmap(heatmap_path)\n",
        "    if max_x is not None:\n",
        "        expert_mask_img = cv2.imread(str(expert_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        # 座標がマスクの範囲内にあるか確認\n",
        "        if max_y < expert_mask_img.shape[0] and max_x < expert_mask_img.shape[1]:\n",
        "            is_hit = 1 if expert_mask_img[max_y, max_x] > 0 else 0\n",
        "        else:\n",
        "            is_hit = 0 # 座標が範囲外の場合はヒットしない\n",
        "\n",
        "        df.loc[index, 'LIME_X'] = max_x\n",
        "        df.loc[index, 'LIME_Y'] = max_y\n",
        "        df.loc[index, 'LIME_pointing_game'] = is_hit\n",
        "\n",
        "    # 2. IoU\n",
        "    iou = calculate_iou(aoi_mask_path, expert_mask_path)\n",
        "    df.loc[index, 'LIME_IoU'] = iou\n",
        "\n",
        "# --- 結果を保存 ---\n",
        "df.to_csv(MAIN_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "print(f\"✅ LIMEの評価結果をCSVに保存しました。\")\n",
        "display(df[['image_basename', 'LIME_pointing_game', 'LIME_IoU']].dropna().head())"
      ],
      "metadata": {
        "id": "5SKKy5tjgDj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4. Occlusion Sensitivityの評価指標計算\n",
        "\n",
        "AOI_50_mask_Occlusion_sensitivityフォルダに保存されたヒートマップとマスクを使用し、「Pointing Game」と「IoU」を計算してCSVに保存します。"
      ],
      "metadata": {
        "id": "ig8pa5xogGZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "\n",
        "heatmap_dir = Path(OCCLUSION_MASK_DIR) / \"heatmaps\"\n",
        "mask_dir = Path(OCCLUSION_MASK_DIR) / \"masks\"\n",
        "expert_dir = Path(EXPERT_MASK_DIR)\n",
        "\n",
        "print(f\"Occlusion Sensitivity の評価を開始します...\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Occlusion Sensitivity 評価中\"):\n",
        "    # resume機能: 既に評価済みの場合はスキップ\n",
        "    if pd.notna(row.get('Occlusion_IoU')):\n",
        "        continue\n",
        "\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    # 必要なファイルのパスを定義\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    aoi_mask_path = mask_dir / f\"{basename}.png\"\n",
        "    expert_mask_path = expert_dir / f\"{basename}.png\"\n",
        "\n",
        "    # 専門家マスクと、評価対象のファイルが存在するかチェック\n",
        "    if not expert_mask_path.exists() or not heatmap_path.exists() or not aoi_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    # 1. Pointing Game\n",
        "    max_x, max_y = get_max_point_from_heatmap(heatmap_path)\n",
        "    if max_x is not None:\n",
        "        expert_mask_img = cv2.imread(str(expert_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        # 座標がマスクの範囲内にあるか確認\n",
        "        if max_y < expert_mask_img.shape[0] and max_x < expert_mask_img.shape[1]:\n",
        "            is_hit = 1 if expert_mask_img[max_y, max_x] > 0 else 0\n",
        "        else:\n",
        "            is_hit = 0 # 座標が範囲外の場合はヒットしない\n",
        "\n",
        "        df.loc[index, 'Occlusion_X'] = max_x\n",
        "        df.loc[index, 'Occlusion_Y'] = max_y\n",
        "        df.loc[index, 'Occlusion_pointing_game'] = is_hit\n",
        "\n",
        "    # 2. IoU\n",
        "    iou = calculate_iou(aoi_mask_path, expert_mask_path)\n",
        "    df.loc[index, 'Occlusion_IoU'] = iou\n",
        "\n",
        "# --- 結果を保存 ---\n",
        "df.to_csv(MAIN_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "print(f\"✅ Occlusion Sensitivityの評価結果をCSVに保存しました。\")\n",
        "display(df[['image_basename', 'Occlusion_pointing_game', 'Occlusion_IoU']].dropna().head())"
      ],
      "metadata": {
        "id": "NlqRbQRmgG0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.5. RISEの評価指標計算\n",
        "\n",
        "AOI_50_mask_RISEフォルダに保存されたヒートマップとマスクを使用し、「Pointing Game」と「IoU」を計算してCSVに保存します。"
      ],
      "metadata": {
        "id": "pwmD9URdgW_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン処理 ---\n",
        "df = pd.read_csv(MAIN_CSV_PATH)\n",
        "\n",
        "heatmap_dir = Path(RISE_MASK_DIR) / \"heatmaps\"\n",
        "mask_dir = Path(RISE_MASK_DIR) / \"masks\"\n",
        "expert_dir = Path(EXPERT_MASK_DIR)\n",
        "\n",
        "print(f\"RISE の評価を開始します...\")\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"RISE 評価中\"):\n",
        "    # resume機能: 既に評価済みの場合はスキップ\n",
        "    if pd.notna(row.get('RISE_IoU')):\n",
        "        continue\n",
        "\n",
        "    basename = row['image_basename']\n",
        "\n",
        "    # 必要なファイルのパスを定義\n",
        "    heatmap_path = heatmap_dir / f\"{basename}.jpg\"\n",
        "    aoi_mask_path = mask_dir / f\"{basename}.png\"\n",
        "    expert_mask_path = expert_dir / f\"{basename}.png\"\n",
        "\n",
        "    # 専門家マスクと、評価対象のファイルが存在するかチェック\n",
        "    if not expert_mask_path.exists() or not heatmap_path.exists() or not aoi_mask_path.exists():\n",
        "        continue\n",
        "\n",
        "    # 1. Pointing Game\n",
        "    max_x, max_y = get_max_point_from_heatmap(heatmap_path)\n",
        "    if max_x is not None:\n",
        "        expert_mask_img = cv2.imread(str(expert_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        # 座標がマスクの範囲内にあるか確認\n",
        "        if max_y < expert_mask_img.shape[0] and max_x < expert_mask_img.shape[1]:\n",
        "            is_hit = 1 if expert_mask_img[max_y, max_x] > 0 else 0\n",
        "        else:\n",
        "            is_hit = 0 # 座標が範囲外の場合はヒットしない\n",
        "\n",
        "        df.loc[index, 'RISE_X'] = max_x\n",
        "        df.loc[index, 'RISE_Y'] = max_y\n",
        "        df.loc[index, 'RISE_pointing_game'] = is_hit\n",
        "\n",
        "    # 2. IoU\n",
        "    iou = calculate_iou(aoi_mask_path, expert_mask_path)\n",
        "    df.loc[index, 'RISE_IoU'] = iou\n",
        "\n",
        "# --- 結果を保存 ---\n",
        "df.to_csv(MAIN_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "print(f\"✅ RISEの評価結果をCSVに保存しました。\")\n",
        "display(df[['image_basename', 'RISE_pointing_game', 'RISE_IoU']].dropna().head())"
      ],
      "metadata": {
        "id": "SIuqGSaYgaV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##第4部：Cut & Paste実験\n",
        "\n",
        "角膜領域を別の画像に移植し、モデルが背景の変化に対してどれだけ頑健であるかを評価します。"
      ],
      "metadata": {
        "id": "EKVYBzL-gcvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1. 実験用CSVの作成 (Ueno_Mix1039_cutmix.csv)\n",
        "\n",
        "まず、移植元（cornea）と移植先（background）の画像の組み合わせを網羅したCSVファイルを作成します。ここでは、元論文のコードにあったUeno_Mix1039_over90.csvという高画質な画像リストを基に作成するロジックを再現します。\n",
        "\n",
        "【注意】 この処理を実行する前に、Ueno_Mix1039_over90.csvがBASE_DIRに存在するかご確認ください。"
      ],
      "metadata": {
        "id": "FaMVUjfqgv8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.1. 実験ペアリストの作成 ---\n",
        "\n",
        "# 高画質リストとされるCSVを読み込む\n",
        "try:\n",
        "    source_csv_path = os.path.join(BASE_DIR, \"Ueno_Mix1039_over90.csv\")\n",
        "    df_quality = pd.read_csv(source_csv_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"エラー: {source_csv_path} が見つかりません。このセルはスキップされます。\")\n",
        "    df_quality = None\n",
        "\n",
        "if df_quality is not None:\n",
        "    # 画質が良いものだけを抽出\n",
        "    df_high_quality = df_quality[df_quality[\"Image_quality\"] == 1].copy()\n",
        "\n",
        "    # 背景用と角膜用のDataFrameを準備\n",
        "    df_bg = df_high_quality[['image_basename']].rename(columns={\"image_basename\": \"background_basename\"})\n",
        "    df_cornea = df_high_quality[['image_basename']].rename(columns={\"image_basename\": \"cornea_basename\"})\n",
        "\n",
        "    # 全ての組み合わせ（デカルト積）を作成\n",
        "    df_bg['key'] = 1\n",
        "    df_cornea['key'] = 1\n",
        "    cutmix_df = pd.merge(df_bg, df_cornea, on='key').drop('key', axis=1)\n",
        "\n",
        "    # 予測結果を格納する空の列を追加\n",
        "    cutmix_df['cornea_pred'] = pd.NA\n",
        "    cutmix_df['cutmix_pred'] = pd.NA\n",
        "\n",
        "    # CSVとして保存\n",
        "    cutmix_df.to_csv(CUTMIX_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"✅ Cut & Paste実験用のペアリストを作成しました。\")\n",
        "    print(f\"   - 保存先: {CUTMIX_CSV_PATH}\")\n",
        "    print(f\"   - 総ペア数: {len(cutmix_df)}\")\n",
        "    display(cutmix_df.head())"
      ],
      "metadata": {
        "id": "C9Lsz9eDgvWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2. & 4.3. Cut & Pasteの実行と推論\n",
        "\n",
        "4.1で作成したペアリストに基づき、実際に角膜領域の切り貼りを行い、合成画像に対してAIの推論を実行します。処理に時間がかかるため、100件ごとに中間保存を行います。"
      ],
      "metadata": {
        "id": "p1YREbhGg5Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.2 & 4.3. 画像合成、推論、結果の記録 ---\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def get_ellipse_from_xml(xml_path, image_name):\n",
        "    \"\"\"XMLファイルから楕円情報を取得\"\"\"\n",
        "    # 毎回ファイルをパースするのは非効率なため、初回のみパース結果をキャッシュする\n",
        "    if not hasattr(get_ellipse_from_xml, 'root'):\n",
        "        try:\n",
        "            tree = ET.parse(xml_path)\n",
        "            get_ellipse_from_xml.root = tree.getroot()\n",
        "        except FileNotFoundError:\n",
        "            get_ellipse_from_xml.root = None\n",
        "            return None\n",
        "\n",
        "    if get_ellipse_from_xml.root is None:\n",
        "        return None\n",
        "\n",
        "    for image_node in get_ellipse_from_xml.root.findall('.//image'):\n",
        "        if image_node.get('name') == image_name:\n",
        "            ellipse_node = image_node.find('ellipse')\n",
        "            if ellipse_node is not None:\n",
        "                return {k: float(v) for k, v in ellipse_node.attrib.items()}\n",
        "    return None\n",
        "\n",
        "def affine_transplant(src_img, tgt_img, src_ellipse, tgt_ellipse):\n",
        "    \"\"\"アフィン変換を用いて角膜を移植する\"\"\"\n",
        "    def get_transform_points(e):\n",
        "        angle_rad = np.deg2rad(e.get('rotation', 0))\n",
        "        cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
        "        cx, cy, rx, ry = e['cx'], e['cy'], e['rx'], e['ry']\n",
        "        return np.float32([\n",
        "            [cx, cy],\n",
        "            [cx + rx * cos_a, cy + rx * sin_a],\n",
        "            [cx - ry * sin_a, cy + ry * cos_a]\n",
        "        ])\n",
        "\n",
        "    M = cv2.getAffineTransform(get_transform_points(src_ellipse), get_transform_points(tgt_ellipse))\n",
        "    warped = cv2.warpAffine(src_img, M, (tgt_img.shape[1], tgt_img.shape[0]))\n",
        "\n",
        "    mask = np.zeros(tgt_img.shape[:2], dtype=np.uint8)\n",
        "    cv2.ellipse(mask,\n",
        "                (int(tgt_ellipse['cx']), int(tgt_ellipse['cy'])),\n",
        "                (int(tgt_ellipse['rx']), int(tgt_ellipse['ry'])),\n",
        "                tgt_ellipse.get('rotation', 0), 0, 360, 255, -1)\n",
        "\n",
        "    # 境界をぼかして自然に合成\n",
        "    mask_blurred = cv2.GaussianBlur(mask, (21, 21), 10)\n",
        "    mask_3ch = cv2.cvtColor(mask_blurred, cv2.COLOR_GRAY2BGR).astype('float32') / 255.0\n",
        "\n",
        "    return ((mask_3ch * warped) + ((1 - mask_3ch) * tgt_img)).astype(np.uint8)\n",
        "\n",
        "# --- Main Execution Loop ---\n",
        "try:\n",
        "    df_cutmix = pd.read_csv(CUTMIX_CSV_PATH)\n",
        "\n",
        "    # 未処理の行のみを対象にする\n",
        "    to_process = df_cutmix[df_cutmix['cutmix_pred'].isna()]\n",
        "    print(f\"Cut & Paste推論を開始します。対象ペア数: {len(to_process)} / {len(df_cutmix)}\")\n",
        "\n",
        "    for index, row in tqdm(to_process.iterrows(), total=len(to_process), desc=\"Cut & Paste 推論中\"):\n",
        "        cornea_path = path_map.get(row['cornea_basename'])\n",
        "        bg_path = path_map.get(row['background_basename'])\n",
        "\n",
        "        if not cornea_path or not bg_path:\n",
        "            continue\n",
        "\n",
        "        cornea_ellipse = get_ellipse_from_xml(XML_ANNOTATION_PATH, cornea_path.name)\n",
        "        bg_ellipse = get_ellipse_from_xml(XML_ANNOTATION_PATH, bg_path.name)\n",
        "\n",
        "        if not cornea_ellipse or not bg_ellipse:\n",
        "            df_cutmix.loc[index, 'cutmix_pred'] = 'no_ellipse'\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # 合成画像を作成して推論\n",
        "            src_img = cv2.imread(str(cornea_path))\n",
        "            tgt_img = cv2.imread(str(bg_path))\n",
        "            cutmix_img = affine_transplant(src_img, tgt_img, cornea_ellipse, bg_ellipse)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                img_tensor, _ = preprocess_image(cutmix_img, device=DEVICE)\n",
        "                pred = model(img_tensor)[0]\n",
        "                pred_nms = yolo_nms(pred, conf_thres=CONF_THRES, iou_thres=IOU_THRES)[0]\n",
        "\n",
        "                if pred_nms is not None and len(pred_nms) > 0:\n",
        "                    pred_class_idx = int(pred_nms[0][5])\n",
        "                    df_cutmix.loc[index, 'cutmix_pred'] = CLASS_NAMES[pred_class_idx]\n",
        "                else:\n",
        "                    df_cutmix.loc[index, 'cutmix_pred'] = 'none'\n",
        "\n",
        "            # 100件ごとに中間保存\n",
        "            if (index + 1) % 100 == 0:\n",
        "                df_cutmix.to_csv(CUTMIX_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"エラー発生: {row['cornea_basename']} -> {row['background_basename']}, Error: {e}\")\n",
        "            df_cutmix.loc[index, 'cutmix_pred'] = 'error'\n",
        "\n",
        "    # 最終保存\n",
        "    df_cutmix.to_csv(CUTMIX_CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "    print(f\"✅ Cut & Paste実験の推論が完了しました。\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Cut & Paste実験用CSVが存在しないため、このセルはスキップされました。\")"
      ],
      "metadata": {
        "id": "cn-sh55DhANh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##第5部：追加分析とデータ整理"
      ],
      "metadata": {
        "id": "0UQFbaBAhMEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1. AI検出AOI_50と専門家マスクの一致率計算 (expert_ratio)\n",
        "\n",
        "AIが物体として認識した領域（バウンディングボックス）が、専門家が重要だと判断した領域（エキスパートマスク）とどの程度重なっているかを評価します。この指標は、AIが「どこを見ているか」と専門家の判断が一致しているかを示します。"
      ],
      "metadata": {
        "id": "msfiGU39hOCa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kEb0sFQhhSwL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}