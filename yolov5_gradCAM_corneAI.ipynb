{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3e1XGuuST+KxXaL2eqGh8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CorneAI/blob/main/yolov5_gradCAM_corneAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d42M6k9QpvSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5_GradCAM_CorneAI**\n",
        "\n",
        "https://github.com/pooya-mohammadi/yolov5-gradcam"
      ],
      "metadata": {
        "id": "2cakhs2BZLRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup YOLOv5**"
      ],
      "metadata": {
        "id": "ytBOWsuXZQzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7oJE1rLrE_4",
        "outputId": "5621b961-7008-4cea-f72d-97b38932438c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p48tU-_wYVHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f1912c-0b46-484e-9476-9f428b83dc3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[33mWARNING: Skipping deep_utils as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/pooya-mohammadi/deep_utils.git\n",
            "  Cloning https://github.com/pooya-mohammadi/deep_utils.git to /tmp/pip-req-build-x903ab2k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pooya-mohammadi/deep_utils.git /tmp/pip-req-build-x903ab2k\n",
            "  Resolved https://github.com/pooya-mohammadi/deep_utils.git to commit af444c93a14ba0853ec302d86a7aef63534647cc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from deep-utils==1.3.30) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deep-utils==1.3.30) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from deep-utils==1.3.30) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deep-utils==1.3.30) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deep-utils==1.3.30) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deep-utils==1.3.30) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deep-utils==1.3.30) (2024.6.2)\n",
            "Building wheels for collected packages: deep-utils\n",
            "  Building wheel for deep-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-utils: filename=deep_utils-1.3.30-py3-none-any.whl size=534934 sha256=c0196b1202b44f9d1f35f351e1023409880a6787b728b6a890d5e4e4ad63bfc7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i677vr1u/wheels/8f/0a/f4/5e2b92d9573699e3e30ce319a4b06218eb281695935d0b8b54\n",
            "Successfully built deep-utils\n",
            "Installing collected packages: deep-utils\n",
            "Successfully installed deep-utils-1.3.30\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.10.0.82-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "Successfully installed opencv-python-4.10.0.82\n",
            "[INFO] To use new installed version of opencv, the session should be restarted!!!!\n",
            "Cloning into 'yolov5-gradcam'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 134 (delta 29), reused 36 (delta 13), pack-reused 68\u001b[K\n",
            "Receiving objects: 100% (134/134), 6.95 MiB | 13.97 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!pip uninstall deep_utils -y\n",
        "!pip install -U git+https://github.com/pooya-mohammadi/deep_utils.git\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install -U opencv-python\n",
        "print(\"[INFO] To use new installed version of opencv, the session should be restarted!!!!\")\n",
        "\n",
        "!git clone https://github.com/pooya-mohammadi/yolov5-gradcam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/yolov5-gradcam')\n",
        "\n",
        "model_path = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial/3.jpg\""
      ],
      "metadata": {
        "id": "wkvc2KijYes5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python main.py --model-path $model_path --img-path $img_path --output-dir out"
      ],
      "metadata": {
        "id": "cjgRkuSuYinZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Top3 analysis**"
      ],
      "metadata": {
        "id": "wvBLe9pbpCwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "img_dir = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "img_dir = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit\"\n",
        "print(len(os.listdir(img_dir)))"
      ],
      "metadata": {
        "id": "GWizQkPAjczd",
        "outputId": "4b491509-f628-447c-f61c-fd18f4e8e736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN98dpHRuyNV",
        "outputId": "6a174612-c5a4-470e-a7ec-577534a8946b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################\n",
        "#################\n",
        "\n",
        "import numpy as np\n",
        "from deep_utils.utils.box_utils.boxes import Box\n",
        "import torch\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import xywh2xyxy\n",
        "from utils.datasets import letterbox\n",
        "import cv2\n",
        "import time\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from utils.metrics import box_iou\n",
        "\n",
        "class YOLOV5TorchObjectDetector(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_weight,\n",
        "                 device,\n",
        "                 img_size,\n",
        "                 names=None,\n",
        "                 mode='eval',\n",
        "                 confidence=0.25,\n",
        "                 iou_thresh=0.45,\n",
        "                 agnostic_nms=False):\n",
        "        super(YOLOV5TorchObjectDetector, self).__init__()\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.img_size = img_size\n",
        "        self.mode = mode\n",
        "        self.confidence = confidence\n",
        "        self.iou_thresh = iou_thresh\n",
        "        self.agnostic = agnostic_nms\n",
        "        self.model = attempt_load(model_weight, device=device)\n",
        "        print(\"[INFO] Model is loaded\")\n",
        "        self.model.requires_grad_(True)\n",
        "        self.model.to(device)\n",
        "        if self.mode == 'train':\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "        # fetch the names\n",
        "        if names is None:\n",
        "            print('[INFO] fetching names from coco file')\n",
        "            self.names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
        "                          'traffic light',\n",
        "                          'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
        "                          'cow',\n",
        "                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase',\n",
        "                          'frisbee',\n",
        "                          'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "                          'surfboard',\n",
        "                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "                          'apple',\n",
        "                          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
        "                          'couch',\n",
        "                          'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "                          'keyboard', 'cell phone',\n",
        "                          'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "                          'teddy bear',\n",
        "                          'hair drier', 'toothbrush']\n",
        "        else:\n",
        "            self.names = names\n",
        "\n",
        "        # preventing cold start\n",
        "        img = torch.zeros((1, 3, *self.img_size), device=device)\n",
        "        self.model(img)\n",
        "\n",
        "    @staticmethod\n",
        "    def non_max_suppression(prediction, logits, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False,\n",
        "                            multi_label=False, labels=(), max_det=300):\n",
        "        \"\"\"Runs Non-Maximum Suppression (NMS) on inference and logits results\n",
        "\n",
        "        Returns:\n",
        "             list of detections, on (n,6) tensor per image [xyxy, conf, cls] and pruned input logits (n, number-classes)\n",
        "        \"\"\"\n",
        "\n",
        "        nc = prediction.shape[2] - 5  # number of classes\n",
        "        xc = prediction[..., 4] > conf_thres  # candidates\n",
        "\n",
        "        # Checks\n",
        "        assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
        "        assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
        "\n",
        "        # Settings\n",
        "        min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
        "        max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
        "        time_limit = 10.0  # seconds to quit after\n",
        "        redundant = True  # require redundant detections\n",
        "        multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
        "        merge = False  # use merge-NMS\n",
        "\n",
        "        t = time.time()\n",
        "        output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
        "        logits_output = [torch.zeros((0, 80), device=logits.device)] * logits.shape[0]\n",
        "        for xi, (x, log_) in enumerate(zip(prediction, logits)):  # image index, image inference\n",
        "            # Apply constraints\n",
        "            # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
        "            x = x[xc[xi]]  # confidence\n",
        "            log_ = log_[xc[xi]]\n",
        "            # Cat apriori labels if autolabelling\n",
        "            if labels and len(labels[xi]):\n",
        "                l = labels[xi]\n",
        "                v = torch.zeros((len(l), nc + 5), device=x.device)\n",
        "                v[:, :4] = l[:, 1:5]  # box\n",
        "                v[:, 4] = 1.0  # conf\n",
        "                v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
        "                x = torch.cat((x, v), 0)\n",
        "\n",
        "            # If none remain process next image\n",
        "            if not x.shape[0]:\n",
        "                continue\n",
        "\n",
        "            # Compute conf\n",
        "            x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
        "            # log_ *= x[:, 4:5]\n",
        "            # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
        "            box = xywh2xyxy(x[:, :4])\n",
        "\n",
        "            # Detections matrix nx6 (xyxy, conf, cls)\n",
        "            if multi_label:\n",
        "                i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
        "                x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
        "            else:  # best class only\n",
        "                conf, j = x[:, 5:].max(1, keepdim=True)\n",
        "                # log_ = x[:, 5:]\n",
        "                x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
        "                log_ = log_[conf.view(-1) > conf_thres]\n",
        "            # Filter by class\n",
        "            if classes is not None:\n",
        "                x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
        "\n",
        "            # Check shape\n",
        "            n = x.shape[0]  # number of boxes\n",
        "            if not n:  # no boxes\n",
        "                continue\n",
        "            elif n > max_nms:  # excess boxes\n",
        "                x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
        "\n",
        "            # Batched NMS\n",
        "            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
        "            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
        "            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
        "            if i.shape[0] > max_det:  # limit detections\n",
        "                i = i[:max_det]\n",
        "            if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
        "                # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
        "                iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
        "                weights = iou * scores[None]  # box weights\n",
        "                x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
        "                if redundant:\n",
        "                    i = i[iou.sum(1) > 1]  # require redundancy\n",
        "\n",
        "            output[xi] = x[i]\n",
        "            logits_output[xi] = log_[i]\n",
        "            assert log_[i].shape[0] == x[i].shape[0]\n",
        "            if (time.time() - t) > time_limit:\n",
        "                print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
        "                break  # time limit exceeded\n",
        "\n",
        "        return output, logits_output\n",
        "\n",
        "    @staticmethod\n",
        "    def yolo_resize(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True):\n",
        "\n",
        "        return letterbox(img, new_shape=new_shape, color=color, auto=auto, scaleFill=scaleFill, scaleup=scaleup)\n",
        "\n",
        "    def forward(self, img):\n",
        "        prediction, logits, _ = self.model(img, augment=False)\n",
        "        prediction, logits = self.non_max_suppression(prediction, logits, self.confidence, self.iou_thresh,\n",
        "                                                      classes=None,\n",
        "                                                      agnostic=self.agnostic)\n",
        "        self.boxes, self.class_names, self.classes, self.confidences = [[[] for _ in range(img.shape[0])] for _ in\n",
        "                                                                        range(4)]\n",
        "        for i, det in enumerate(prediction):  # detections per image\n",
        "            if len(det):\n",
        "                for *xyxy, conf, cls in det:\n",
        "                    # xyxyの値を修正\n",
        "                    xyxy[0] = max(0, xyxy[0])\n",
        "                    xyxy[1] = max(0, xyxy[1])\n",
        "                    xyxy[2] = min(img_size, xyxy[2])\n",
        "                    xyxy[3] = min(img_size, xyxy[3])\n",
        "\n",
        "                    bbox = Box.box2box(xyxy,\n",
        "                                       in_source=Box.BoxSource.Torch,\n",
        "                                       to_source=Box.BoxSource.Numpy,\n",
        "                                       return_int=True)\n",
        "                    self.boxes[i].append(bbox)\n",
        "                    self.confidences[i].append(round(conf.item(), 2))\n",
        "                    cls = int(cls.item())\n",
        "                    self.classes[i].append(cls)\n",
        "                    if self.names is not None:\n",
        "                        self.class_names[i].append(self.names[cls])\n",
        "                    else:\n",
        "                        self.class_names[i].append(cls)\n",
        "        return [self.boxes, self.classes, self.class_names, self.confidences], logits\n",
        "\n",
        "    def preprocessing(self, img):\n",
        "        if len(img.shape) != 4:\n",
        "            img = np.expand_dims(img, axis=0)\n",
        "        im0 = img.astype(np.uint8)\n",
        "        img = np.array([self.yolo_resize(im, new_shape=self.img_size)[0] for im in im0])\n",
        "        img = img.transpose((0, 3, 1, 2))\n",
        "        img = np.ascontiguousarray(img)\n",
        "        img = torch.from_numpy(img).to(self.device)\n",
        "        img = img / 255.0\n",
        "        return img\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMIlXO_mIun8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "# from models.gradcam import YOLOV5GradCAM\n",
        "#from models.yolo_v5_object_detector import YOLOV5TorchObjectDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from deep_utils import Box, split_extension\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "# パラメータ\n",
        "model_path = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "#img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial/99.jpg\"\n",
        "#output_dir = 'out'  # 出力ディレクトリ\n",
        "output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'  # 出力ディレクトリ\n",
        "img_size = 640  # 入力画像サイズ\n",
        "target_layer = 'model_23_cv3_act'  # GradCAM を適用するレイヤー\n",
        "#target_layer = 'model_23_m_0_cv2_act'  # GradCAM を適用するレイヤー\n",
        "#target_layer = 'model_24_m_2'  # GradCAM を適用するレイヤー\n",
        "method = 'gradcam'  # 'gradcam' または 'gradcampp'\n",
        "device = 'cpu'  # 'cuda' または 'cpu'\n",
        "\n",
        "# クラス名リストを指定\n",
        "names = [\"infection\",\"normal\",\"non-infection\",\"scar\",\"tumor\",\"deposit\",\"APAC\",\"lens opacity\",\"bullous\"]\n",
        "\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_res_img(bbox, masks, res_img):\n",
        "    for mask in masks:\n",
        "        mask = mask.squeeze().mul(255).add_(0.5).clamp_(0, 255).detach().cpu().numpy().astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
        "        n_heatmat = (Box.fill_outer_box(heatmap, bbox) / 255).astype(np.float32)\n",
        "        res_img = res_img / 255\n",
        "        res_img = cv2.add(res_img, n_heatmat)\n",
        "        res_img = (res_img / res_img.max())\n",
        "    return res_img, n_heatmat\n",
        "\n",
        "def put_text_box(bbox, cls_name, res_img):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    # this is a bug in cv2. It does not put box on a converted image from torch unless it's buffered and read again!\n",
        "    cv2.imwrite('temp.jpg', (res_img * 255).astype(np.uint8))\n",
        "    res_img = cv2.imread('temp.jpg')\n",
        "    res_img = Box.put_box(res_img, bbox)\n",
        "\n",
        "    # Set the font size and other parameters\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 2.0\n",
        "    color = (0, 255, 0)  # Green color in BGR format\n",
        "    thickness = 2\n",
        "\n",
        "    # Calculate the text size and position\n",
        "    text_size, _ = cv2.getTextSize(cls_name, font, font_scale, thickness)\n",
        "    text_x = 10  # Adjust the horizontal position to place the text near the left edge\n",
        "    text_y = text_size[1] + 10  # Adjust the vertical position to place the text near the top edge\n",
        "\n",
        "    # Put the text on the image\n",
        "    cv2.putText(res_img, cls_name, (text_x, text_y), font, font_scale, color, thickness)\n",
        "\n",
        "    return res_img\n",
        "\n",
        "def concat_images(images):\n",
        "    w, h = images[0].shape[:2]\n",
        "    width = w\n",
        "    height = h * len(images)\n",
        "    base_img = np.zeros((width, height, 3), dtype=np.uint8)\n",
        "    for i, img in enumerate(images):\n",
        "        base_img[:, h * i:h * (i + 1), ...] = img\n",
        "    return base_img\n",
        "def find_yolo_layer(model, layer_name):\n",
        "    \"\"\"Find yolov5 layer to calculate GradCAM and GradCAM++\n",
        "\n",
        "    Args:\n",
        "        model: yolov5 model.\n",
        "        layer_name (str): the name of layer with its hierarchical information.\n",
        "\n",
        "    Return:\n",
        "        target_layer: found layer\n",
        "    \"\"\"\n",
        "    hierarchy = layer_name.split('_')\n",
        "    target_layer = model.model._modules[hierarchy[0]]\n",
        "\n",
        "    for h in hierarchy[1:]:\n",
        "        target_layer = target_layer._modules[h]\n",
        "    return target_layer\n",
        "\n",
        "\n",
        "class YOLOV5GradCAM:\n",
        "    def __init__(self, model, layer_name, img_size=(640, 640)):\n",
        "        self.model = model\n",
        "        self.gradients = dict()\n",
        "        self.activations = dict()\n",
        "        self.cls_names = []  # 追加: Top1~3のクラス名を保存するリスト\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients['value'] = grad_output[0]\n",
        "            return None\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations['value'] = output\n",
        "            return None\n",
        "\n",
        "        target_layer = find_yolo_layer(self.model, layer_name)\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        device = 'cuda' if next(self.model.model.parameters()).is_cuda else 'cpu'\n",
        "        self.model(torch.zeros(1, 3, *img_size, device=device))\n",
        "        # print('[INFO] saliency_map size :', self.activations['value'].shape[2:])\n",
        "\n",
        "    def forward(self, input_img, class_idx=True):\n",
        "        saliency_maps = []\n",
        "        b, c, h, w = input_img.size()\n",
        "        tic = time.time()\n",
        "        preds, logits = self.model(input_img)\n",
        "        # print(\"[INFO] model-forward took: \", round(time.time() - tic, 4), 'seconds')\n",
        "\n",
        "        _, top3_indices = torch.topk(logits[0], k=3)\n",
        "\n",
        "        if top3_indices.numel() > 0:\n",
        "            preds[1][0] = top3_indices.tolist()[0]\n",
        "            preds[2][0] = [names[i] for i in preds[1][0]]\n",
        "            self.cls_names = preds[2][0]  # 修正: Top1~3のクラス名を保存\n",
        "        else:\n",
        "            self.cls_names = []  # top3_indicesが空の場合は空のリストを代入\n",
        "\n",
        "        for cls, cls_name in zip(preds[1][0], preds[2][0]):\n",
        "            if class_idx:\n",
        "                score = logits[0][0][cls]\n",
        "            else:\n",
        "                score = logits[0][0].max()\n",
        "            self.model.zero_grad()\n",
        "            tic = time.time()\n",
        "            score.backward(retain_graph=True)\n",
        "            # print(f\"[INFO] {cls_name}, model-backward took: \", round(time.time() - tic, 4), 'seconds')\n",
        "            gradients = self.gradients['value']\n",
        "            activations = self.activations['value']\n",
        "            b, k, u, v = gradients.size()\n",
        "            alpha = gradients.view(b, k, -1).mean(2)\n",
        "            weights = alpha.view(b, k, 1, 1)\n",
        "            saliency_map = (weights * activations).sum(1, keepdim=True)\n",
        "            saliency_map = F.relu(saliency_map)\n",
        "            saliency_map = F.upsample(saliency_map, size=(h, w), mode='bilinear', align_corners=False)\n",
        "            saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
        "            saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
        "            saliency_maps.append(saliency_map)\n",
        "\n",
        "        return saliency_maps, logits, preds, self.cls_names\n",
        "\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "        return self.forward(input_img)\n",
        "\n",
        "def main(img_path):\n",
        "   input_size = (img_size, img_size)\n",
        "   img = cv2.imread(img_path)\n",
        "  #  print('[INFO] Loading the model')\n",
        "   model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size,\n",
        "                                     names=names)\n",
        "   torch_img = model.preprocessing(img[..., ::-1])\n",
        "   if method == 'gradcam':\n",
        "       saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "   tic = time.time()\n",
        "   masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "   print(\"total time:\", round(time.time() - tic, 4))\n",
        "   result = torch_img.squeeze(0).mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).detach().cpu().numpy()\n",
        "   result = result[..., ::-1]  # convert to bgr\n",
        "   images = [result]\n",
        "\n",
        "   for i in range(len(masks)):\n",
        "       res_img = result.copy()\n",
        "       for j, mask in enumerate(masks[i]):\n",
        "           bbox = boxes[0][j]\n",
        "           res_img, _ = get_res_img(bbox, [mask], res_img)\n",
        "           res_img = put_text_box(bbox, cls_names[i], res_img)\n",
        "       images.append(res_img)\n",
        "\n",
        "   final_image = concat_images(images)\n",
        "   img_name = split_extension(os.path.split(img_path)[-1], suffix='-res')\n",
        "   output_path = f'{output_dir}/{img_name}'\n",
        "   os.makedirs(output_dir, exist_ok=True)\n",
        "   print(f'[INFO] Saving the final image at {output_path}')\n",
        "   cv2.imwrite(output_path, final_image)\n",
        "   cv2_imshow(final_image)  # cv2.imwriteの代わりにcv2_imshowを使用\n",
        "\n",
        "\n",
        "\n",
        "def folder_main(folder_path):\n",
        "    input_size = (img_size, img_size)\n",
        "    model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size, names=names)\n",
        "\n",
        "    #################################################################\n",
        "    # ファイル名を数字でソート\n",
        "    file_list = sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0]))[127:130]\n",
        "    #################################################################\n",
        "\n",
        "    for item in file_list:\n",
        "        img_path = os.path.join(folder_path, item)\n",
        "        img_basename = os.path.basename(img_path)\n",
        "        print(f\"Processing image: {img_basename}\")\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # 元の画像の縦横比を維持しながらリサイズ\n",
        "        h, w = img.shape[:2]\n",
        "        if h > w:\n",
        "            new_h, new_w = img_size, int(img_size * w / h)\n",
        "        else:\n",
        "            new_h, new_w = int(img_size * h / w), img_size\n",
        "        img = cv2.resize(img, (new_w, new_h))\n",
        "\n",
        "        # パディングを追加して640×640pxにする\n",
        "        delta_w = img_size - new_w\n",
        "        delta_h = img_size - new_h\n",
        "        top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "        left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "        torch_img = model.preprocessing(img[..., ::-1])\n",
        "\n",
        "        if method == 'gradcam':\n",
        "            saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "\n",
        "        masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "        print(f\"boxes: {boxes}\")\n",
        "\n",
        "        result = torch_img.squeeze(0).mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).detach().cpu().numpy()\n",
        "        result = result[..., ::-1]  # convert to bgr\n",
        "        images = [result]\n",
        "\n",
        "        for i in range(len(masks)):\n",
        "            res_img = result.copy()\n",
        "            for j, mask in enumerate(masks[i]):\n",
        "                bbox = boxes[0][j]\n",
        "                res_img, _ = get_res_img(bbox, [mask], res_img)\n",
        "                res_img = put_text_box(bbox, cls_names[i], res_img)\n",
        "            images.append(res_img)\n",
        "\n",
        "        final_image = concat_images(images)\n",
        "        img_name = split_extension(os.path.split(img_path)[-1], suffix='-res')\n",
        "        output_path = f'{output_dir}/{img_name}'\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        print(f'[INFO] Saving the final image at {output_path}')\n",
        "        cv2.imwrite(output_path, final_image)\n",
        "        #cv2_imshow(final_image)  # cv2.imwriteの代わりにcv2_imshowを使用\n",
        "\n",
        "\n",
        "        # オブジェクトを明示的に削除\n",
        "        del saliency_method\n",
        "        del masks\n",
        "        del logits\n",
        "        del boxes\n",
        "        del images\n",
        "        del final_image\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #target_layer = 'model_17_cv3_act'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_20_cv3_act'  # GradCAM を適用するレイヤー\n",
        "    target_layer = 'model_23_cv3_conv'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_23_cv3_act'  # GradCAM を適用するレイヤー  →デフォルト\n",
        "    #target_layer = 'model_23_m_0_cv2_conv'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_23_m_0_cv2_act'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_24_m_1'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_24_m_2'  # GradCAM を適用するレイヤー\n",
        "    img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "    #img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial\"\n",
        "    output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'  # 出力ディレクトリ\n",
        "    if os.path.isdir(img_path):\n",
        "        folder_main(img_path)\n",
        "    else:\n",
        "        main(img_path)"
      ],
      "metadata": {
        "id": "6hBb7eKP986c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.exit()"
      ],
      "metadata": {
        "id": "SFDwQ_bfIYaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4xA9qfVzajFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Sort GradCam Images**\n",
        "\n",
        "GradCAM画像をクラスごとにフォルダ分け"
      ],
      "metadata": {
        "id": "YHLMn6kZIlSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSVファイルのパス\n",
        "csv_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/maehara234.csv\"\n",
        "\n",
        "# CSVファイルを読み込み\n",
        "df = pd.read_csv(csv_path, encoding='ISO-8859-1')\n",
        "\n",
        "# データフレームの最初の数行を表示\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZaYBsjL7NTcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/maehara_slit_total_updated.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Define source and destination directories\n",
        "source_dirs = [\n",
        "    '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit',\n",
        "    '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_sumaho'\n",
        "]\n",
        "destination_base_dirs = [\n",
        "    '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_slit_sorted',\n",
        "    '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_sumaho_sorted'\n",
        "]\n",
        "\n",
        "# Iterate over the source and destination directory pairs\n",
        "for source_dir, destination_base_dir in zip(source_dirs, destination_base_dirs):\n",
        "    print(f'Processing files from {source_dir} to {destination_base_dir}')\n",
        "    # Iterate over the dataframe and copy files to the appropriate class folder\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "        serial_number = row['serial_number']\n",
        "        class_num = row['class_num']\n",
        "        source_file = os.path.join(source_dir, f'{serial_number}-res.jpg')\n",
        "        destination_dir = os.path.join(destination_base_dir, str(class_num))\n",
        "\n",
        "        # Create the destination directory if it does not exist\n",
        "        os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "        # Copy the file to the destination directory\n",
        "        destination_file = os.path.join(destination_dir, f'{serial_number}-res.jpg')\n",
        "        if os.path.exists(source_file):\n",
        "            shutil.copy(source_file, destination_file)\n",
        "        else:\n",
        "            print(f'File {source_file} does not exist.')\n",
        "\n",
        "print('Files have been copied successfully.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBll2vlDM26D",
        "outputId": "f238c4e9-9e95-44f6-cffc-3b90ec61e326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "Processing files from /gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit to /gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_slit_sorted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 228/228 [00:02<00:00, 88.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files from /gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_sumaho to /gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_sumaho_sorted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 228/228 [00:02<00:00, 89.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files have been copied successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Compare area of interest**\n",
        "\n",
        "注目度n%以上の画像を"
      ],
      "metadata": {
        "id": "dxtwlXulSgO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################\n",
        "#################\n",
        "\n",
        "import numpy as np\n",
        "from deep_utils.utils.box_utils.boxes import Box\n",
        "import torch\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import xywh2xyxy\n",
        "from utils.datasets import letterbox\n",
        "import cv2\n",
        "import time\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from utils.metrics import box_iou\n",
        "\n",
        "class YOLOV5TorchObjectDetector(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_weight,\n",
        "                 device,\n",
        "                 img_size,\n",
        "                 names=None,\n",
        "                 mode='eval',\n",
        "                 confidence=0.25,\n",
        "                 iou_thresh=0.45,\n",
        "                 agnostic_nms=False):\n",
        "        super(YOLOV5TorchObjectDetector, self).__init__()\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.img_size = img_size\n",
        "        self.mode = mode\n",
        "        self.confidence = confidence\n",
        "        self.iou_thresh = iou_thresh\n",
        "        self.agnostic = agnostic_nms\n",
        "        self.model = attempt_load(model_weight, device=device)\n",
        "        print(\"[INFO] Model is loaded\")\n",
        "        self.model.requires_grad_(True)\n",
        "        self.model.to(device)\n",
        "        if self.mode == 'train':\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "        # fetch the names\n",
        "        if names is None:\n",
        "            print('[INFO] fetching names from coco file')\n",
        "            self.names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
        "                          'traffic light',\n",
        "                          'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
        "                          'cow',\n",
        "                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase',\n",
        "                          'frisbee',\n",
        "                          'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "                          'surfboard',\n",
        "                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "                          'apple',\n",
        "                          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
        "                          'couch',\n",
        "                          'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "                          'keyboard', 'cell phone',\n",
        "                          'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "                          'teddy bear',\n",
        "                          'hair drier', 'toothbrush']\n",
        "        else:\n",
        "            self.names = names\n",
        "\n",
        "        # preventing cold start\n",
        "        img = torch.zeros((1, 3, *self.img_size), device=device)\n",
        "        self.model(img)\n",
        "\n",
        "    @staticmethod\n",
        "    def non_max_suppression(prediction, logits, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False,\n",
        "                            multi_label=False, labels=(), max_det=300):\n",
        "        \"\"\"Runs Non-Maximum Suppression (NMS) on inference and logits results\n",
        "\n",
        "        Returns:\n",
        "             list of detections, on (n,6) tensor per image [xyxy, conf, cls] and pruned input logits (n, number-classes)\n",
        "        \"\"\"\n",
        "\n",
        "        nc = prediction.shape[2] - 5  # number of classes\n",
        "        xc = prediction[..., 4] > conf_thres  # candidates\n",
        "\n",
        "        # Checks\n",
        "        assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
        "        assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
        "\n",
        "        # Settings\n",
        "        min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
        "        max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
        "        time_limit = 10.0  # seconds to quit after\n",
        "        redundant = True  # require redundant detections\n",
        "        multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
        "        merge = False  # use merge-NMS\n",
        "\n",
        "        t = time.time()\n",
        "        output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
        "        logits_output = [torch.zeros((0, 80), device=logits.device)] * logits.shape[0]\n",
        "        for xi, (x, log_) in enumerate(zip(prediction, logits)):  # image index, image inference\n",
        "            # Apply constraints\n",
        "            # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
        "            x = x[xc[xi]]  # confidence\n",
        "            log_ = log_[xc[xi]]\n",
        "            # Cat apriori labels if autolabelling\n",
        "            if labels and len(labels[xi]):\n",
        "                l = labels[xi]\n",
        "                v = torch.zeros((len(l), nc + 5), device=x.device)\n",
        "                v[:, :4] = l[:, 1:5]  # box\n",
        "                v[:, 4] = 1.0  # conf\n",
        "                v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
        "                x = torch.cat((x, v), 0)\n",
        "\n",
        "            # If none remain process next image\n",
        "            if not x.shape[0]:\n",
        "                continue\n",
        "\n",
        "            # Compute conf\n",
        "            x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
        "            # log_ *= x[:, 4:5]\n",
        "            # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
        "            box = xywh2xyxy(x[:, :4])\n",
        "\n",
        "            # Detections matrix nx6 (xyxy, conf, cls)\n",
        "            if multi_label:\n",
        "                i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
        "                x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
        "            else:  # best class only\n",
        "                conf, j = x[:, 5:].max(1, keepdim=True)\n",
        "                # log_ = x[:, 5:]\n",
        "                x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
        "                log_ = log_[conf.view(-1) > conf_thres]\n",
        "            # Filter by class\n",
        "            if classes is not None:\n",
        "                x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
        "\n",
        "            # Check shape\n",
        "            n = x.shape[0]  # number of boxes\n",
        "            if not n:  # no boxes\n",
        "                continue\n",
        "            elif n > max_nms:  # excess boxes\n",
        "                x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
        "\n",
        "            # Batched NMS\n",
        "            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
        "            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
        "            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
        "            if i.shape[0] > max_det:  # limit detections\n",
        "                i = i[:max_det]\n",
        "            if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
        "                # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
        "                iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
        "                weights = iou * scores[None]  # box weights\n",
        "                x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
        "                if redundant:\n",
        "                    i = i[iou.sum(1) > 1]  # require redundancy\n",
        "\n",
        "            output[xi] = x[i]\n",
        "            logits_output[xi] = log_[i]\n",
        "            assert log_[i].shape[0] == x[i].shape[0]\n",
        "            if (time.time() - t) > time_limit:\n",
        "                print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
        "                break  # time limit exceeded\n",
        "\n",
        "        return output, logits_output\n",
        "\n",
        "    @staticmethod\n",
        "    def yolo_resize(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True):\n",
        "\n",
        "        return letterbox(img, new_shape=new_shape, color=color, auto=auto, scaleFill=scaleFill, scaleup=scaleup)\n",
        "\n",
        "    def forward(self, img):\n",
        "        prediction, logits, _ = self.model(img, augment=False)\n",
        "        prediction, logits = self.non_max_suppression(prediction, logits, self.confidence, self.iou_thresh,\n",
        "                                                      classes=None,\n",
        "                                                      agnostic=self.agnostic)\n",
        "        self.boxes, self.class_names, self.classes, self.confidences = [[[] for _ in range(img.shape[0])] for _ in\n",
        "                                                                        range(4)]\n",
        "        for i, det in enumerate(prediction):  # detections per image\n",
        "            if len(det):\n",
        "                for *xyxy, conf, cls in det:\n",
        "                    # xyxyの値を修正\n",
        "                    xyxy[0] = max(0, xyxy[0])\n",
        "                    xyxy[1] = max(0, xyxy[1])\n",
        "                    xyxy[2] = min(img_size, xyxy[2])\n",
        "                    xyxy[3] = min(img_size, xyxy[3])\n",
        "\n",
        "                    bbox = Box.box2box(xyxy,\n",
        "                                       in_source=Box.BoxSource.Torch,\n",
        "                                       to_source=Box.BoxSource.Numpy,\n",
        "                                       return_int=True)\n",
        "                    self.boxes[i].append(bbox)\n",
        "                    self.confidences[i].append(round(conf.item(), 2))\n",
        "                    cls = int(cls.item())\n",
        "                    self.classes[i].append(cls)\n",
        "                    if self.names is not None:\n",
        "                        self.class_names[i].append(self.names[cls])\n",
        "                    else:\n",
        "                        self.class_names[i].append(cls)\n",
        "        return [self.boxes, self.classes, self.class_names, self.confidences], logits\n",
        "\n",
        "    def preprocessing(self, img):\n",
        "        if len(img.shape) != 4:\n",
        "            img = np.expand_dims(img, axis=0)\n",
        "        im0 = img.astype(np.uint8)\n",
        "        img = np.array([self.yolo_resize(im, new_shape=self.img_size)[0] for im in im0])\n",
        "        img = img.transpose((0, 3, 1, 2))\n",
        "        img = np.ascontiguousarray(img)\n",
        "        img = torch.from_numpy(img).to(self.device)\n",
        "        img = img / 255.0\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "6iDm_dPKM28s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "# from models.gradcam import YOLOV5GradCAM\n",
        "#from models.yolo_v5_object_detector import YOLOV5TorchObjectDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from deep_utils import Box, split_extension\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "# パラメータ\n",
        "model_path = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "#img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial/99.jpg\"\n",
        "#output_dir = 'out'  # 出力ディレクトリ\n",
        "output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'  # 出力ディレクトリ\n",
        "img_size = 640  # 入力画像サイズ\n",
        "target_layer = 'model_23_cv3_act'  # GradCAM を適用するレイヤー\n",
        "#target_layer = 'model_23_m_0_cv2_act'  # GradCAM を適用するレイヤー\n",
        "#target_layer = 'model_24_m_2'  # GradCAM を適用するレイヤー\n",
        "method = 'gradcam'  # 'gradcam' または 'gradcampp'\n",
        "device = 'cpu'  # 'cuda' または 'cpu'\n",
        "\n",
        "# クラス名リストを指定\n",
        "names = [\"infection\",\"normal\",\"non-infection\",\"scar\",\"tumor\",\"deposit\",\"APAC\",\"lens opacity\",\"bullous\"]\n",
        "\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_res_img(bbox, masks, res_img, threshold):\n",
        "    for mask in masks:\n",
        "        mask = mask.squeeze().mul(255).add_(0.5).clamp_(0, 255).detach().cpu().numpy().astype(np.uint8)\n",
        "        mask[mask < threshold*255] = 0  # 追加: 128未満の値を0にする\n",
        "        mask[mask >= threshold*255] = 255  # 追加: 128未満の値を0にする\n",
        "        heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
        "        n_heatmat = (Box.fill_outer_box(heatmap, bbox) / 255).astype(np.float32)\n",
        "        res_img = res_img / 255\n",
        "        res_img = cv2.add(res_img, n_heatmat)\n",
        "        res_img = (res_img / res_img.max())\n",
        "    return res_img, n_heatmat\n",
        "\n",
        "def put_text_box(bbox, cls_name, res_img):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    # this is a bug in cv2. It does not put box on a converted image from torch unless it's buffered and read again!\n",
        "    cv2.imwrite('temp.jpg', (res_img * 255).astype(np.uint8))\n",
        "    res_img = cv2.imread('temp.jpg')\n",
        "    res_img = Box.put_box(res_img, bbox)\n",
        "\n",
        "    # Set the font size and other parameters\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 2.0\n",
        "    color = (0, 255, 0)  # Green color in BGR format\n",
        "    thickness = 2\n",
        "\n",
        "    # Calculate the text size and position\n",
        "    text_size, _ = cv2.getTextSize(cls_name, font, font_scale, thickness)\n",
        "    text_x = 10  # Adjust the horizontal position to place the text near the left edge\n",
        "    text_y = text_size[1] + 10  # Adjust the vertical position to place the text near the top edge\n",
        "\n",
        "    # Put the text on the image\n",
        "    cv2.putText(res_img, cls_name, (text_x, text_y), font, font_scale, color, thickness)\n",
        "\n",
        "    return res_img\n",
        "\n",
        "def concat_images(images):\n",
        "    w, h = images[0].shape[:2]\n",
        "    width = w\n",
        "    height = h * len(images)\n",
        "    base_img = np.zeros((width, height, 3), dtype=np.uint8)\n",
        "    for i, img in enumerate(images):\n",
        "        base_img[:, h * i:h * (i + 1), ...] = img\n",
        "    return base_img\n",
        "\n",
        "def find_yolo_layer(model, layer_name):\n",
        "    \"\"\"Find yolov5 layer to calculate GradCAM and GradCAM++\n",
        "\n",
        "    Args:\n",
        "        model: yolov5 model.\n",
        "        layer_name (str): the name of layer with its hierarchical information.\n",
        "\n",
        "    Return:\n",
        "        target_layer: found layer\n",
        "    \"\"\"\n",
        "    hierarchy = layer_name.split('_')\n",
        "    target_layer = model.model._modules[hierarchy[0]]\n",
        "\n",
        "    for h in hierarchy[1:]:\n",
        "        target_layer = target_layer._modules[h]\n",
        "    return target_layer\n",
        "\n",
        "\n",
        "class YOLOV5GradCAM:\n",
        "    def __init__(self, model, layer_name, img_size=(640, 640)):\n",
        "        self.model = model\n",
        "        self.gradients = dict()\n",
        "        self.activations = dict()\n",
        "        self.cls_names = []  # 追加: Top1~3のクラス名を保存するリスト\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients['value'] = grad_output[0]\n",
        "            return None\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations['value'] = output\n",
        "            return None\n",
        "\n",
        "        target_layer = find_yolo_layer(self.model, layer_name)\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        device = 'cuda' if next(self.model.model.parameters()).is_cuda else 'cpu'\n",
        "        self.model(torch.zeros(1, 3, *img_size, device=device))\n",
        "        # print('[INFO] saliency_map size :', self.activations['value'].shape[2:])\n",
        "\n",
        "    def forward(self, input_img, class_idx=True):\n",
        "        saliency_maps = []\n",
        "        b, c, h, w = input_img.size()\n",
        "        tic = time.time()\n",
        "        preds, logits = self.model(input_img)\n",
        "        # print(\"[INFO] model-forward took: \", round(time.time() - tic, 4), 'seconds')\n",
        "\n",
        "        _, top3_indices = torch.topk(logits[0], k=3)\n",
        "\n",
        "        if top3_indices.numel() > 0:\n",
        "            preds[1][0] = top3_indices.tolist()[0]\n",
        "            preds[2][0] = [names[i] for i in preds[1][0]]\n",
        "            self.cls_names = preds[2][0]  # 修正: Top1~3のクラス名を保存\n",
        "        else:\n",
        "            self.cls_names = []  # top3_indicesが空の場合は空のリストを代入\n",
        "\n",
        "        for cls, cls_name in zip(preds[1][0], preds[2][0]):\n",
        "            if class_idx:\n",
        "                score = logits[0][0][cls]\n",
        "            else:\n",
        "                score = logits[0][0].max()\n",
        "            self.model.zero_grad()\n",
        "            tic = time.time()\n",
        "            score.backward(retain_graph=True)\n",
        "            # print(f\"[INFO] {cls_name}, model-backward took: \", round(time.time() - tic, 4), 'seconds')\n",
        "            gradients = self.gradients['value']\n",
        "            activations = self.activations['value']\n",
        "            b, k, u, v = gradients.size()\n",
        "            alpha = gradients.view(b, k, -1).mean(2)\n",
        "            weights = alpha.view(b, k, 1, 1)\n",
        "            saliency_map = (weights * activations).sum(1, keepdim=True)\n",
        "            saliency_map = F.relu(saliency_map)\n",
        "            saliency_map = F.upsample(saliency_map, size=(h, w), mode='bilinear', align_corners=False)\n",
        "            saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
        "            saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
        "            saliency_maps.append(saliency_map)\n",
        "\n",
        "        return saliency_maps, logits, preds, self.cls_names\n",
        "\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "        return self.forward(input_img)\n",
        "\n",
        "def main(img_path):\n",
        "    input_size = (img_size, img_size)\n",
        "    img = cv2.imread(img_path)\n",
        "    model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size,\n",
        "                                      names=names)\n",
        "    torch_img = model.preprocessing(img[..., ::-1])\n",
        "    if method == 'gradcam':\n",
        "        saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "    tic = time.time()\n",
        "    masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "    print(\"total time:\", round(time.time() - tic, 4))\n",
        "    result = torch_img.squeeze(0).mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).detach().cpu().numpy()\n",
        "    result = result[..., ::-1]  # convert to bgr\n",
        "    images = [result]\n",
        "\n",
        "    if len(masks) > 0:\n",
        "        mask = masks[0][0]  # top1のマスクのみ使用\n",
        "        bbox = boxes[0][0]  # top1のバウンディングボックスのみ使用\n",
        "        cls_name = cls_names[0]  # top1のクラス名のみ使用\n",
        "        res_img = result.copy()\n",
        "        res_img, _ = get_res_img(bbox, [mask], res_img, GradCAM_threshold)\n",
        "        res_img = put_text_box(bbox, cls_name, res_img)\n",
        "        images.append(res_img)\n",
        "\n",
        "    final_image = concat_images(images)\n",
        "    img_name = split_extension(os.path.split(img_path)[-1], suffix='-res')\n",
        "    output_path = f'{output_dir}/{img_name}'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f'[INFO] Saving the final image at {output_path}')\n",
        "    cv2_imshow(final_image)  # cv2.imwriteの代わりにcv2_imshowを使用\n",
        "\n",
        "\n",
        "\n",
        "def folder_main(folder_path):\n",
        "    input_size = (img_size, img_size)\n",
        "    model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size, names=names)\n",
        "\n",
        "    ##############################################################################################\n",
        "    ######## ファイル名を数字でソート#############################################################\n",
        "    file_list = sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0]))[128:132]\n",
        "    ##############################################################################################\n",
        "    ##############################################################################################\n",
        "\n",
        "    for item in file_list:\n",
        "        img_path = os.path.join(folder_path, item)\n",
        "        img_basename = os.path.basename(img_path)\n",
        "        print(f\"Processing image: {img_basename}\")\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # 元の画像の縦横比を維持しながらリサイズ\n",
        "        h, w = img.shape[:2]\n",
        "        if h > w:\n",
        "            new_h, new_w = img_size, int(img_size * w / h)\n",
        "        else:\n",
        "            new_h, new_w = int(img_size * h / w), img_size\n",
        "        img = cv2.resize(img, (new_w, new_h))\n",
        "\n",
        "        # パディングを追加して640×640pxにする\n",
        "        delta_w = img_size - new_w\n",
        "        delta_h = img_size - new_h\n",
        "        top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "        left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "        torch_img = model.preprocessing(img[..., ::-1])\n",
        "\n",
        "        if method == 'gradcam':\n",
        "            saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "\n",
        "        masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "        print(f\"boxes: {boxes}\")\n",
        "\n",
        "        result = torch_img.squeeze(0).mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).detach().cpu().numpy()\n",
        "        result = result[..., ::-1]  # convert to bgr\n",
        "        images = [result]\n",
        "\n",
        "        if len(masks) > 0:\n",
        "            mask = masks[0][0]  # top1のマスクのみ使用\n",
        "            bbox = boxes[0][0]  # top1のバウンディングボックスのみ使用\n",
        "            cls_name = cls_names[0]  # top1のクラス名のみ使用\n",
        "            res_img = result.copy()\n",
        "            res_img, _ = get_res_img(bbox, [mask], res_img, GradCAM_threshold)\n",
        "            res_img = put_text_box(bbox, cls_name, res_img)\n",
        "            images.append(res_img)\n",
        "\n",
        "        final_image = concat_images(images)\n",
        "        img_name = split_extension(os.path.split(img_path)[-1], suffix='-res')\n",
        "        output_path = f'{output_dir}/{img_name}'\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        print(f'[INFO] Saving the final image at {output_path}')\n",
        "        cv2_imshow(final_image)  # cv2.imwriteの代わりにcv2_imshowを使用\n",
        "\n",
        "        # オブジェクトを明示的に削除\n",
        "        del saliency_method\n",
        "        del masks\n",
        "        del logits\n",
        "        del boxes\n",
        "        del images\n",
        "        del final_image\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #target_layer = 'model_17_cv3_act'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_20_cv3_act'  # GradCAM を適用するレイヤー\n",
        "    target_layer = 'model_23_cv3_conv'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_23_cv3_act'  # GradCAM を適用するレイヤー  →デフォルト\n",
        "    #target_layer = 'model_23_m_0_cv2_conv'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_23_m_0_cv2_act'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_24_m_1'  # GradCAM を適用するレイヤー\n",
        "    #target_layer = 'model_24_m_2'  # GradCAM を適用するレイヤー\n",
        "    #img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "    img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial\"\n",
        "    #output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'  # 出力ディレクトリ\n",
        "    output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_sumaho_slit'  # 出力ディレクトリ\n",
        "\n",
        "    GradCAM_threshold = 0.5 #GradCAMの閾値設定\n",
        "    if os.path.isdir(img_path):\n",
        "        folder_main(img_path)\n",
        "    else:\n",
        "        main(img_path)"
      ],
      "metadata": {
        "id": "HV90u_Z9Urn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Area of interestの計算**\n",
        "\n",
        "結果をcsvに保存する"
      ],
      "metadata": {
        "id": "iEUdHWgh79uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSVファイルのパス\n",
        "file_path = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/maehara_sumaho_total_updated.csv'\n",
        "\n",
        "# CSVファイルをDataFrameとして読み込む\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 'Unnamed'が含まれる列を削除する\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "# 例としてthresholdの値を設定\n",
        "threshold = 0.5\n",
        "\n",
        "# 新しい列 'AOI_{threshold}' を作成\n",
        "df[f'AOI_{threshold}'] = None  # 初期値を設定\n",
        "\n",
        "# 修正後のDataFrameを表示する\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Up7ykhgI5l3n",
        "outputId": "80dec364-9c94-4537-c8f9-103c1e83b328"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   serial_number    basename disease_English  class_num  top1  top1_prob  \\\n",
              "0              1   9TTR_R_01       infection          0     0   0.936966   \n",
              "1              2  12TTR_R_01       infection          0     0   0.922136   \n",
              "2              3  13TTR_R_01       infection          0     2   0.426648   \n",
              "3              4  21TTR_L_01       infection          0     0   0.689450   \n",
              "4              5  25TTR_R_01            APAC          6     6   0.912041   \n",
              "\n",
              "   top2  top2_prob  top3  top3_prob AOI_0.5  \n",
              "0     4   0.010804     0   0.006100    None  \n",
              "1     2   0.001290     3   0.000831    None  \n",
              "2     8   0.154254     0   0.099206    None  \n",
              "3     2   0.456746     3   0.015478    None  \n",
              "4     0   0.065191     4   0.060999    None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d869de9a-a5db-469a-baef-c83e9505b511\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>serial_number</th>\n",
              "      <th>basename</th>\n",
              "      <th>disease_English</th>\n",
              "      <th>class_num</th>\n",
              "      <th>top1</th>\n",
              "      <th>top1_prob</th>\n",
              "      <th>top2</th>\n",
              "      <th>top2_prob</th>\n",
              "      <th>top3</th>\n",
              "      <th>top3_prob</th>\n",
              "      <th>AOI_0.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>9TTR_R_01</td>\n",
              "      <td>infection</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.936966</td>\n",
              "      <td>4</td>\n",
              "      <td>0.010804</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>12TTR_R_01</td>\n",
              "      <td>infection</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.922136</td>\n",
              "      <td>2</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13TTR_R_01</td>\n",
              "      <td>infection</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.426648</td>\n",
              "      <td>8</td>\n",
              "      <td>0.154254</td>\n",
              "      <td>0</td>\n",
              "      <td>0.099206</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>21TTR_L_01</td>\n",
              "      <td>infection</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.689450</td>\n",
              "      <td>2</td>\n",
              "      <td>0.456746</td>\n",
              "      <td>3</td>\n",
              "      <td>0.015478</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>25TTR_R_01</td>\n",
              "      <td>APAC</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.912041</td>\n",
              "      <td>0</td>\n",
              "      <td>0.065191</td>\n",
              "      <td>4</td>\n",
              "      <td>0.060999</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d869de9a-a5db-469a-baef-c83e9505b511')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d869de9a-a5db-469a-baef-c83e9505b511 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d869de9a-a5db-469a-baef-c83e9505b511');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b25dacb3-1349-4ba4-9d75-19736c2bd54e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b25dacb3-1349-4ba4-9d75-19736c2bd54e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b25dacb3-1349-4ba4-9d75-19736c2bd54e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################\n",
        "#################\n",
        "\n",
        "import numpy as np\n",
        "from deep_utils.utils.box_utils.boxes import Box\n",
        "import torch\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import xywh2xyxy\n",
        "from utils.datasets import letterbox\n",
        "import cv2\n",
        "import time\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from utils.metrics import box_iou\n",
        "\n",
        "class YOLOV5TorchObjectDetector(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_weight,\n",
        "                 device,\n",
        "                 img_size,\n",
        "                 names=None,\n",
        "                 mode='eval',\n",
        "                 confidence=0.25,\n",
        "                 iou_thresh=0.45,\n",
        "                 agnostic_nms=False):\n",
        "        super(YOLOV5TorchObjectDetector, self).__init__()\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.img_size = img_size\n",
        "        self.mode = mode\n",
        "        self.confidence = confidence\n",
        "        self.iou_thresh = iou_thresh\n",
        "        self.agnostic = agnostic_nms\n",
        "        self.model = attempt_load(model_weight, device=device)\n",
        "        print(\"[INFO] Model is loaded\")\n",
        "        self.model.requires_grad_(True)\n",
        "        self.model.to(device)\n",
        "        if self.mode == 'train':\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "        # fetch the names\n",
        "        if names is None:\n",
        "            print('[INFO] fetching names from coco file')\n",
        "            self.names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
        "                          'traffic light',\n",
        "                          'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
        "                          'cow',\n",
        "                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase',\n",
        "                          'frisbee',\n",
        "                          'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "                          'surfboard',\n",
        "                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "                          'apple',\n",
        "                          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
        "                          'couch',\n",
        "                          'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "                          'keyboard', 'cell phone',\n",
        "                          'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "                          'teddy bear',\n",
        "                          'hair drier', 'toothbrush']\n",
        "        else:\n",
        "            self.names = names\n",
        "\n",
        "        # preventing cold start\n",
        "        img = torch.zeros((1, 3, *self.img_size), device=device)\n",
        "        self.model(img)\n",
        "\n",
        "    @staticmethod\n",
        "    def non_max_suppression(prediction, logits, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False,\n",
        "                            multi_label=False, labels=(), max_det=300):\n",
        "        \"\"\"Runs Non-Maximum Suppression (NMS) on inference and logits results\n",
        "\n",
        "        Returns:\n",
        "             list of detections, on (n,6) tensor per image [xyxy, conf, cls] and pruned input logits (n, number-classes)\n",
        "        \"\"\"\n",
        "\n",
        "        nc = prediction.shape[2] - 5  # number of classes\n",
        "        xc = prediction[..., 4] > conf_thres  # candidates\n",
        "\n",
        "        # Checks\n",
        "        assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
        "        assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
        "\n",
        "        # Settings\n",
        "        min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
        "        max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
        "        time_limit = 10.0  # seconds to quit after\n",
        "        redundant = True  # require redundant detections\n",
        "        multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
        "        merge = False  # use merge-NMS\n",
        "\n",
        "        t = time.time()\n",
        "        output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
        "        logits_output = [torch.zeros((0, 80), device=logits.device)] * logits.shape[0]\n",
        "        for xi, (x, log_) in enumerate(zip(prediction, logits)):  # image index, image inference\n",
        "            # Apply constraints\n",
        "            # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
        "            x = x[xc[xi]]  # confidence\n",
        "            log_ = log_[xc[xi]]\n",
        "            # Cat apriori labels if autolabelling\n",
        "            if labels and len(labels[xi]):\n",
        "                l = labels[xi]\n",
        "                v = torch.zeros((len(l), nc + 5), device=x.device)\n",
        "                v[:, :4] = l[:, 1:5]  # box\n",
        "                v[:, 4] = 1.0  # conf\n",
        "                v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
        "                x = torch.cat((x, v), 0)\n",
        "\n",
        "            # If none remain process next image\n",
        "            if not x.shape[0]:\n",
        "                continue\n",
        "\n",
        "            # Compute conf\n",
        "            x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
        "            # log_ *= x[:, 4:5]\n",
        "            # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
        "            box = xywh2xyxy(x[:, :4])\n",
        "\n",
        "            # Detections matrix nx6 (xyxy, conf, cls)\n",
        "            if multi_label:\n",
        "                i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
        "                x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
        "            else:  # best class only\n",
        "                conf, j = x[:, 5:].max(1, keepdim=True)\n",
        "                # log_ = x[:, 5:]\n",
        "                x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
        "                log_ = log_[conf.view(-1) > conf_thres]\n",
        "            # Filter by class\n",
        "            if classes is not None:\n",
        "                x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
        "\n",
        "            # Check shape\n",
        "            n = x.shape[0]  # number of boxes\n",
        "            if not n:  # no boxes\n",
        "                continue\n",
        "            elif n > max_nms:  # excess boxes\n",
        "                x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
        "\n",
        "            # Batched NMS\n",
        "            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
        "            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
        "            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
        "            if i.shape[0] > max_det:  # limit detections\n",
        "                i = i[:max_det]\n",
        "            if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
        "                # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
        "                iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
        "                weights = iou * scores[None]  # box weights\n",
        "                x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
        "                if redundant:\n",
        "                    i = i[iou.sum(1) > 1]  # require redundancy\n",
        "\n",
        "            output[xi] = x[i]\n",
        "            logits_output[xi] = log_[i]\n",
        "            assert log_[i].shape[0] == x[i].shape[0]\n",
        "            if (time.time() - t) > time_limit:\n",
        "                print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
        "                break  # time limit exceeded\n",
        "\n",
        "        return output, logits_output\n",
        "\n",
        "    @staticmethod\n",
        "    def yolo_resize(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True):\n",
        "\n",
        "        return letterbox(img, new_shape=new_shape, color=color, auto=auto, scaleFill=scaleFill, scaleup=scaleup)\n",
        "\n",
        "    def forward(self, img):\n",
        "        prediction, logits, _ = self.model(img, augment=False)\n",
        "        prediction, logits = self.non_max_suppression(prediction, logits, self.confidence, self.iou_thresh,\n",
        "                                                      classes=None,\n",
        "                                                      agnostic=self.agnostic)\n",
        "        self.boxes, self.class_names, self.classes, self.confidences = [[[] for _ in range(img.shape[0])] for _ in\n",
        "                                                                        range(4)]\n",
        "        for i, det in enumerate(prediction):  # detections per image\n",
        "            if len(det):\n",
        "                for *xyxy, conf, cls in det:\n",
        "                    # xyxyの値を修正\n",
        "                    xyxy[0] = max(0, xyxy[0])\n",
        "                    xyxy[1] = max(0, xyxy[1])\n",
        "                    xyxy[2] = min(self.img_size[0], xyxy[2])\n",
        "                    xyxy[3] = min(self.img_size[1], xyxy[3])\n",
        "\n",
        "                    bbox = Box.box2box(xyxy,\n",
        "                                      in_source=Box.BoxSource.Torch,\n",
        "                                      to_source=Box.BoxSource.Numpy,\n",
        "                                      return_int=True)\n",
        "                    self.boxes[i].append(bbox)\n",
        "                    self.confidences[i].append(round(conf.item(), 2))\n",
        "                    cls = int(cls.item())\n",
        "                    self.classes[i].append(cls)\n",
        "                    if self.names is not None:\n",
        "                        self.class_names[i].append(self.names[cls])\n",
        "                    else:\n",
        "                        self.class_names[i].append(cls)\n",
        "        return [self.boxes, self.classes, self.class_names, self.confidences], logits\n",
        "\n",
        "    def preprocessing(self, img):\n",
        "        if len(img.shape) != 4:\n",
        "            img = np.expand_dims(img, axis=0)\n",
        "        im0 = img.astype(np.uint8)\n",
        "        img = np.array([self.yolo_resize(im, new_shape=self.img_size)[0] for im in im0])\n",
        "        img = img.transpose((0, 3, 1, 2))\n",
        "        img = np.ascontiguousarray(img)\n",
        "        img = torch.from_numpy(img).to(self.device)\n",
        "        img = img / 255.0\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "wj6fl4uVCCji"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS3iA_8QKWZC",
        "outputId": "d1148429-0fbb-48ee-8e10-08b8596d854c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from deep_utils import Box, split_extension\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "#from models.yolo_v5_object_detector import YOLOV5TorchObjectDetector\n",
        "# from models.gradcam import YOLOV5GradCAM\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import gc\n",
        "\n",
        "class YOLOV5GradCAM:\n",
        "    def __init__(self, model, layer_name, img_size=(640, 640)):\n",
        "        self.model = model\n",
        "        self.gradients = dict()\n",
        "        self.activations = dict()\n",
        "        self.cls_names = []  # 追加: Top1~3のクラス名を保存するリスト\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients['value'] = grad_output[0]\n",
        "            return None\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations['value'] = output\n",
        "            return None\n",
        "\n",
        "        target_layer = find_yolo_layer(self.model, layer_name)\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        device = 'cuda' if next(self.model.model.parameters()).is_cuda else 'cpu'\n",
        "        self.model(torch.zeros(1, 3, *img_size, device=device))\n",
        "        # print('[INFO] saliency_map size :', self.activations['value'].shape[2:])\n",
        "\n",
        "    def forward(self, input_img, class_idx=True):\n",
        "        saliency_maps = []\n",
        "        b, c, h, w = input_img.size()\n",
        "        tic = time.time()\n",
        "        preds, logits = self.model(input_img)\n",
        "        # print(\"[INFO] model-forward took: \", round(time.time() - tic, 4), 'seconds')\n",
        "\n",
        "        _, top3_indices = torch.topk(logits[0], k=3)\n",
        "\n",
        "        if top3_indices.numel() > 0:\n",
        "            preds[1][0] = top3_indices.tolist()[0]\n",
        "            preds[2][0] = [names[i] for i in preds[1][0]]\n",
        "            self.cls_names = preds[2][0]  # 修正: Top1~3のクラス名を保存\n",
        "        else:\n",
        "            self.cls_names = []  # top3_indicesが空の場合は空のリストを代入\n",
        "\n",
        "        for cls, cls_name in zip(preds[1][0], preds[2][0]):\n",
        "            if class_idx:\n",
        "                score = logits[0][0][cls]\n",
        "            else:\n",
        "                score = logits[0][0].max()\n",
        "            self.model.zero_grad()\n",
        "            tic = time.time()\n",
        "            score.backward(retain_graph=True)\n",
        "            # print(f\"[INFO] {cls_name}, model-backward took: \", round(time.time() - tic, 4), 'seconds')\n",
        "            gradients = self.gradients['value']\n",
        "            activations = self.activations['value']\n",
        "            b, k, u, v = gradients.size()\n",
        "            alpha = gradients.view(b, k, -1).mean(2)\n",
        "            weights = alpha.view(b, k, 1, 1)\n",
        "            saliency_map = (weights * activations).sum(1, keepdim=True)\n",
        "            saliency_map = F.relu(saliency_map)\n",
        "            saliency_map = F.upsample(saliency_map, size=(h, w), mode='bilinear', align_corners=False)\n",
        "            saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
        "            saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
        "            saliency_maps.append(saliency_map)\n",
        "\n",
        "        return saliency_maps, logits, preds, self.cls_names\n",
        "\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "        return self.forward(input_img)\n",
        "\n",
        "def find_yolo_layer(model, layer_name):\n",
        "    \"\"\"Find yolov5 layer to calculate GradCAM and GradCAM++\n",
        "\n",
        "    Args:\n",
        "        model: yolov5 model.\n",
        "        layer_name (str): the name of layer with its hierarchical information.\n",
        "\n",
        "    Return:\n",
        "        target_layer: found layer\n",
        "    \"\"\"\n",
        "    hierarchy = layer_name.split('_')\n",
        "    target_layer = model.model._modules[hierarchy[0]]\n",
        "\n",
        "    for h in hierarchy[1:]:\n",
        "        target_layer = target_layer._modules[h]\n",
        "    return target_layer\n",
        "\n",
        "def get_aoi(bbox, masks, threshold):\n",
        "    if len(bbox) == 0 or len(masks) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    for mask in masks:\n",
        "        mask = mask.squeeze().mul(255).add_(0.5).clamp_(0, 255).detach().cpu().numpy().astype(np.uint8)\n",
        "        mask[mask < threshold*255] = 0\n",
        "        mask[mask >= threshold*255] = 255\n",
        "        heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
        "        n_heatmat = (Box.fill_outer_box(heatmap, bbox) / 255).astype(np.float32)\n",
        "        aoi = np.sum(n_heatmat > 0) / (n_heatmat.shape[0] * n_heatmat.shape[1])\n",
        "    return aoi\n",
        "\n",
        "def calculate_aoi(folder_path, csv_path, threshold, model, saliency_method, start_index=0, end_index=None):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "    if f'AOI_{threshold}' not in df.columns:\n",
        "        df[f'AOI_{threshold}'] = None\n",
        "\n",
        "    if end_index is None:\n",
        "        end_index = len(df)\n",
        "\n",
        "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\"):\n",
        "        if index < start_index or index >= end_index:\n",
        "            continue\n",
        "\n",
        "        serial_number = row['serial_number']\n",
        "\n",
        "        if pd.isna(serial_number):\n",
        "            print(f\"Skipping row {index} due to NaN serial_number\")\n",
        "            continue\n",
        "\n",
        "        img_name = f\"{int(serial_number)}.jpg\"\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "\n",
        "        # Rest of the code remains the same\n",
        "        if os.path.exists(img_path):\n",
        "            img = cv2.imread(img_path)\n",
        "            torch_img = model.preprocessing(img[..., ::-1])\n",
        "\n",
        "            try:\n",
        "                masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "            except ValueError as e:\n",
        "                print(f\"Error processing image {img_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            if len(masks) > 0 and len(boxes) > 0:\n",
        "                mask = masks[0][0]  # top1のマスクのみ使用\n",
        "                bbox = boxes[0][0]  # top1のバウンディングボックスのみ使用\n",
        "\n",
        "                aoi = get_aoi(bbox, [mask], threshold)\n",
        "                df.at[index, f'AOI_{threshold}'] = aoi\n",
        "\n",
        "                print(f\"Image: {img_name}, AOI: {aoi}\")\n",
        "        else:\n",
        "            print(f\"Image not found: {img_name}\")\n",
        "\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "# 使用例\n",
        "# folder_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial\"\n",
        "# csv_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/maehara_sumaho_total_updated.csv\"\n",
        "folder_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "csv_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/maehara_slit_total_updated.csv\"\n",
        "threshold = 0.5\n",
        "start_index =100 # 開始するインデックスを指定\n",
        "end_index = 234 # 終了するインデックスを指定\n",
        "\n",
        "# モデルとsaliency_methodの定義\n",
        "model_path = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "device = 'cpu'\n",
        "input_size = (640, 640)\n",
        "names = [\"infection\",\"normal\",\"non-infection\",\"scar\",\"tumor\",\"deposit\",\"APAC\",\"lens opacity\",\"bullous\"]\n",
        "\n",
        "model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size, names=names)\n",
        "target_layer = 'model_23_cv3_conv'\n",
        "saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "\n",
        "calculate_aoi(folder_path, csv_path, threshold, model, saliency_method, start_index, end_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7rq_tvQf7zfW",
        "outputId": "52597149-6fd7-47e0-982d-152338dfeac7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:models.yolo:Fusing layers... \n",
            "Fusing layers... \n",
            "INFO:utils.torch_utils:Model Summary: 213 layers, 7034398 parameters, 0 gradients\n",
            "Model Summary: 213 layers, 7034398 parameters, 0 gradients\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Model is loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "Processing images:   0%|          | 0/999 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  10%|█         | 101/999 [00:00<00:06, 144.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 105.jpg, AOI: 0.6757952008928572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 106.jpg, AOI: 0.58125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 107.jpg, AOI: 0.6843226841517858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 108.jpg, AOI: 0.6613351004464286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 109.jpg, AOI: 0.59326171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 110.jpg, AOI: 0.5586983816964286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 111.jpg, AOI: 0.5604631696428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 112.jpg, AOI: 0.6138671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 113.jpg, AOI: 0.6551897321428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 115.jpg, AOI: 0.56875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 116.jpg, AOI: 0.8991927083333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 118.jpg, AOI: 0.2581298828125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 119.jpg, AOI: 0.19083251953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 120.jpg, AOI: 0.49359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 121.jpg, AOI: 0.36203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  12%|█▏        | 116/999 [00:08<01:23, 10.61it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 122.jpg, AOI: 0.43384114583333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 123.jpg, AOI: 0.4628092447916667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 124.jpg, AOI: 0.13233235677083333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 125.jpg, AOI: 0.3128125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 126.jpg, AOI: 0.25509207589285715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 127.jpg, AOI: 0.31112234933035715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 128.jpg, AOI: 0.2130092075892857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  12%|█▏        | 123/999 [00:11<01:58,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 129.jpg, AOI: 0.2556396484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 130.jpg, AOI: 0.3070731026785714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 131.jpg, AOI: 0.28359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 132.jpg, AOI: 0.291845703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  13%|█▎        | 127/999 [00:14<02:31,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 133.jpg, AOI: 0.22753208705357142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 134.jpg, AOI: 0.21797921316964286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 135.jpg, AOI: 0.27958286830357143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  13%|█▎        | 130/999 [00:15<02:57,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 136.jpg, AOI: 0.2741001674107143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 137.jpg, AOI: 0.22307477678571427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  13%|█▎        | 132/999 [00:16<03:13,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 138.jpg, AOI: 0.20339006696428572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 139.jpg, AOI: 0.32052873883928573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  13%|█▎        | 134/999 [00:17<03:33,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 140.jpg, AOI: 0.23818359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▎        | 135/999 [00:18<03:45,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 141.jpg, AOI: 0.2908238002232143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▎        | 136/999 [00:18<04:01,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 142.jpg, AOI: 0.3612060546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▎        | 137/999 [00:19<04:20,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 143.jpg, AOI: 0.31171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 138/999 [00:19<04:38,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 144.jpg, AOI: 0.3074462890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 139/999 [00:20<05:02,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 145.jpg, AOI: 0.23542131696428573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 140/999 [00:20<05:21,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 146.jpg, AOI: 0.15824497767857143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 141/999 [00:21<05:49,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 147.jpg, AOI: 0.6090364583333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 142/999 [00:21<06:04,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 148.jpg, AOI: 0.915771484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 143/999 [00:22<06:22,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 149.jpg, AOI: 0.7642578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  14%|█▍        | 144/999 [00:22<06:35,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 150.jpg, AOI: 0.5530143229166666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▍        | 145/999 [00:23<06:47,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 151.jpg, AOI: 0.648125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▍        | 146/999 [00:23<06:54,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 152.jpg, AOI: 0.6205794270833334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▍        | 147/999 [00:24<06:58,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 153.jpg, AOI: 0.65185546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▍        | 148/999 [00:24<07:04,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 154.jpg, AOI: 0.55072265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▍        | 149/999 [00:25<07:39,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 155.jpg, AOI: 0.663017578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▌        | 150/999 [00:26<08:27,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 156.jpg, AOI: 0.7536979166666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▌        | 151/999 [00:26<09:08,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 157.jpg, AOI: 0.668486328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▌        | 152/999 [00:27<09:09,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 158.jpg, AOI: 0.6966796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▌        | 153/999 [00:28<08:43,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 159.jpg, AOI: 0.7356770833333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  15%|█▌        | 154/999 [00:28<08:12,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 160.jpg, AOI: 0.75234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 155/999 [00:29<07:55,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 161.jpg, AOI: 0.748828125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 156/999 [00:29<07:40,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 162.jpg, AOI: 0.61125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 157/999 [00:30<07:28,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 163.jpg, AOI: 0.6188802083333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 158/999 [00:30<07:22,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 164.jpg, AOI: 0.5417317708333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 159/999 [00:31<07:18,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 165.jpg, AOI: 0.48134765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 160/999 [00:31<07:15,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 166.jpg, AOI: 0.7645703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 161/999 [00:32<07:05,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 167.jpg, AOI: 0.71970703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▌        | 162/999 [00:32<07:08,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 168.jpg, AOI: 0.6099739583333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▋        | 163/999 [00:33<07:05,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 169.jpg, AOI: 0.5923828125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  16%|█▋        | 164/999 [00:33<07:07,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 170.jpg, AOI: 0.6445345052083333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 165/999 [00:34<07:03,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 171.jpg, AOI: 0.6172526041666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 166/999 [00:34<07:01,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 172.jpg, AOI: 0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 167/999 [00:35<07:02,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 173.jpg, AOI: 0.6248046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 168/999 [00:35<07:05,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 174.jpg, AOI: 0.6879166666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 169/999 [00:36<07:05,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 175.jpg, AOI: 0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 170/999 [00:36<07:02,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 176.jpg, AOI: 0.2515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 171/999 [00:37<07:02,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 177.jpg, AOI: 0.5936881510416666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 172/999 [00:37<07:07,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 178.jpg, AOI: 0.704150390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 173/999 [00:38<08:11,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 179.jpg, AOI: 0.6644140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  17%|█▋        | 174/999 [00:39<08:15,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 180.jpg, AOI: 0.6444010416666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 175/999 [00:39<08:16,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 181.jpg, AOI: 0.5586848958333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 176/999 [00:40<08:55,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 182.jpg, AOI: 0.639345703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 177/999 [00:41<08:33,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 183.jpg, AOI: 0.8676920572916667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 178/999 [00:41<07:59,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 184.jpg, AOI: 0.625625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 179/999 [00:42<07:44,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 185.jpg, AOI: 0.50880859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 180/999 [00:42<07:18,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 186.jpg, AOI: 0.6632359095982143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 181/999 [00:43<07:06,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 187.jpg, AOI: 0.4445277622767857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 182/999 [00:43<07:02,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 188.jpg, AOI: 0.856025390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 183/999 [00:44<06:51,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 189.jpg, AOI: 0.512939453125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  18%|█▊        | 184/999 [00:44<06:42,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 190.jpg, AOI: 0.6745291573660714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▊        | 185/999 [00:45<06:40,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 191.jpg, AOI: 0.30654296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▊        | 186/999 [00:45<06:37,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 192.jpg, AOI: 0.63154296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▊        | 187/999 [00:46<06:35,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 193.jpg, AOI: 0.6159877232142857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 188/999 [00:46<06:43,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 194.jpg, AOI: 0.7547037760416667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 189/999 [00:47<06:48,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 195.jpg, AOI: 0.87763671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 190/999 [00:47<06:39,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 196.jpg, AOI: 0.5665283203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 191/999 [00:48<06:44,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 197.jpg, AOI: 0.6414388020833334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 192/999 [00:48<06:42,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 198.jpg, AOI: 0.54140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 193/999 [00:49<06:40,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 199.jpg, AOI: 0.48880789620535714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  19%|█▉        | 194/999 [00:49<06:39,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 200.jpg, AOI: 0.633759765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|█▉        | 195/999 [00:50<06:43,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 201.jpg, AOI: 0.630126953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|█▉        | 196/999 [00:50<06:36,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 202.jpg, AOI: 0.6767578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|█▉        | 197/999 [00:51<06:43,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 203.jpg, AOI: 0.5519321986607143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|█▉        | 198/999 [00:51<07:42,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 204.jpg, AOI: 0.79013671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|█▉        | 199/999 [00:52<08:13,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 205.jpg, AOI: 0.67974853515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|██        | 200/999 [00:53<07:52,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 206.jpg, AOI: 0.39104817708333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|██        | 201/999 [00:53<08:12,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 207.jpg, AOI: 0.6927490234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|██        | 202/999 [00:54<08:13,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 208.jpg, AOI: 0.5587332589285714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|██        | 203/999 [00:54<07:39,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 209.jpg, AOI: 0.5757742745535714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  20%|██        | 204/999 [00:55<07:19,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 210.jpg, AOI: 0.5354352678571429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 205/999 [00:55<07:01,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 211.jpg, AOI: 0.5760672433035714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 206/999 [00:56<06:50,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 212.jpg, AOI: 0.6109619140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 207/999 [00:56<06:55,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 213.jpg, AOI: 0.5980224609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 208/999 [00:57<06:58,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 214.jpg, AOI: 0.54744873046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 209/999 [00:57<06:46,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 215.jpg, AOI: 0.6399204799107143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 210/999 [00:58<06:54,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 216.jpg, AOI: 0.539276123046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 211/999 [00:58<06:56,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 217.jpg, AOI: 0.52001953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██        | 212/999 [00:59<06:45,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 218.jpg, AOI: 0.5829275948660714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██▏       | 213/999 [00:59<06:37,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 219.jpg, AOI: 0.5508544921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  21%|██▏       | 214/999 [01:00<06:31,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 220.jpg, AOI: 0.5814174107142858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 215/999 [01:00<06:23,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 221.jpg, AOI: 0.48082449776785713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 216/999 [01:01<06:29,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 222.jpg, AOI: 0.7115169270833334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 217/999 [01:01<06:34,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 223.jpg, AOI: 0.8505208333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 218/999 [01:02<06:26,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 224.jpg, AOI: 0.5404122488839286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 219/999 [01:02<06:34,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 225.jpg, AOI: 0.914560546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 220/999 [01:03<06:25,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 226.jpg, AOI: 0.6239858774038461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 221/999 [01:03<06:24,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 227.jpg, AOI: 0.558984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 222/999 [01:04<06:33,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 228.jpg, AOI: 0.6724330357142857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 223/999 [01:05<06:58,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 229.jpg, AOI: 0.8140755208333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  22%|██▏       | 224/999 [01:05<07:19,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 230.jpg, AOI: 0.7763671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  23%|██▎       | 225/999 [01:06<08:07,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 231.jpg, AOI: 0.686370849609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  23%|██▎       | 226/999 [01:07<08:01,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 232.jpg, AOI: 0.8772739955357143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  23%|██▎       | 227/999 [01:07<07:58,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 233.jpg, AOI: 0.6362374441964286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Processing images:  23%|██▎       | 228/999 [01:08<03:50,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 234.jpg, AOI: 0.5539388020833333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot convert float NaN to integer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b29864c61a09>\u001b[0m in \u001b[0;36m<cell line: 171>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0msaliency_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOV5GradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m \u001b[0mcalculate_aoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaliency_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-b29864c61a09>\u001b[0m in \u001b[0;36mcalculate_aoi\u001b[0;34m(folder_path, csv_path, threshold, model, saliency_method, start_index, end_index)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mserial_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serial_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{int(serial_number)}.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**注目点色塗り**"
      ],
      "metadata": {
        "id": "fmGNyvTdM3c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#注目点に色を塗る（反転あり）\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from google.colab.patches import cv2_imshow\n",
        "from deep_utils import Box, split_extension\n",
        "import gc\n",
        "\n",
        "# パラメータ\n",
        "model_path = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial/99.jpg\"\n",
        "output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'\n",
        "img_size = 640\n",
        "target_layer = 'model_23_cv3_act'\n",
        "method = 'gradcam'\n",
        "device = 'cpu'\n",
        "names = [\"infection\",\"normal\",\"non-infection\",\"scar\",\"tumor\",\"deposit\",\"APAC\",\"lens opacity\",\"bullous\"]\n",
        "\n",
        "def get_res_img(bbox, masks, res_img):\n",
        "    for mask in masks:\n",
        "        mask = mask.squeeze().mul(255).add_(0.5).clamp_(0, 255).detach().cpu().numpy().astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
        "        n_heatmat = (Box.fill_outer_box(heatmap, bbox) / 255).astype(np.float32)\n",
        "        res_img = res_img / 255\n",
        "        res_img = cv2.add(res_img, n_heatmat)\n",
        "        res_img = (res_img / res_img.max())\n",
        "    return res_img, n_heatmat\n",
        "\n",
        "def put_text_box(bbox, cls_name, res_img):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cv2.imwrite('temp.jpg', (res_img * 255).astype(np.uint8))\n",
        "    res_img = cv2.imread('temp.jpg')\n",
        "    res_img = Box.put_box(res_img, bbox)\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 2.0\n",
        "    color = (0, 255, 0)\n",
        "    thickness = 2\n",
        "\n",
        "    text_size, _ = cv2.getTextSize(cls_name, font, font_scale, thickness)\n",
        "    text_x = 10\n",
        "    text_y = text_size[1] + 10\n",
        "\n",
        "    cv2.putText(res_img, cls_name, (text_x, text_y), font, font_scale, color, thickness)\n",
        "\n",
        "    return res_img\n",
        "\n",
        "def find_yolo_layer(model, layer_name):\n",
        "    hierarchy = layer_name.split('_')\n",
        "    target_layer = model.model._modules[hierarchy[0]]\n",
        "\n",
        "    for h in hierarchy[1:]:\n",
        "        target_layer = target_layer._modules[h]\n",
        "    return target_layer\n",
        "\n",
        "class YOLOV5GradCAM:\n",
        "    def __init__(self, model, layer_name, img_size=(640, 640)):\n",
        "        self.model = model\n",
        "        self.gradients = dict()\n",
        "        self.activations = dict()\n",
        "        self.cls_names = []\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients['value'] = grad_output[0]\n",
        "            return None\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations['value'] = output\n",
        "            return None\n",
        "\n",
        "        target_layer = find_yolo_layer(self.model, layer_name)\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        device = 'cuda' if next(self.model.model.parameters()).is_cuda else 'cpu'\n",
        "        self.model(torch.zeros(1, 3, *img_size, device=device))\n",
        "\n",
        "    def forward(self, input_img, class_idx=True):\n",
        "        saliency_maps = []\n",
        "        b, c, h, w = input_img.size()\n",
        "        preds, logits = self.model(input_img)\n",
        "        _, top1_idx = torch.topk(logits[0], k=1)\n",
        "\n",
        "        if top1_idx.numel() > 0:\n",
        "            preds[1][0] = top1_idx.tolist()[0]\n",
        "            preds[2][0] = [names[i] for i in preds[1][0]]\n",
        "            self.cls_names = preds[2][0]\n",
        "        else:\n",
        "            self.cls_names = []\n",
        "\n",
        "        cls, cls_name = preds[1][0][0], preds[2][0][0]\n",
        "        if class_idx:\n",
        "            score = logits[0][0][cls]\n",
        "        else:\n",
        "            score = logits[0][0].max()\n",
        "        self.model.zero_grad()\n",
        "        score.backward(retain_graph=True)\n",
        "        gradients = self.gradients['value']\n",
        "        activations = self.activations['value']\n",
        "        b, k, u, v = gradients.size()\n",
        "        alpha = gradients.view(b, k, -1).mean(2)\n",
        "        weights = alpha.view(b, k, 1, 1)\n",
        "        saliency_map = (weights * activations).sum(1, keepdim=True)\n",
        "        saliency_map = F.relu(saliency_map)\n",
        "        saliency_map = F.upsample(saliency_map, size=(h, w), mode='bilinear', align_corners=False)\n",
        "        saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
        "        saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
        "        saliency_maps.append(saliency_map)\n",
        "\n",
        "        return saliency_maps, logits, preds, self.cls_names\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "        return self.forward(input_img)\n",
        "\n",
        "def main(img_path, threshold=0.5):\n",
        "    input_size = (img_size, img_size)\n",
        "    img = cv2.imread(img_path)\n",
        "    model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size, names=names)\n",
        "    torch_img = model.preprocessing(img[..., ::-1])\n",
        "    if method == 'gradcam':\n",
        "        saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "    masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "    result = torch_img.squeeze(0).mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).detach().cpu().numpy()\n",
        "    result = result[..., ::-1]\n",
        "\n",
        "    if masks:\n",
        "        mask = masks[0].squeeze().cpu().numpy()\n",
        "        if mask.max() >= threshold:\n",
        "            binary_mask = np.where(mask >= threshold, 1, 0).astype(np.uint8)\n",
        "            black_mask = np.where(mask >= threshold, 0, 1).astype(np.uint8)\n",
        "            binary_mask = cv2.resize(binary_mask, (result.shape[1], result.shape[0]))\n",
        "            black_mask = cv2.resize(black_mask, (result.shape[1], result.shape[0]))\n",
        "\n",
        "            color = np.array([0,0,0], dtype=np.uint8) #マスクの色：白は[0,0,0]\n",
        "            masked_res_img = result * binary_mask[..., np.newaxis] + (1 - binary_mask[..., np.newaxis]) * color\n",
        "            masked_res_img = (masked_res_img / masked_res_img.max()) * 255\n",
        "\n",
        "            black_masked_res_img = result * black_mask[..., np.newaxis] + (1 - black_mask[..., np.newaxis]) * color\n",
        "            black_masked_res_img = (black_masked_res_img / black_masked_res_img.max()) * 255\n",
        "\n",
        "            cv2_imshow(masked_res_img.astype(np.uint8))\n",
        "            cv2_imshow(black_masked_res_img.astype(np.uint8))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    target_layer = 'model_23_cv3_conv'\n",
        "    img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial/8.jpg\"\n",
        "    output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'\n",
        "    threshold = 0.1  # ここで閾値を指定\n",
        "    if os.path.isdir(img_path):\n",
        "        folder_main(img_path, threshold)\n",
        "    else:\n",
        "        main(img_path, threshold)\n"
      ],
      "metadata": {
        "id": "sx9KdyNZNzz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 注目点をblurする（反転あり）\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from google.colab.patches import cv2_imshow\n",
        "from deep_utils import Box, split_extension\n",
        "import gc\n",
        "\n",
        "# パラメータ\n",
        "model_path = \"/gdrive/MyDrive/Deep_learning/CorneAI_nagoya/yolo5_forcresco/weights/eye_nii_2202_onecaseoneimage2_doctorcompare_yolov5s_epoch200_batch16_89.8p/last.pt\"\n",
        "img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial/99.jpg\"\n",
        "output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'\n",
        "img_size = 640\n",
        "target_layer = 'model_23_cv3_act'\n",
        "method = 'gradcam'\n",
        "device = 'cpu'\n",
        "names = [\"infection\",\"normal\",\"non-infection\",\"scar\",\"tumor\",\"deposit\",\"APAC\",\"lens opacity\",\"bullous\"]\n",
        "\n",
        "def get_res_img(bbox, masks, res_img):\n",
        "    for mask in masks:\n",
        "        mask = mask.squeeze().mul(255).add_(0.5).clamp_(0, 255).detach().cpu().numpy().astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
        "        n_heatmat = (Box.fill_outer_box(heatmap, bbox) / 255).astype(np.float32)\n",
        "        res_img = res_img / 255\n",
        "        res_img = cv2.add(res_img, n_heatmat)\n",
        "        res_img = (res_img / res_img.max())\n",
        "    return res_img, n_heatmat\n",
        "\n",
        "def put_text_box(bbox, cls_name, res_img):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cv2.imwrite('temp.jpg', (res_img * 255).astype(np.uint8))\n",
        "    res_img = cv2.imread('temp.jpg')\n",
        "    res_img = Box.put_box(res_img, bbox)\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 2.0\n",
        "    color = (0, 255, 0)\n",
        "    thickness = 2\n",
        "\n",
        "    text_size, _ = cv2.getTextSize(cls_name, font, font_scale, thickness)\n",
        "    text_x = 10\n",
        "    text_y = text_size[1] + 10\n",
        "\n",
        "    cv2.putText(res_img, cls_name, (text_x, text_y), font, font_scale, color, thickness)\n",
        "\n",
        "    return res_img\n",
        "\n",
        "def find_yolo_layer(model, layer_name):\n",
        "    hierarchy = layer_name.split('_')\n",
        "    target_layer = model.model._modules[hierarchy[0]]\n",
        "\n",
        "    for h in hierarchy[1:]:\n",
        "        target_layer = target_layer._modules[h]\n",
        "    return target_layer\n",
        "\n",
        "class YOLOV5GradCAM:\n",
        "    def __init__(self, model, layer_name, img_size=(640, 640)):\n",
        "        self.model = model\n",
        "        self.gradients = dict()\n",
        "        self.activations = dict()\n",
        "        self.cls_names = []\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients['value'] = grad_output[0]\n",
        "            return None\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations['value'] = output\n",
        "            return None\n",
        "\n",
        "        target_layer = find_yolo_layer(self.model, layer_name)\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        device = 'cuda' if next(self.model.model.parameters()).is_cuda else 'cpu'\n",
        "        self.model(torch.zeros(1, 3, *img_size, device=device))\n",
        "\n",
        "    def forward(self, input_img, class_idx=True):\n",
        "        saliency_maps = []\n",
        "        b, c, h, w = input_img.size()\n",
        "        preds, logits = self.model(input_img)\n",
        "        _, top1_idx = torch.topk(logits[0], k=1)\n",
        "\n",
        "        if top1_idx.numel() > 0:\n",
        "            preds[1][0] = top1_idx.tolist()[0]\n",
        "            preds[2][0] = [names[i] for i in preds[1][0]]\n",
        "            self.cls_names = preds[2][0]\n",
        "        else:\n",
        "            self.cls_names = []\n",
        "\n",
        "        cls, cls_name = preds[1][0][0], preds[2][0][0]\n",
        "        if class_idx:\n",
        "            score = logits[0][0][cls]\n",
        "        else:\n",
        "            score = logits[0][0].max()\n",
        "        self.model.zero_grad()\n",
        "        score.backward(retain_graph=True)\n",
        "        gradients = self.gradients['value']\n",
        "        activations = self.activations['value']\n",
        "        b, k, u, v = gradients.size()\n",
        "        alpha = gradients.view(b, k, -1).mean(2)\n",
        "        weights = alpha.view(b, k, 1, 1)\n",
        "        saliency_map = (weights * activations).sum(1, keepdim=True)\n",
        "        saliency_map = F.relu(saliency_map)\n",
        "        saliency_map = F.upsample(saliency_map, size=(h, w), mode='bilinear', align_corners=False)\n",
        "        saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
        "        saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
        "        saliency_maps.append(saliency_map)\n",
        "\n",
        "        return saliency_maps, logits, preds, self.cls_names\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "        return self.forward(input_img)\n",
        "\n",
        "def main(img_path, threshold=0.5):\n",
        "    input_size = (img_size, img_size)\n",
        "    img = cv2.imread(img_path)\n",
        "    model = YOLOV5TorchObjectDetector(model_path, device, img_size=input_size, names=names)\n",
        "    torch_img = model.preprocessing(img[..., ::-1])\n",
        "    if method == 'gradcam':\n",
        "        saliency_method = YOLOV5GradCAM(model=model, layer_name=target_layer, img_size=input_size)\n",
        "    masks, logits, [boxes, _, _, _], cls_names = saliency_method(torch_img)\n",
        "    result = torch_img.squeeze(0).mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).detach().cpu().numpy()\n",
        "    result = result[..., ::-1]\n",
        "\n",
        "    if masks:\n",
        "        mask = masks[0].squeeze().cpu().numpy()\n",
        "        if mask.max() >= threshold:\n",
        "            binary_mask = np.where(mask >= threshold, 1, 0).astype(np.uint8)\n",
        "            black_mask = np.where(mask >= threshold, 0, 1).astype(np.uint8)\n",
        "            binary_mask = cv2.resize(binary_mask, (result.shape[1], result.shape[0]))\n",
        "            black_mask = cv2.resize(black_mask, (result.shape[1], result.shape[0]))\n",
        "\n",
        "            # ぼかし効果を適用\n",
        "            blurred_result = cv2.GaussianBlur(result, (91, 91), 0)\n",
        "            masked_res_img = result * binary_mask[..., np.newaxis] + blurred_result * (1 - binary_mask[..., np.newaxis])\n",
        "            masked_res_img = (masked_res_img / masked_res_img.max()) * 255\n",
        "\n",
        "            black_blurred_result = cv2.GaussianBlur(result, (91, 91), 0)\n",
        "            black_masked_res_img = result * black_mask[..., np.newaxis] + black_blurred_result * (1 - black_mask[..., np.newaxis])\n",
        "            black_masked_res_img = (black_masked_res_img / black_masked_res_img.max()) * 255\n",
        "\n",
        "            cv2_imshow(masked_res_img.astype(np.uint8))\n",
        "            cv2_imshow(black_masked_res_img.astype(np.uint8))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    target_layer = 'model_23_cv3_conv'\n",
        "    img_path = \"/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial/41.jpg\"\n",
        "    output_dir = '/gdrive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問_GradCAM/GradCam_img_slit'\n",
        "    threshold = 0.3  # ここで閾値を指定\n",
        "    if os.path.isdir(img_path):\n",
        "        folder_main(img_path, threshold)\n",
        "    else:\n",
        "        main(img_path, threshold)\n"
      ],
      "metadata": {
        "id": "VEn_KHC-T8C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h03rgBUoWi_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}