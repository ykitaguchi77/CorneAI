{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgnr7SG6WkPA4vbuxfL/xM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CorneAI/blob/main/DreamBooth_Lora_automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOMFql9SeFFP",
        "outputId": "9cb33f5e-270d-4cfe-9b26-33b0ce3921f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\CorneAI\\\\sd-scripts'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd TrainingData_pterygium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NbX2fKZeSDy",
        "outputId": "8e8275c3-99d4-4216-c836-39ba22dc88de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MWGm262eYBN",
        "outputId": "c7ec8470-ad84-45b3-9675-9cdff22bd71a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ドライブ C のボリューム ラベルは WINDOWS です\n",
            " ボリューム シリアル番号は 2880-08EC です\n",
            "\n",
            " C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium のディレクトリ\n",
            "\n",
            "2023/07/23  17:03    <DIR>          .\n",
            "2023/07/11  01:02    <DIR>          ..\n",
            "2023/07/22  13:46    <DIR>          cataract_image_768letterbox\n",
            "2023/07/15  03:05             1,297 command_dreambooth.txt\n",
            "2023/07/22  13:55               745 command_dreambooth_multiclass_letterbox.txt\n",
            "2023/07/15  23:24               651 command_dreambooth_myt16mai.txt\n",
            "2023/07/17  20:06               702 command_dreambooth_myt16mai_letterbox.txt\n",
            "2023/07/18  00:53             1,060 command_dreambooth_myt16mai_letterbox_add.txt\n",
            "2023/07/22  16:04               700 command_dreambooth_normal_letterbox.txt\n",
            "2023/07/23  01:09               705 command_dreambooth_pterygium_letterbox.txt\n",
            "2023/07/23  17:06               764 command_dreambooth_pterygium123mai.txt\n",
            "2023/07/23  13:54               924 command_lora.txt\n",
            "2023/07/01  22:55                 0 config.txt\n",
            "2023/07/21  18:56               644 datasetconfig.toml\n",
            "2023/07/11  23:12               443 datasetconfig_dreambooth.toml\n",
            "2023/07/18  03:46               456 datasetconfig_dreambooth_letterbox.toml\n",
            "2023/07/22  02:33               445 datasetconfig_dreambooth_multiclass_letterbox.toml\n",
            "2023/07/15  23:31               459 datasetconfig_dreambooth_myt16mai.toml\n",
            "2023/07/18  03:32               466 datasetconfig_dreambooth_myt16mai_letterbox.toml\n",
            "2023/07/23  17:06               637 datasetconfig_dreambooth_pterygium_123mai.toml\n",
            "2023/07/22  17:17               630 datasetconfig_dreambooth_pterygium_letterbox.toml\n",
            "2023/07/23  13:55               649 datasetconfig_lora.toml\n",
            "2023/07/22  02:03    <DIR>          multiclass_768px_letterbox_dreambooth\n",
            "2023/07/23  19:40    <DIR>          outputs\n",
            "2023/07/22  13:45    <DIR>          pterygium_image_768letterbox\n",
            "2023/07/23  16:58    <DIR>          pterygium_image_768letterbox_123mai\n",
            "2023/07/23  09:53    <DIR>          pterygium_image_768letterbox_28mai\n",
            "2023/07/11  12:23    <DIR>          regularized_image\n",
            "2023/07/15  23:13    <DIR>          regularized_image_768_normal_myt16mai_dreambooth\n",
            "2023/07/18  03:20    <DIR>          regularized_image_768letterbox_normal_dreambooth\n",
            "2023/07/16  01:06    <DIR>          regularized_image_768letterbox_normal_myt16mai_dreambooth\n",
            "2023/07/11  12:36    <DIR>          regularized_image_768px\n",
            "2023/07/14  08:54    <DIR>          regularized_image_768px_dreambooth\n",
            "2023/07/11  18:16    <DIR>          regularized_image_768px_dreambooth_4mai\n",
            "2023/07/18  08:01    <DIR>          regularized_image_768px_normal_dreambooth\n",
            "2023/07/22  13:46    <DIR>          rojinkan_image_768letterbox\n",
            "2023/07/22  13:42    <DIR>          sltphoto_normal_image_768letterbox\n",
            "2023/07/03  10:19               256 tags_to_exclude.txt\n",
            "2023/07/11  00:38    <DIR>          train_image\n",
            "2023/07/21  18:35    <DIR>          train_image_10mai_pte_768px_letterbox\n",
            "2023/07/11  01:34    <DIR>          train_image_768px\n",
            "2023/07/21  18:26    <DIR>          train_image_768px_letterbox\n",
            "              20 個のファイル              12,633 バイト\n",
            "              22 個のディレクトリ  1,647,381,504,000 バイトの空き領域\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pterygiumのフォルダを作る（command, tomlファイルを作成）\n",
        "%mkdir dreambooth_pterygium\n",
        "%cd dreambooth_pterygium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h3klru1gw2b",
        "outputId": "ffd08246-c49c-4218-af17-5fe389a04223"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\dreambooth_pterygium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "サブディレクトリまたはファイル dreambooth_pterygium は既に存在します。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DreamBooth**"
      ],
      "metadata": {
        "id": "GWbteZueIOSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tomlファイルを作成\n",
        "%%writefile datasetconfig_dreambooth_pterygium_123mai.toml\n",
        "\n",
        "[general]\n",
        "enable_bucket = true                       # Aspect Ratio Bucketingを使うか否か\n",
        "bucket_no_upscale = true\n",
        "\n",
        "[[datasets]]\n",
        "#resolution = 768, 768                           # 学習解像度\n",
        "batch_size = 4                              # バッチサイズ\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = 'C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\pterygium_image_768letterbox_123mai'\n",
        "caption_extension = '.txt'\n",
        "num_repeats = 10\n",
        "\n",
        "#[[datasets.subsets]]\n",
        "#is_reg = true\n",
        "#image_dir = 'C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\sltphoto_normal_image_768letterbox'\n",
        "#class_tokens = 'sltphoto'\n",
        "#num_repeats = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPyLR5ApgO7A",
        "outputId": "9986921f-9016-426f-fe24-980845303351"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting datasetconfig_dreambooth_pterygium_123mai.toml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protocolの記録\n",
        "%%writefile protocol_dreambooth_pterygium_123mai.txt\n",
        "\n",
        ".\\venv\\Scripts\\activate\n",
        "300 - 600 - 1200 - 2400 - 4800 - 9600 stepsで比較\n",
        "\n",
        "以下command\n",
        "\n",
        "# 300 steps\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_db.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\ACertainty.ckpt --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\datasetconfig_dreambooth_pterygium_letterbox.toml --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --output_name=sltphoto_pterygium_123mai_10times300steps --save_model_as=safetensors --resolution=768,768 --prior_loss_weight=1.0 --train_batch_size=4 --max_train_steps=300 --learning_rate=1e-6 --optimizer_type=\"AdamW8bit\" --xformers --mixed_precision=\"fp16\" --cache_latents --gradient_checkpointing\n",
        "\n",
        "# 600 steps\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_db.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\ACertainty.ckpt --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\datasetconfig_dreambooth_pterygium_letterbox.toml --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --output_name=sltphoto_pterygium_letterbox768_10times600steps --save_model_as=safetensors --resolution=768,768 --prior_loss_weight=1.0 --train_batch_size=4 --max_train_steps=600 --learning_rate=1e-6 --optimizer_type=\"AdamW8bit\" --xformers --mixed_precision=\"fp16\" --cache_latents --gradient_checkpointing\n",
        "\n",
        "# 1200 steps\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_db.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\ACertainty.ckpt --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\datasetconfig_dreambooth_pterygium_letterbox.toml --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --output_name=sltphoto_pterygium_letterbox768_10times1200steps --save_model_as=safetensors --resolution=768,768 --prior_loss_weight=1.0 --train_batch_size=4 --max_train_steps=1200 --learning_rate=1e-6 --optimizer_type=\"AdamW8bit\" --xformers --mixed_precision=\"fp16\" --cache_latents --gradient_checkpointing\n",
        "\n",
        "# 2400 steps\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_db.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\ACertainty.ckpt --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\datasetconfig_dreambooth_pterygium_letterbox.toml --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --output_name=sltphoto_pterygium_letterbox768_10times2400steps --save_model_as=safetensors --resolution=768,768 --prior_loss_weight=1.0 --train_batch_size=4 --max_train_steps=2400 --learning_rate=1e-6 --optimizer_type=\"AdamW8bit\" --xformers --mixed_precision=\"fp16\" --cache_latents --gradient_checkpointing\n",
        "\n",
        "# 4800 steps\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_db.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\ACertainty.ckpt --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\datasetconfig_dreambooth_pterygium_letterbox.toml --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --output_name=sltphoto_pterygium_letterbox768_10times4800steps --save_model_as=safetensors --resolution=768,768 --prior_loss_weight=1.0 --train_batch_size=4 --max_train_steps=4800 --learning_rate=1e-6 --optimizer_type=\"AdamW8bit\" --xformers --mixed_precision=\"fp16\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mGw3UjJotMG",
        "outputId": "e5eaa4e8-afec-451f-900c-3cf288451a7a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing protocol_dreambooth_pterygium_123mai.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def reader(pipe, func):\n",
        "    try:\n",
        "        with pipe:\n",
        "            for line in iter(pipe.readline, b''):\n",
        "                func(line)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def train_dreambooth(num_train_step):\n",
        "    command = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"--num_cpu_threads_per_process\", \"1\",\n",
        "    \"train_db.py\",\n",
        "    \"--pretrained_model_name_or_path=C:\\\\Users\\\\CorneAI\\\\stable-diffusion-webui\\\\models\\\\Stable-diffusion\\\\ACertainty.ckpt\",\n",
        "    \"--dataset_config=C:\\\\Users\\\\CorneAI\\\\sd-scripts\\\\TrainingData_pterygium\\\\datasetconfig_dreambooth_pterygium_letterbox.toml\",\n",
        "    \"--output_dir=C:\\\\Users\\\\CorneAI\\\\sd-scripts\\\\TrainingData_pterygium\\\\outputs\",\n",
        "    f\"--output_name=sltphoto_pterygium_123mai_10times{num_train_step}steps\",\n",
        "    \"--save_model_as=safetensors\",\n",
        "    \"--resolution=768,768\",\n",
        "    \"--prior_loss_weight=1.0\",\n",
        "    \"--train_batch_size=4\",\n",
        "    f\"--max_train_steps={num_train_step}\",\n",
        "    \"--learning_rate=1e-6\",\n",
        "    \"--optimizer_type=AdamW8bit\",\n",
        "    \"--xformers\",\n",
        "    \"--mixed_precision=fp16\",\n",
        "    \"--cache_latents\",\n",
        "    \"--gradient_checkpointing\"\n",
        "    ]\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "    threading.Thread(target=reader, args=[process.stdout, lambda x: print(f\"stdout: {x}\")]).start()\n",
        "    threading.Thread(target=reader, args=[process.stderr, lambda x: print(f\"stderr: {x}\")]).start()\n",
        "\n",
        "    process.wait()\n"
      ],
      "metadata": {
        "id": "t9mezTuXQFOk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 300 steps\n",
        "train_dreambooth(num_train_step=300)"
      ],
      "metadata": {
        "id": "Ufoewmv6Qu6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 600 steps\n",
        "train_dreambooth(num_train_step=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEG4wOE8R3X2",
        "outputId": "ff6dd7d4-9085-4708-e250-6bd87b678d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stderr: steps:  50%|#####     | 300/600 [14:53<14:53,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  50%|#####     | 301/600 [14:56<14:50,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  50%|#####     | 301/600 [14:56<14:50,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  50%|#####     | 302/600 [14:59<14:47,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  50%|#####     | 302/600 [14:59<14:47,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  50%|#####     | 303/600 [15:02<14:44,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  50%|#####     | 303/600 [15:02<14:44,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####     | 304/600 [15:06<14:42,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####     | 304/600 [15:06<14:42,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####     | 305/600 [15:08<14:39,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####     | 305/600 [15:08<14:39,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####1    | 306/600 [15:11<14:36,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####1    | 306/600 [15:11<14:36,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####1    | 307/600 [15:14<14:32,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  51%|#####1    | 307/600 [15:14<14:32,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  51%|#####1    | 308/600 [15:17<14:30,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  51%|#####1    | 308/600 [15:17<14:30,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####1    | 309/600 [15:20<14:27,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####1    | 309/600 [15:20<14:27,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####1    | 310/600 [15:23<14:24,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####1    | 310/600 [15:23<14:24,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####1    | 311/600 [15:27<14:21,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####1    | 311/600 [15:27<14:21,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 312/600 [15:30<14:18,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 312/600 [15:30<14:18,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 313/600 [15:33<14:15,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 313/600 [15:33<14:15,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 314/600 [15:36<14:12,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 314/600 [15:36<14:12,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 315/600 [15:39<14:09,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  52%|#####2    | 315/600 [15:39<14:09,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####2    | 316/600 [15:42<14:06,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####2    | 316/600 [15:42<14:06,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####2    | 317/600 [15:44<14:03,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####2    | 317/600 [15:44<14:03,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####3    | 318/600 [15:48<14:00,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####3    | 318/600 [15:48<14:00,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####3    | 319/600 [15:51<13:58,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####3    | 319/600 [15:51<13:58,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####3    | 320/600 [15:54<13:55,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  53%|#####3    | 320/600 [15:54<13:55,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####3    | 321/600 [15:57<13:52,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####3    | 321/600 [15:57<13:52,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####3    | 322/600 [16:00<13:49,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####3    | 322/600 [16:00<13:49,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####3    | 323/600 [16:03<13:46,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####3    | 323/600 [16:03<13:46,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####4    | 324/600 [16:06<13:43,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####4    | 324/600 [16:06<13:43,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####4    | 325/600 [16:09<13:40,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####4    | 325/600 [16:09<13:40,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####4    | 326/600 [16:12<13:37,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  54%|#####4    | 326/600 [16:12<13:37,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####4    | 327/600 [16:15<13:34,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####4    | 327/600 [16:15<13:34,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####4    | 328/600 [16:18<13:31,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####4    | 328/600 [16:18<13:31,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####4    | 329/600 [16:21<13:28,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####4    | 329/600 [16:21<13:28,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####5    | 330/600 [16:24<13:25,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####5    | 330/600 [16:24<13:25,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####5    | 331/600 [16:27<13:22,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  55%|#####5    | 331/600 [16:27<13:22,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  55%|#####5    | 332/600 [16:30<13:19,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  55%|#####5    | 332/600 [16:30<13:19,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  56%|#####5    | 333/600 [16:33<13:16,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  56%|#####5    | 333/600 [16:33<13:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####5    | 334/600 [16:36<13:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####5    | 334/600 [16:36<13:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####5    | 335/600 [16:39<13:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####5    | 335/600 [16:39<13:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 336/600 [16:42<13:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 336/600 [16:42<13:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 337/600 [16:45<13:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 337/600 [16:45<13:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 338/600 [16:47<13:01,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 338/600 [16:47<13:01,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 339/600 [16:50<12:58,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  56%|#####6    | 339/600 [16:50<12:58,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####6    | 340/600 [16:53<12:55,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####6    | 340/600 [16:53<12:55,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####6    | 341/600 [16:56<12:52,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####6    | 341/600 [16:56<12:52,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####6    | 342/600 [17:00<12:49,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####6    | 342/600 [17:00<12:49,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####7    | 343/600 [17:03<12:46,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####7    | 343/600 [17:03<12:46,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####7    | 344/600 [17:06<12:43,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####7    | 344/600 [17:06<12:43,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####7    | 345/600 [17:08<12:40,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  57%|#####7    | 345/600 [17:08<12:40,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####7    | 346/600 [17:11<12:37,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####7    | 346/600 [17:11<12:37,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####7    | 347/600 [17:14<12:34,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####7    | 347/600 [17:14<12:34,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 348/600 [17:17<12:31,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 348/600 [17:17<12:31,  2.98s/it, loss=0.111]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 349/600 [17:20<12:28,  2.98s/it, loss=0.111]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 349/600 [17:20<12:28,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 350/600 [17:23<12:25,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 350/600 [17:23<12:25,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 351/600 [17:26<12:22,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  58%|#####8    | 351/600 [17:26<12:22,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####8    | 352/600 [17:30<12:19,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####8    | 352/600 [17:30<12:19,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####8    | 353/600 [17:33<12:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####8    | 353/600 [17:33<12:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####8    | 354/600 [17:36<12:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####8    | 354/600 [17:36<12:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####9    | 355/600 [17:38<12:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####9    | 355/600 [17:38<12:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####9    | 356/600 [17:41<12:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  59%|#####9    | 356/600 [17:41<12:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  60%|#####9    | 357/600 [17:44<12:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  60%|#####9    | 357/600 [17:44<12:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  60%|#####9    | 358/600 [17:47<12:01,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  60%|#####9    | 358/600 [17:47<12:01,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  60%|#####9    | 359/600 [17:50<11:58,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  60%|#####9    | 359/600 [17:50<11:58,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 360/600 [17:53<11:55,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 360/600 [17:53<11:55,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 361/600 [17:56<11:52,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 361/600 [17:56<11:52,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 362/600 [17:59<11:49,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 362/600 [17:59<11:49,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 363/600 [18:02<11:46,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  60%|######    | 363/600 [18:02<11:46,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######    | 364/600 [18:05<11:43,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######    | 364/600 [18:05<11:43,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######    | 365/600 [18:08<11:41,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######    | 365/600 [18:08<11:41,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  61%|######1   | 366/600 [18:11<11:38,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  61%|######1   | 366/600 [18:11<11:38,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######1   | 367/600 [18:14<11:35,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######1   | 367/600 [18:14<11:35,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######1   | 368/600 [18:17<11:31,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  61%|######1   | 368/600 [18:17<11:31,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######1   | 369/600 [18:20<11:28,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######1   | 369/600 [18:20<11:28,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######1   | 370/600 [18:23<11:25,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######1   | 370/600 [18:23<11:25,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######1   | 371/600 [18:26<11:22,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######1   | 371/600 [18:26<11:22,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######2   | 372/600 [18:29<11:19,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######2   | 372/600 [18:29<11:19,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######2   | 373/600 [18:32<11:16,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######2   | 373/600 [18:32<11:16,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######2   | 374/600 [18:35<11:13,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  62%|######2   | 374/600 [18:35<11:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  62%|######2   | 375/600 [18:37<11:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  62%|######2   | 375/600 [18:37<11:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  63%|######2   | 376/600 [18:41<11:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  63%|######2   | 376/600 [18:41<11:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  63%|######2   | 377/600 [18:43<11:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  63%|######2   | 377/600 [18:43<11:04,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  63%|######3   | 378/600 [18:46<11:01,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  63%|######3   | 378/600 [18:46<11:01,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  63%|######3   | 379/600 [18:49<10:58,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  63%|######3   | 379/600 [18:49<10:58,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  63%|######3   | 380/600 [18:52<10:55,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  63%|######3   | 380/600 [18:52<10:55,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######3   | 381/600 [18:55<10:52,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######3   | 381/600 [18:55<10:52,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######3   | 382/600 [18:58<10:49,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######3   | 382/600 [18:58<10:49,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######3   | 383/600 [19:01<10:46,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######3   | 383/600 [19:01<10:46,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 384/600 [19:04<10:43,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 384/600 [19:04<10:43,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 385/600 [19:07<10:40,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 385/600 [19:07<10:40,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 386/600 [19:10<10:37,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 386/600 [19:10<10:37,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 387/600 [19:13<10:34,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  64%|######4   | 387/600 [19:13<10:34,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######4   | 388/600 [19:15<10:31,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######4   | 388/600 [19:15<10:31,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######4   | 389/600 [19:18<10:28,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######4   | 389/600 [19:18<10:28,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######5   | 390/600 [19:21<10:25,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######5   | 390/600 [19:21<10:25,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######5   | 391/600 [19:24<10:22,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  65%|######5   | 391/600 [19:24<10:22,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  65%|######5   | 392/600 [19:27<10:19,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  65%|######5   | 392/600 [19:27<10:19,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######5   | 393/600 [19:30<10:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######5   | 393/600 [19:30<10:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######5   | 394/600 [19:33<10:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######5   | 394/600 [19:33<10:13,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  66%|######5   | 395/600 [19:36<10:10,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  66%|######5   | 395/600 [19:36<10:10,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######6   | 396/600 [19:39<10:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######6   | 396/600 [19:39<10:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######6   | 397/600 [19:42<10:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######6   | 397/600 [19:42<10:04,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######6   | 398/600 [19:45<10:01,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  66%|######6   | 398/600 [19:45<10:01,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  66%|######6   | 399/600 [19:48<09:58,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  66%|######6   | 399/600 [19:48<09:58,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######6   | 400/600 [19:51<09:55,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######6   | 400/600 [19:51<09:55,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######6   | 401/600 [19:54<09:52,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######6   | 401/600 [19:54<09:52,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######7   | 402/600 [19:57<09:49,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######7   | 402/600 [19:57<09:49,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######7   | 403/600 [20:00<09:46,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######7   | 403/600 [20:00<09:46,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######7   | 404/600 [20:03<09:43,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  67%|######7   | 404/600 [20:03<09:43,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######7   | 405/600 [20:06<09:40,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######7   | 405/600 [20:06<09:40,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######7   | 406/600 [20:09<09:37,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######7   | 406/600 [20:09<09:37,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######7   | 407/600 [20:12<09:34,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######7   | 407/600 [20:12<09:34,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######8   | 408/600 [20:15<09:31,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######8   | 408/600 [20:15<09:31,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######8   | 409/600 [20:18<09:28,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######8   | 409/600 [20:18<09:28,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######8   | 410/600 [20:21<09:25,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  68%|######8   | 410/600 [20:21<09:25,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  68%|######8   | 411/600 [20:24<09:22,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  68%|######8   | 411/600 [20:24<09:22,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######8   | 412/600 [20:27<09:19,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######8   | 412/600 [20:27<09:19,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######8   | 413/600 [20:29<09:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######8   | 413/600 [20:29<09:16,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######9   | 414/600 [20:32<09:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######9   | 414/600 [20:32<09:13,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######9   | 415/600 [20:36<09:11,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######9   | 415/600 [20:36<09:11,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######9   | 416/600 [20:38<09:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  69%|######9   | 416/600 [20:38<09:07,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|######9   | 417/600 [20:42<09:05,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|######9   | 417/600 [20:42<09:05,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|######9   | 418/600 [20:44<09:02,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|######9   | 418/600 [20:44<09:02,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|######9   | 419/600 [20:47<08:59,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|######9   | 419/600 [20:47<08:59,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 420/600 [20:50<08:56,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 420/600 [20:50<08:56,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 421/600 [20:53<08:53,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 421/600 [20:53<08:53,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 422/600 [20:57<08:50,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 422/600 [20:57<08:50,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 423/600 [20:59<08:47,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  70%|#######   | 423/600 [20:59<08:47,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######   | 424/600 [21:02<08:44,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######   | 424/600 [21:02<08:44,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######   | 425/600 [21:05<08:41,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######   | 425/600 [21:05<08:41,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######1  | 426/600 [21:08<08:38,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######1  | 426/600 [21:08<08:38,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######1  | 427/600 [21:12<08:35,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######1  | 427/600 [21:12<08:35,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######1  | 428/600 [21:14<08:32,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  71%|#######1  | 428/600 [21:14<08:32,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######1  | 429/600 [21:18<08:29,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######1  | 429/600 [21:18<08:29,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######1  | 430/600 [21:20<08:26,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######1  | 430/600 [21:20<08:26,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######1  | 431/600 [21:23<08:23,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######1  | 431/600 [21:23<08:23,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 432/600 [21:27<08:20,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 432/600 [21:27<08:20,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 433/600 [21:29<08:17,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 433/600 [21:29<08:17,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 434/600 [21:32<08:14,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 434/600 [21:32<08:14,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 435/600 [21:36<08:11,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  72%|#######2  | 435/600 [21:36<08:11,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  73%|#######2  | 436/600 [21:38<08:08,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  73%|#######2  | 436/600 [21:38<08:08,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######2  | 437/600 [21:42<08:05,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######2  | 437/600 [21:42<08:05,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######3  | 438/600 [21:45<08:02,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######3  | 438/600 [21:45<08:02,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######3  | 439/600 [21:48<07:59,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######3  | 439/600 [21:48<07:59,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######3  | 440/600 [21:50<07:56,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  73%|#######3  | 440/600 [21:50<07:56,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######3  | 441/600 [21:53<07:53,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######3  | 441/600 [21:53<07:53,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######3  | 442/600 [21:57<07:50,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######3  | 442/600 [21:57<07:50,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######3  | 443/600 [21:59<07:47,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######3  | 443/600 [21:59<07:47,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 444/600 [22:02<07:44,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 444/600 [22:02<07:44,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 445/600 [22:05<07:41,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 445/600 [22:05<07:41,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 446/600 [22:08<07:38,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 446/600 [22:08<07:38,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 447/600 [22:11<07:35,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  74%|#######4  | 447/600 [22:11<07:35,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######4  | 448/600 [22:14<07:32,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######4  | 448/600 [22:14<07:32,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######4  | 449/600 [22:17<07:29,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######4  | 449/600 [22:17<07:29,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######5  | 450/600 [22:20<07:26,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######5  | 450/600 [22:20<07:26,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######5  | 451/600 [22:23<07:23,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######5  | 451/600 [22:23<07:23,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######5  | 452/600 [22:26<07:20,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  75%|#######5  | 452/600 [22:26<07:20,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######5  | 453/600 [22:29<07:17,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######5  | 453/600 [22:29<07:17,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######5  | 454/600 [22:32<07:15,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######5  | 454/600 [22:32<07:15,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######5  | 455/600 [22:35<07:12,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######5  | 455/600 [22:35<07:12,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 456/600 [22:38<07:09,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 456/600 [22:38<07:09,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 457/600 [22:41<07:06,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 457/600 [22:41<07:06,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 458/600 [22:44<07:03,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 458/600 [22:44<07:03,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 459/600 [22:47<07:00,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  76%|#######6  | 459/600 [22:47<07:00,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  77%|#######6  | 460/600 [22:50<06:57,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  77%|#######6  | 460/600 [22:50<06:57,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  77%|#######6  | 461/600 [22:53<06:54,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  77%|#######6  | 461/600 [22:53<06:54,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  77%|#######7  | 462/600 [22:56<06:51,  2.98s/it, loss=0.113]\n",
            "\n",
            "stderr: steps:  77%|#######7  | 462/600 [22:56<06:51,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  77%|#######7  | 463/600 [22:59<06:48,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  77%|#######7  | 463/600 [22:59<06:48,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  77%|#######7  | 464/600 [23:03<06:45,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  77%|#######7  | 464/600 [23:03<06:45,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######7  | 465/600 [23:06<06:42,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######7  | 465/600 [23:06<06:42,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######7  | 466/600 [23:09<06:39,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######7  | 466/600 [23:09<06:39,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######7  | 467/600 [23:11<06:36,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######7  | 467/600 [23:11<06:36,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######8  | 468/600 [23:15<06:33,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######8  | 468/600 [23:15<06:33,  2.98s/it, loss=0.112]\n",
            "\n",
            "stderr: steps:  78%|#######8  | 469/600 [23:18<06:30,  2.98s/it, loss=0.112]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4800 steps\n",
        "train_dreambooth(num_train_step=4800)"
      ],
      "metadata": {
        "id": "zQ_wWH9pSDkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkUdVQSdE_CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lora**"
      ],
      "metadata": {
        "id": "N0KrDJ1hIc_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\dreambooth_pterygium\""
      ],
      "metadata": {
        "id": "t5gF4wQFL1cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\n",
        "\n",
        "# pterygiumのフォルダを作る（command, tomlファイルを作成）\n",
        "%mkdir lora_pterygium\n",
        "%cd lora_pterygium"
      ],
      "metadata": {
        "id": "dDFUZPubLe6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tomlファイルを作成\n",
        "%%writefile datasetconfig_Lora_pterygium_28mai.toml\n",
        "\n",
        "[general]\n",
        "enable_bucket = true                       # Aspect Ratio Bucketingを使うか否か\n",
        "bucket_no_upscale = true\n",
        "\n",
        "[[datasets]]\n",
        "#resolution = 768, 768\n",
        "#batch_size = 4                           # バッチサイズ\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = 'C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\pterygium_image_768letterbox_28mai'\n",
        "caption_extension = '.txt'\n",
        "num_repeats = 6\n",
        "\n",
        "# 正則化をする場合は以下を追加\n",
        "#[[datasets.subsets]]\n",
        "#is_reg = true\n",
        "#image_dir ='C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\regularized_image_768letterbox_normal_dreambooth'\n",
        "#class_tokens = 'sltphoto'\n",
        "#num_repeats = 1"
      ],
      "metadata": {
        "id": "18-F1dvLIsuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# protocolの記録\n",
        "%%writefile protocol_lora_pterygium_123mai.txt\n",
        "\n",
        ".\\venv\\Scripts\\activate\n",
        "2 - 4 - 8 - 16 - 32 - 64 epochsで比較 (repeat=6)\n",
        "\n",
        "以下command\n",
        "\n",
        "# 2epochs\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\sltphoto_pterygium_123mai_10times300steps.safetensors --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\lora_pterygium\\ datasetconfig_Lora_pterygium_28mai.toml --output_name=lora_pte_28mai_rep6epoch2 --train_batch_size=4 --max_train_epochs=2 --resolution=768,768 --optimizer_type=AdamW8bit --learning_rate=1e-4 --network_dim=128 --network_alpha=64 --lr_scheduler=cosine_with_restarts --lr_scheduler_num_cycles=4 --lr_warmup_steps=500 --keep_tokens=1 --shuffle_caption --caption_dropout_rate=0.05 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --xformers --mixed_precision=fp16 --network_module=networks.lora --persistent_data_loader_workers\n",
        "\n",
        "# 4epochs\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\sltphoto_pterygium_123mai_10times300steps.safetensors --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\lora_pterygium\\ datasetconfig_Lora_pterygium_28mai.toml --output_name=lora_pte_28mai_rep6epoch4 --train_batch_size=4 --max_train_epochs=4 --resolution=768,768 --optimizer_type=AdamW8bit --learning_rate=1e-4 --network_dim=128 --network_alpha=64 --lr_scheduler=cosine_with_restarts --lr_scheduler_num_cycles=4 --lr_warmup_steps=500 --keep_tokens=1 --shuffle_caption --caption_dropout_rate=0.05 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --xformers --mixed_precision=fp16 --network_module=networks.lora --persistent_data_loader_workers\n",
        "\n",
        "# 8epochs\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\sltphoto_pterygium_123mai_10times300steps.safetensors --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\lora_pterygium\\ datasetconfig_Lora_pterygium_28mai.toml --output_name=lora_pte_28mai_rep6epoch8 --train_batch_size=4 --max_train_epochs=8 --resolution=768,768 --optimizer_type=AdamW8bit --learning_rate=1e-4 --network_dim=128 --network_alpha=64 --lr_scheduler=cosine_with_restarts --lr_scheduler_num_cycles=4 --lr_warmup_steps=500 --keep_tokens=1 --shuffle_caption --caption_dropout_rate=0.05 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --xformers --mixed_precision=fp16 --network_module=networks.lora --persistent_data_loader_workers\n",
        "\n",
        "# 16epochs\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\sltphoto_pterygium_123mai_10times300steps.safetensors --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\lora_pterygium\\ datasetconfig_Lora_pterygium_28mai.toml --output_name=lora_pte_28mai_rep6epoch16 --train_batch_size=4 --max_train_epochs=16 --resolution=768,768 --optimizer_type=AdamW8bit --learning_rate=1e-4 --network_dim=128 --network_alpha=64 --lr_scheduler=cosine_with_restarts --lr_scheduler_num_cycles=4 --lr_warmup_steps=500 --keep_tokens=1 --shuffle_caption --caption_dropout_rate=0.05 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --xformers --mixed_precision=fp16 --network_module=networks.lora --persistent_data_loader_workers\n",
        "\n",
        "# 32epochs\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\sltphoto_pterygium_123mai_10times300steps.safetensors --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\lora_pterygium\\ datasetconfig_Lora_pterygium_28mai.toml --output_name=lora_pte_28mai_rep6epoch32 --train_batch_size=4 --max_train_epochs=32 --resolution=768,768 --optimizer_type=AdamW8bit --learning_rate=1e-4 --network_dim=128 --network_alpha=64 --lr_scheduler=cosine_with_restarts --lr_scheduler_num_cycles=4 --lr_warmup_steps=500 --keep_tokens=1 --shuffle_caption --caption_dropout_rate=0.05 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --xformers --mixed_precision=fp16 --network_module=networks.lora --persistent_data_loader_workers\n",
        "\n",
        "# 64epochs\n",
        "accelerate launch --num_cpu_threads_per_process 1 train_network.py --pretrained_model_name_or_path=C:\\Users\\CorneAI\\stable-diffusion-webui\\models\\Stable-diffusion\\sltphoto_pterygium_123mai_10times300steps.safetensors --output_dir=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\outputs --dataset_config=C:\\Users\\CorneAI\\sd-scripts\\TrainingData_pterygium\\lora_pterygium\\ datasetconfig_Lora_pterygium_28mai.toml --output_name=lora_pte_28mai_rep6epoch64 --train_batch_size=4 --max_train_epochs=64 --resolution=768,768 --optimizer_type=AdamW8bit --learning_rate=1e-4 --network_dim=128 --network_alpha=64 --lr_scheduler=cosine_with_restarts --lr_scheduler_num_cycles=4 --lr_warmup_steps=500 --keep_tokens=1 --shuffle_caption --caption_dropout_rate=0.05 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --xformers --mixed_precision=fp16 --network_module=networks.lora --persistent_data_loader_workers"
      ],
      "metadata": {
        "id": "V8R3rHgeIs0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def reader(pipe, func):\n",
        "    try:\n",
        "        with pipe:\n",
        "            for line in iter(pipe.readline, b''):\n",
        "                func(line)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def train_dreambooth(num_train_step):\n",
        "    command = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"--num_cpu_threads_per_process\", \"1\",\n",
        "    \"train_db.py\",\n",
        "    \"--pretrained_model_name_or_path=C:\\\\Users\\\\CorneAI\\\\stable-diffusion-webui\\\\models\\\\Stable-diffusion\\\\ACertainty.ckpt\",\n",
        "    \"--dataset_config=C:\\\\Users\\\\CorneAI\\\\sd-scripts\\\\TrainingData_pterygium\\\\datasetconfig_dreambooth_pterygium_letterbox.toml\",\n",
        "    \"--output_dir=C:\\\\Users\\\\CorneAI\\\\sd-scripts\\\\TrainingData_pterygium\\\\outputs\",\n",
        "    f\"--output_name=sltphoto_pterygium_123mai_10times{num_train_step}steps\",\n",
        "    \"--save_model_as=safetensors\",\n",
        "    \"--resolution=768,768\",\n",
        "    \"--prior_loss_weight=1.0\",\n",
        "    \"--train_batch_size=4\",\n",
        "    f\"--max_train_steps={num_train_step}\",\n",
        "    \"--learning_rate=1e-6\",\n",
        "    \"--optimizer_type=AdamW8bit\",\n",
        "    \"--xformers\",\n",
        "    \"--mixed_precision=fp16\",\n",
        "    \"--cache_latents\",\n",
        "    \"--gradient_checkpointing\"\n",
        "    ]\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "    threading.Thread(target=reader, args=[process.stdout, lambda x: print(f\"stdout: {x}\")]).start()\n",
        "    threading.Thread(target=reader, args=[process.stderr, lambda x: print(f\"stderr: {x}\")]).start()\n",
        "\n",
        "    process.wait()\n"
      ],
      "metadata": {
        "id": "iKxGx7NgIs2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def reader(pipe, func):\n",
        "    try:\n",
        "        with pipe:\n",
        "            for line in iter(pipe.readline, ''):\n",
        "                func(line)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def train_network(num_epochs):\n",
        "    command = [\n",
        "        \"accelerate\", \"launch\",\n",
        "        \"--num_cpu_threads_per_process\", \"1\",\n",
        "        \"train_network.py\",\n",
        "        \"--pretrained_model_name_or_path=C:\\\\Users\\\\CorneAI\\\\stable-diffusion-webui\\\\models\\\\Stable-diffusion\\\\sltphoto_pterygium_123mai_10times2400steps.safetensors\",\n",
        "        \"--output_dir=C:\\\\Users\\\\CorneAI\\\\sd-scripts\\\\TrainingData_pterygium\\\\outputs\",\n",
        "        \"--dataset_config=C:\\\\Users\\\\CorneAI\\\\sd-scripts\\\\TrainingData_pterygium\\\\lora_pterygium\\\\datasetconfig_Lora_pterygium_28mai.toml\",\n",
        "        f\"--output_name=lora_pte_28mai_rep6epoch{num_epochs}\",\n",
        "        \"--train_batch_size=4\",\n",
        "        f\"--max_train_epochs={num_epochs}\",\n",
        "        \"--resolution=768,768\",\n",
        "        \"--optimizer_type=AdamW8bit\",\n",
        "        \"--learning_rate=1e-4\",\n",
        "        \"--network_dim=128\",\n",
        "        \"--network_alpha=64\",\n",
        "        \"--lr_scheduler=cosine_with_restarts\",\n",
        "        \"--lr_scheduler_num_cycles=4\",\n",
        "        \"--lr_warmup_steps=500\",\n",
        "        \"--keep_tokens=1\",\n",
        "        \"--shuffle_caption\",\n",
        "        \"--caption_dropout_rate=0.05\",\n",
        "        \"--save_model_as=safetensors\",\n",
        "        \"--clip_skip=2\",\n",
        "        \"--seed=42\",\n",
        "        \"--color_aug\",\n",
        "        \"--xformers\",\n",
        "        \"--mixed_precision=fp16\",\n",
        "        \"--network_module=networks.lora\",\n",
        "        \"--persistent_data_loader_workers\"\n",
        "    ]\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "    threading.Thread(target=reader, args=[process.stdout, lambda x: print(f\"stdout: {x.strip()}\")]).start()\n",
        "    threading.Thread(target=reader, args=[process.stderr, lambda x: print(f\"stderr: {x.strip()}\")]).start()\n",
        "\n",
        "    process.wait()\n",
        "\n",
        "# Call the function\n",
        "train_network()\n"
      ],
      "metadata": {
        "id": "0g3jiAZ8W0ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}