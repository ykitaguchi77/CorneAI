{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPulLzVADCdDuhOPbfWHY/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CorneAI/blob/main/Eyelid_COCO_annotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7bcW2621aHo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Eyelid_COCO_annotation**"
      ],
      "metadata": {
        "id": "6Op0vUfl1xIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfSItiL-1fzE",
        "outputId": "b6a31266-b4cd-467d-dba3-964788aa3680"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image # (pip install Pillow)\n",
        "import numpy as np                                 # (pip install numpy)\n",
        "from skimage import measure                        # (pip install scikit-image)\n",
        "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
        "\n",
        "def create_sub_masks(mask_image):\n",
        "    width, height = mask_image.size\n",
        "\n",
        "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
        "    sub_masks = {}\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            # Get the RGB values of the pixel\n",
        "            pixel = mask_image.getpixel((x,y))[:3]\n",
        "\n",
        "            # If the pixel is not black...\n",
        "            if pixel != (0, 0, 0):\n",
        "                # Check to see if we've created a sub-mask...\n",
        "                pixel_str = str(pixel)\n",
        "                sub_mask = sub_masks.get(pixel_str)\n",
        "                if sub_mask is None:\n",
        "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
        "                    # Note: we add 1 pixel of padding in each direction\n",
        "                    # because the contours module doesn't handle cases\n",
        "                    # where pixels bleed to the edge of the image\n",
        "                    sub_masks[pixel_str] = Image.new('1', (width+2, height+2))\n",
        "\n",
        "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
        "                sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
        "\n",
        "    return sub_masks\n",
        "\n",
        "\n",
        "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd):\n",
        "    # Find contours (boundary lines) around each sub-mask\n",
        "    # Note: there could be multiple contours if the object\n",
        "    # is partially occluded. (E.g. an elephant behind a tree)\n",
        "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
        "\n",
        "    segmentations = []\n",
        "    polygons = []\n",
        "    for contour in contours:\n",
        "        # Flip from (row, col) representation to (x, y)\n",
        "        # and subtract the padding pixel\n",
        "        for i in range(len(contour)):\n",
        "            row, col = contour[i]\n",
        "            contour[i] = (col - 1, row - 1)\n",
        "\n",
        "        # Make a polygon and simplify it\n",
        "        poly = Polygon(contour)\n",
        "        poly = poly.simplify(1.0, preserve_topology=False)\n",
        "        polygons.append(poly)\n",
        "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
        "        segmentations.append(segmentation)\n",
        "\n",
        "    # Combine the polygons to calculate the bounding box and area\n",
        "    multi_poly = MultiPolygon(polygons)\n",
        "    x, y, max_x, max_y = multi_poly.bounds\n",
        "    width = max_x - x\n",
        "    height = max_y - y\n",
        "    bbox = (x, y, width, height)\n",
        "    area = multi_poly.area\n",
        "\n",
        "    annotation = {\n",
        "        'segmentation': segmentations,\n",
        "        'iscrowd': is_crowd,\n",
        "        'image_id': image_id,\n",
        "        'category_id': category_id,\n",
        "        'id': annotation_id,\n",
        "        'bbox': bbox,\n",
        "        'area': area\n",
        "    }\n",
        "\n",
        "    return annotation"
      ],
      "metadata": {
        "id": "VXGfyAdi-OaG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "plant_book_mask_image = Image.open('/content/Images/1/1_1i_Ll_1.jpg')\n",
        "bottle_book_mask_image = Image.open('/content/Images/1/1_1i_Ll_2.jpg')\n",
        "\n",
        "mask_images = [plant_book_mask_image, bottle_book_mask_image]\n",
        "\n",
        "# Define which colors match which categories in the images\n",
        "houseplant_id, book_id, bottle_id, lamp_id = [1, 2, 3, 4]\n",
        "category_ids = {\n",
        "    1: {\n",
        "        '(0, 255, 0)': houseplant_id,\n",
        "        '(0, 0, 255)': book_id,\n",
        "    },\n",
        "    2: {\n",
        "        '(255, 255, 0)': bottle_id,\n",
        "        '(255, 0, 128)': book_id,\n",
        "        '(255, 100, 0)': lamp_id,\n",
        "    }\n",
        "}\n",
        "\n",
        "is_crowd = 0\n",
        "\n",
        "# These ids will be automatically increased as we go\n",
        "annotation_id = 1\n",
        "image_id = 1\n",
        "\n",
        "# Create the annotations\n",
        "annotations = []\n",
        "for mask_image in mask_images:\n",
        "    sub_masks = create_sub_masks(mask_image)\n",
        "    for color, sub_mask in sub_masks.items():\n",
        "        category_id = category_ids[image_id][color]\n",
        "        annotation = create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd)\n",
        "        annotations.append(annotation)\n",
        "        annotation_id += 1\n",
        "    image_id += 1\n",
        "\n",
        "print(json.dumps(annotations))"
      ],
      "metadata": {
        "id": "reljHEqb-OcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ASjDnAfw-Odx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1H15ltoA-Of_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGvPIDoD-Oh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/MOBIUS.zip\" -d \"/content/\"\n"
      ],
      "metadata": {
        "id": "s4Um_Fe11we6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import collections as cl\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Redefine the functions with corrections and complete them with the necessary steps\n",
        "\n",
        "def info():\n",
        "    tmp = cl.OrderedDict()\n",
        "    tmp[\"description\"] = \"Test\"\n",
        "    tmp[\"url\"] = \"https://test\"\n",
        "    tmp[\"version\"] = \"0.01\"\n",
        "    tmp[\"year\"] = 2020\n",
        "    tmp[\"contributor\"] = \"salt22g\"\n",
        "    tmp[\"data_created\"] = \"2020/12/20\"\n",
        "    return tmp\n",
        "\n",
        "def licenses():\n",
        "    tmp = cl.OrderedDict()\n",
        "    tmp[\"id\"] = 1\n",
        "    tmp[\"url\"] = \"dummy_words\"\n",
        "    tmp[\"name\"] = \"salt22g\"\n",
        "    return tmp\n",
        "\n",
        "def images(file_path):\n",
        "    tmps = []\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    tmp = cl.OrderedDict()\n",
        "    tmp[\"license\"] = 1\n",
        "    tmp[\"id\"] = 0\n",
        "    tmp[\"file_name\"] = os.path.basename(file_path)\n",
        "    tmp[\"width\"] = width\n",
        "    tmp[\"height\"] = height\n",
        "    tmp[\"date_captured\"] = \"\"\n",
        "    tmp[\"coco_url\"] = \"dummy_words\"\n",
        "    tmp[\"flickr_url\"] = \"dummy_words\"\n",
        "    tmps.append(tmp)\n",
        "    return tmps\n",
        "\n",
        "def annotations(file_path):\n",
        "    tmps = []\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "    # Use the blue channel for finding contours which is the pupil (assuming red for sclera and green for iris)\n",
        "    blue_channel = img[:,:,0]\n",
        "    contours = measure.find_contours(blue_channel, 0.5)\n",
        "\n",
        "    for i, contour in enumerate(contours):\n",
        "        # Flip from (row, col) to (x, y) and then flatten\n",
        "        contour = np.fliplr(contour).flatten().tolist()\n",
        "        segmentation_list = contour\n",
        "\n",
        "        # Create bounding box from the segmentation\n",
        "        xs = contour[0::2]\n",
        "        ys = contour[1::2]\n",
        "        xmin = min(xs)\n",
        "        xmax = max(xs)\n",
        "        ymin = min(ys)\n",
        "        ymax = max(ys)\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "        bbox = [xmin, ymin, width, height]\n",
        "        area = width * height\n",
        "\n",
        "        tmp = cl.OrderedDict()\n",
        "        tmp[\"segmentation\"] = [segmentation_list]\n",
        "        tmp[\"id\"] = str(i)\n",
        "        tmp[\"image_id\"] = 0\n",
        "        tmp[\"category_id\"] = 1\n",
        "        tmp[\"area\"] = area\n",
        "        tmp[\"iscrowd\"] = 0\n",
        "        tmp[\"bbox\"] = bbox\n",
        "        tmps.append(tmp)\n",
        "    return tmps\n",
        "\n",
        "def categories():\n",
        "    tmps = []\n",
        "    sup = [\"person\"]\n",
        "    cat = [\"person\"]\n",
        "    for i in range(len(sup)):\n",
        "        tmp = cl.OrderedDict()\n",
        "        tmp[\"id\"] = i+1\n",
        "        tmp[\"name\"] = cat[i]\n",
        "        tmp[\"supercategory\"] = sup[i]\n",
        "        tmps.append(tmp)\n",
        "    return tmps\n",
        "\n",
        "def main(img_path, json_name):\n",
        "    query_list = [\"info\", \"licenses\", \"images\", \"annotations\", \"categories\"]\n",
        "    js = cl.OrderedDict()\n",
        "    for query in query_list:\n",
        "        if query == \"info\":\n",
        "            js[query] = info()\n",
        "        elif query == \"licenses\":\n",
        "            js[query] = licenses()\n",
        "        elif query == \"images\":\n",
        "            js[query] = images(img_path)\n",
        "        elif query == \"annotations\":\n",
        "            js[query] = annotations(img_path)\n",
        "        elif query == \"categories\":\n",
        "            js[query] = categories()\n",
        "\n",
        "    # write\n",
        "    with open(json_name, 'w') as fw:\n",
        "        json.dump(js, fw, indent=2)\n",
        "\n",
        "# The path to the image and the name of the json file\n",
        "img_path = '/content/Images/1/1_1i_Ll_1.jpg'\n",
        "json_name = '/content/coco_format.json'\n",
        "\n",
        "# Call main function with provided arguments\n",
        "main(img_path, json_name)\n",
        "\n",
        "# Return the path to the created json file\n",
        "json_name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LYVKjyvv1f0o",
        "outputId": "2b192af1-3703-42b0-fc3e-d3cfa8cc7b25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/coco_format.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}